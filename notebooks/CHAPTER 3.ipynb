{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","toc_visible":true,"authorship_tag":"ABX9TyOZUAVD9FTCtoKr16ufEdvM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#**CHAPTER 3.MULTIMODAL DRIFT UNDER GOVERNANCE**\n","---"],"metadata":{"id":"rgzq7ad4oQsb"}},{"cell_type":"markdown","source":["##REFERENCE"],"metadata":{"id":"nBRtjho5h2Cg"}},{"cell_type":"markdown","source":["https://chatgpt.com/share/699466a2-db08-8012-94aa-81e27ba6d44a"],"metadata":{"id":"SCQp1W1bWDl0"}},{"cell_type":"markdown","source":["##0.CONTEXT"],"metadata":{"id":"qWHgDkx8h5mE"}},{"cell_type":"markdown","source":["**PART 1. THE THEORY**\n","\n","Multimodality is often introduced as an engineering convenience: one model that can “see and read.” That framing is too small for what students need to understand at the frontier. The deeper claim is that a multimodal model is a machine for constructing **shared meaning under partial observation**. Each modality is a different measurement device. Images measure spatial structure, frequency content, geometry, and invariances; text measures symbolic structure, compositional rules, categorical boundaries, and social conventions. When a model becomes multimodal, it is not merely concatenating inputs; it is learning to **treat different measurements as compatible coordinates of the same underlying world**. That is the constructive thesis of Chapter 3: multimodality is not a feature; it is a theory of representation, and the theory is only as strong as the system’s ability to maintain meaning when the measurement process changes.\n","\n","Chapter 1 taught multimodality “by construction”: we built a synthetic world where images and symbolic sequences were two views of the same latent factors, and we learned a shared embedding space that made those views comparable. Chapter 2 taught that the shared space is fragile: dominance, spurious alignment, corruption, and collapse are not rare bugs but structural failure modes. Chapter 3 now steps into the frontier theme that binds the AI 2026 umbrella together: **if a multimodal model is a mapping from measurements to meaning, what happens when the measurement process drifts?** In production, modalities drift for mundane reasons: camera exposure changes, compression settings shift, fonts change, tokenization evolves, prompt templates mutate, languages and slang drift, image styles change, the data pipeline adds a new preprocessing step, or the “text” modality begins to include OCR artifacts. In scientific terms, the observation operator changes. In governance terms, the system’s claims are no longer anchored to the same input semantics. In professional terms, the model can remain confident while becoming wrong.\n","\n","The core theoretical move of this chapter is to treat multimodal systems as **coupled measurement channels** with a shared latent contract. Under stable conditions, the contract is: “if the same underlying object generated two observations, the system should map them to nearby points.” But production systems rarely enjoy stability. We must therefore add a second contract: “if the measurement channel changes, the system must either (a) preserve the meaning geometry, or (b) surface that it cannot.” This is the boundary between impressive demos and professional systems. A model that is “good on average” but cannot detect when the channel has changed is not a model; it is a liability.\n","\n","This chapter therefore takes a control-and-governance view of multimodality. A multimodal model is a controller whose outputs depend on representations; representation drift changes the effective controller policy even if no code changed. The appropriate posture is not to celebrate capability but to impose **stage gates**: signals that drift is occurring, diagnostics that isolate which modality is responsible, and procedures that decide whether to adapt, rollback, or halt. Importantly, drift is not only “performance goes down.” Drift can improve a metric while degrading meaning. For example, a spurious shortcut can increase retrieval accuracy while destroying factor semantics. So the theory emphasizes geometry and invariants over point metrics. We monitor whether the embedding space still encodes the factors we care about, whether modality symmetry holds, whether hubness emerges, and whether the system’s alignment depends on confounders.\n","\n","This theory also explains why purely heuristic detection often fails. In Chapter 2 we used monitors such as effective rank, mean cosine similarity, covariance spectra, retrieval asymmetry, and MI-like proxies. Those are useful, but drift signatures are not guaranteed to be linearly separable in monitor space. Two different failure mechanisms can produce similar surface metrics, and the same mechanism can produce different metrics depending on model scale, temperature, and normalization. Therefore Chapter 3 adds a key frontier idea: **monitoring is itself a modeling problem**. We can build a synthetic laboratory where the drift mechanism is known, then learn or at least validate the mapping from monitors to diagnoses. The pedagogy is not to “memorize thresholds,” but to understand why thresholds are brittle and what robust alternatives look like: counterfactual tests, ablations, invariance checks, and intervention-labeled ground truth in synthetic settings.\n","\n","Finally, Chapter 3 positions multimodal drift alongside the other AI 2026 frontier topics. Long context and memory fail when retrieval becomes selection without constraint; surrogates fail when proxies replace reality without governance. Multimodality fails when measurement channels drift and the system continues to behave as if semantics are unchanged. These are the same story: frontier capability creates new failure modes, and governance is the discipline of making those failure modes observable, reviewable, and actionable.\n","\n","**PART 2. DEFINITIONS OF KEY IDEAS LIKE LATENT SPACE**\n","\n","**Latent space** in this book is not a mystical “hidden dimension.” It is a coordinate system learned by the model that is intended to represent stable properties of the underlying world. In our synthetic laboratories, the “world” is explicit: shapes, orientations, frequencies, phases, thickness, and optional confounders. The latent space is therefore interpretable: it should reflect those factors in geometry. Two samples with the same shape but different orientation should be close in the “shape direction” and separated along the “orientation direction.” In real systems, latent factors are not so clean, but the concept remains: a latent space is the model’s internal representation of “what matters” for its task.\n","\n","**Embedding** is a point in latent space produced by an encoder. For multimodal systems, we have at least two encoders: one for images and one for text. The central objective is not that each encoder is good in isolation, but that the embeddings are **compatible**: the image embedding and the text embedding for the same underlying object should be near each other under a similarity measure. Compatibility is the operational meaning of multimodal alignment.\n","\n","**Alignment** is the property that corresponding observations from different modalities map to nearby points in the shared space. In our notebooks, we often measure alignment via contrastive learning objectives such as InfoNCE, and via retrieval metrics (image→text and text→image). But alignment is broader than retrieval accuracy: alignment means that the shared space preserves semantic structure, not merely pair identity.\n","\n","**Modality symmetry** is the requirement that neither modality becomes privileged in a way that breaks the shared contract. In practice, symmetry can fail through dominance: one modality’s encoder produces embeddings that are easier to match, so training optimizes for that modality and neglects the other. Symmetry is tested by comparing retrieval directions, embedding norm distributions, covariance spectra, and performance degradation under asymmetric noise.\n","\n","**Spurious alignment** occurs when the system aligns modalities through a feature that is shared across modalities but is not the semantic target. In synthetic settings, a confounder can be sample index parity, a watermark, a style marker, or an “ID codebook” appended to both embeddings. Spurious alignment is dangerous because it can increase metrics while destroying meaning. The correct detection tool is often counterfactual: remove the confounder and measure the performance drop.\n","\n","**Representation collapse** is the degenerate case where embeddings lose diversity. In collapsed states, embeddings become nearly identical across samples, covariance rank collapses, and average cosine similarity increases. Collapse can occur due to overly aggressive optimization, bad temperature settings, poor regularization design, or architectural imbalance. Collapse is not only a training pathology; it is also a drift risk if a downstream system forces embeddings through a low-rank bottleneck.\n","\n","**Drift** is a change in the distribution or semantics of inputs, or in the mapping from inputs to embeddings, over time. In multimodal systems, drift is multidimensional: the image distribution can drift while text remains stable; the tokenization scheme can change; the pairing structure can degrade; the prevalence of confounders can shift. Drift is not synonymous with “performance declines.” Drift means the model is operating under a different measurement process than the one it was trained and validated on.\n","\n","**Drift signature** is a pattern in monitor signals that is indicative of a specific drift mechanism. Signatures are not guaranteed to be unique. Therefore a professional system should treat signatures as hypotheses, not proofs. The goal is to combine multiple monitors and counterfactual tests to narrow the diagnosis.\n","\n","**Stage gates** are governance checkpoints that determine whether a system is allowed to proceed. In this chapter, stage gates are defined over monitor distributions rather than single values: for example, “effective rank must remain above a floor across seeds,” “retrieval asymmetry must not exceed a threshold,” “counterfactual confounder drop must remain below a bound,” and “covariance spectrum must not develop a heavy hubness tail.” Stage gates transform monitoring into enforceable operational practice.\n","\n","**Audit bundle** is the reproducibility artifact produced by each run: configuration hashes, deterministic seeds, logs, plots, JSON reports, and risk taxonomy. The audit bundle is not bureaucracy; it is the condition for reviewability. If a drift event occurs, the audit bundle is what allows the team to answer: what changed, how do we know, and what are we doing about it?\n","\n","**PART 3. METHODOLOGY**\n","\n","The Chapter 3 methodology is a governed synthetic laboratory for multimodal drift. The goal is to recreate, at small scale, the logic of production monitoring. We proceed in four stages.\n","\n","First, we build a **baseline multimodal aligner** similar to Chapters 1 and 2: two encoders mapping synthetic images and symbolic text to a shared embedding space trained with a contrastive objective. The baseline matters because drift is defined relative to an operational reference. Without a baseline, “drift detection” is meaningless; there is no contract to measure against.\n","\n","Second, we define a suite of **drift episodes**—controlled interventions that represent distinct failure mechanisms. Unlike typical toy examples, we insist that the interventions have a clear causal interpretation. A drift episode is not “add random noise.” It is a hypothesis about what could go wrong: pairing corruption, modality noise asymmetry, confounder emergence, hubness or anisotropy, and collapse. We also include “smooth drift” episodes that gradually increase noise and minor corruption, to illustrate that many real failures are not abrupt.\n","\n","Third, we compute **monitor signals** that are intended to function like early warning indicators. These include retrieval metrics in both directions, symmetry gaps, hubness proxies, covariance spectra and effective rank, mean cosine similarity (as a collapse signal), and MI-like proxies connecting embeddings to true factors. We also compute counterfactual sensitivity where appropriate: for example, add a confounder shortcut and measure the delta in retrieval when it is removed. The monitors are chosen because they correspond to structural properties of the embedding geometry, not just performance.\n","\n","Fourth, we operationalize governance: every run produces a **strict JSON report** that separates facts, assumptions, open items, analysis, and draft outputs, with verification status explicitly set to “Not verified.” The notebook generates a full audit bundle with manifests, risk logs, and plots saved to disk. The key pedagogical move is that students can inspect how each drift mechanism affects the geometry and the monitors, and they can see the limitations of heuristic attribution.\n","\n","A critical lesson from Chapter 2 is that heuristic thresholds often fail. Therefore Chapter 3 explicitly separates two notions of “diagnosis.” One is **intervention-labeled ground truth** in the synthetic laboratory: we know what drift we injected. The other is **monitor-based heuristic diagnosis**: what the monitors suggest. The gap between the two is the educational value: it demonstrates why production monitoring requires calibration, ensembles of monitors, and counterfactual tests. In a synthetic lab, we can label drift; in production, we infer it.\n","\n","Finally, we include stress testing: we vary drift intensity and seed, and we track monitor distributions. The output is not a single curve but a family of curves, emphasizing that professional acceptance criteria are distributional. The notebook therefore aligns with the AI 2026 posture: frontier capability requires supervision infrastructure, not just a model checkpoint.\n","\n","**PART 4. DELIVERABLES**\n","\n","This chapter’s deliverables are designed to be inspectable, reproducible, and teachable.\n","\n","**A governed Colab notebook** implementing the complete drift laboratory end-to-end, with deterministic seeds, modular code structure, and careful numerical stability. The notebook is intended to run under a single “Run all,” producing consistent artifacts.\n","\n","**A synthetic multimodal dataset generator** that creates paired image matrices and symbolic text feature vectors from a shared factor model. The generator includes optional drift knobs: noise, pairing corruption, confounder injection, and controlled preprocessing changes. This generator is the reusable asset for future lectures.\n","\n","**A drift episode suite** that constructs a timeline of distinct drift mechanisms, including both targeted interventions and smooth drift. Each episode is logged with configuration metadata so that drift events are reproducible.\n","\n","**A monitor and diagnostics suite** that outputs: retrieval metrics (both directions), symmetry and dominance indicators, hubness proxies, collapse indicators (mean cosine, effective rank, covariance spectrum), and factor-information probes (MI proxy and CCA-like proxy). All plots are saved to disk for later review.\n","\n","**A full evidence report** in strict JSON, exported to a deliverables folder. The report includes per-episode evidence rows, baseline references, and both intervention-labeled “truth” and monitor-based heuristic diagnoses, explicitly highlighting when heuristic diagnosis fails.\n","\n","**An audit bundle** containing run manifests, prompts logs (redacted with hashes), risk logs, metrics summaries, drift timeline reports, and plots, zipped at the end of the run. The audit bundle is the unit of supervision: it is what a reviewer, instructor, or risk committee can inspect without rerunning the notebook.\n","\n","**A risk taxonomy and control mapping** specific to multimodal drift: confounding, dominance, collapse, train-test leakage, metric gaming, and pipeline drift, with concrete controls implemented in the notebook (determinism, split hygiene, counterfactual checks, spectra monitoring, and artifact logging). The taxonomy is not decorative; it is the framing that connects the lab to professional practice.\n","\n","**Pedagogical outcomes**: students should leave with a precise understanding that multimodality is a geometry problem under changing measurement operators; that drift is not a single metric decline but a structural change in representation; that monitoring is itself a modeling problem; and that governance is the practical discipline that makes drift observable and actionable. They should also leave with a reusable template: how to build synthetic worlds, how to build diagnostics, and how to make a frontier system reviewable rather than merely impressive.\n"],"metadata":{"id":"pF_yDrZ7h6_y"}},{"cell_type":"markdown","source":["##1.LIBRARIES AND ENVIRONMENT"],"metadata":{"id":"yeIrVzqFh7fZ"}},{"cell_type":"markdown","source":["**CELL 1 — ENVIRONMENT, REPRODUCIBILITY, AND THE CONTRACT OF THE LAB**\n","\n","This first cell establishes the laboratory’s most important professional principle: if a multimodal system is being used to teach frontier ideas, then the experiment must be reproducible and reviewable. The purpose is not only to “set seeds” but to define the environment as part of the scientific object. Multimodal learning is extremely sensitive to small implementation details—random initialization, data order, numeric stability, and even plotting behavior can change outcomes. So Cell 1 sets deterministic seeds, configures global numerical behavior, and creates the folder structure that will hold every artifact we later claim to have produced. In other words, it creates the boundary between a notebook that “ran once” and a notebook that can be defended.\n","\n","Pedagogically, Cell 1 introduces the idea that the experiment has a contract: we will build a multimodal aligner, we will induce drift, and we will detect drift using measurable indicators. That contract must be encoded in configuration rather than in “hand edits.” Students should see that a professional system makes assumptions explicit: embedding dimension, batch size, temperature, learning rate, noise levels, drift intensities, and evaluation sizes all belong in a structured config. This is not an aesthetic choice; it is governance. When a drift event is found later, the first question is: what exactly did we run?\n","\n","Cell 1 also emphasizes that time matters. Drift is a temporal concept, so the notebook records timezone-aware UTC timestamps for the run. This aligns the lab with production operations: monitoring is time-indexed evidence. Finally, this cell sets the tone for the chapter: we are not optimizing for a leaderboard score. We are building an instrument to observe representation geometry under change. A good student outcome is that they understand why “reproducibility utilities” are not a boring preface but the first stage of scientific seriousness. Without this cell, the rest of the chapter becomes a story you cannot prove.\n"],"metadata":{"id":"DGNJu3YAFDsL"}},{"cell_type":"code","source":["# === Cell 1 ===\n","# Title: Runtime Contract — Determinism, Configuration, and Paths\n","# Brief Explanation: Establish reproducible execution, define all configurable parameters, and set filesystem layout for governed artifacts.\n","\n","from __future__ import annotations\n","\n","import os\n","import sys\n","import json\n","import math\n","import time\n","import uuid\n","import shutil\n","import hashlib\n","import zipfile\n","import platform\n","import datetime as _dt\n","from dataclasses import dataclass, asdict, field\n","from typing import Any, Dict, List, Tuple, Optional, Callable\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","\n","def utc_now_iso() -> str:\n","    return _dt.datetime.now(_dt.timezone.utc).isoformat()\n","\n","\n","def set_global_determinism(seed: int) -> None:\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    np.random.seed(seed)\n","\n","\n","def ensure_dir(path: str) -> None:\n","    os.makedirs(path, exist_ok=True)\n","\n","\n","def stable_float(x: float) -> float:\n","    if not np.isfinite(x):\n","        return float(\"nan\")\n","    return float(x)\n","\n","\n","@dataclass(frozen=True)\n","class Paths:\n","    root: str\n","    deliverables: str\n","    plots: str\n","    checkpoints: str\n","\n","\n","@dataclass(frozen=True)\n","class DataCfg:\n","    n_train: int = 1024\n","    n_val: int = 256\n","    n_test: int = 256\n","    image_side: int = 16\n","    text_seq_len: int = 11\n","    vocab_size: int = 64\n","    noise_image: float = 0.15\n","    noise_text: float = 0.10\n","    confounder_enabled: bool = False\n","    confounder_type: str = \"parity\"  # \"parity\" or \"bucket\"\n","    confounder_strength: float = 1.25\n","    pairing_corruption_rate: float = 0.0  # 0..1\n","    # Latent factor supports\n","    n_shape: int = 4\n","    n_orient: int = 8\n","    n_freq: int = 6\n","    n_phase: int = 8\n","    n_thick: int = 3\n","\n","\n","@dataclass(frozen=True)\n","class ModelCfg:\n","    emb_dim: int = 48\n","    hidden_dim: int = 128\n","    temperature: float = 0.12\n","    l2_weight_decay: float = 1e-4\n","    pre_norm_gain_img: float = 1.0\n","    pre_norm_gain_txt: float = 1.0\n","\n","\n","@dataclass(frozen=True)\n","class TrainCfg:\n","    seed: int = 1337\n","    steps: int = 900\n","    batch_size: int = 128\n","    lr: float = 0.065\n","    eval_every: int = 100\n","    grad_clip: float = 5.0\n","    # Determinism self-check\n","    det_check_steps: int = 12\n","    det_check_batch: int = 64\n","\n","\n","@dataclass(frozen=True)\n","class AcceptCfg:\n","    min_retr_top1: float = 0.55\n","    min_retr_top5: float = 0.85\n","    max_sym_gap_abs: float = 0.10\n","    max_mean_offdiag_cos: float = 0.22\n","    min_var_floor: float = 2e-3\n","    min_eff_rank: float = 12.0\n","    min_mi_proxy: float = 0.05\n","    min_cca_proxy: float = 0.35\n","    # Robustness margins\n","    max_noise_deg_slope: float = 0.18   # allowable top1 drop per noise unit\n","    max_corrupt_deg_slope: float = 0.65 # allowable top1 drop per corruption unit\n","    max_counterfactual_drop: float = 0.20  # confounder removal drop ceiling (if exceeded => reject)\n","\n","\n","@dataclass(frozen=True)\n","class DriftCfg:\n","    steps: int = 14\n","    noise_image_start: float = 0.15\n","    noise_image_end: float = 0.45\n","    noise_text_start: float = 0.10\n","    noise_text_end: float = 0.35\n","    corruption_start: float = 0.00\n","    corruption_end: float = 0.20\n","    confounder_start_step: int = 8\n","    confounder_strength: float = 1.35\n","    orient_concentration_start_step: int = 6  # domain shift: concentrate orientations\n","    orient_concentration_strength: float = 0.85  # probability mass on a subset\n","\n","\n","@dataclass(frozen=True)\n","class Cfg:\n","    paths_base: str = \"/content/mm_gov_ch3\"\n","    run_name_prefix: str = \"mm_ch3\"\n","    data: DataCfg = field(default_factory=DataCfg)\n","    model: ModelCfg = field(default_factory=ModelCfg)\n","    train: TrainCfg = field(default_factory=TrainCfg)\n","    accept: AcceptCfg = field(default_factory=AcceptCfg)\n","    drift: DriftCfg = field(default_factory=DriftCfg)\n","\n","\n","CFG = Cfg()\n","\n","set_global_determinism(CFG.train.seed)\n","\n","run_id = f\"{CFG.run_name_prefix}_{utc_now_iso().replace(':','').replace('-','').replace('.','')}_{uuid.uuid4().hex[:8]}\"\n","ROOT = os.path.join(CFG.paths_base, run_id)\n","P = Paths(\n","    root=ROOT,\n","    deliverables=os.path.join(ROOT, \"deliverables\"),\n","    plots=os.path.join(ROOT, \"deliverables\", \"plots\"),\n","    checkpoints=os.path.join(ROOT, \"deliverables\", \"checkpoints\"),\n",")\n","for d in (P.root, P.deliverables, P.plots, P.checkpoints):\n","    ensure_dir(d)\n","\n","print(\"Run root:\", P.root)\n","print(\"NumPy:\", np.__version__)\n","print(\"Python:\", sys.version.split()[0])\n","print(\"UTC:\", utc_now_iso())\n"],"metadata":{"id":"sd0qEMbqWFlk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1771335615431,"user_tz":360,"elapsed":43,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"8eff47a7-7c41-48a2-9881-de0b43a46dbe"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Run root: /content/mm_gov_ch3/mm_ch3_20260217T134016185419+0000_19b2e27a\n","NumPy: 2.0.2\n","Python: 3.12.12\n","UTC: 2026-02-17T13:40:16.186164+00:00\n"]}]},{"cell_type":"markdown","source":["##2.GOVERNANCE TOOLKIT"],"metadata":{"id":"aOzs2vNWiEjE"}},{"cell_type":"markdown","source":["###2.1.OVERVIEW"],"metadata":{"id":"_Z7ptw6JiIcM"}},{"cell_type":"markdown","source":["**CELL 2 — GOVERNANCE ARTIFACTS, LOGGING, AND RISK TAXONOMY**\n","\n","Cell 2 operationalizes governance. In earlier chapters, you required that every run produces an audit bundle: a manifest, prompt logs, risk logs, and a deliverables folder. This cell is where that becomes real. The notebook creates structured JSON writers with atomic file replacement to prevent partial writes, defines hashing utilities to track configuration and code identity, and establishes redaction rules for prompt logs. Even though we are using synthetic data and not calling external models, the point is to teach students the discipline of evidence: every run is a record that could be reviewed by someone else.\n","\n","Pedagogically, Cell 2 is where the chapter becomes institutional. It introduces a risk taxonomy specifically for multimodal drift: confounding shortcuts, modality dominance, collapse, pairing corruption, train-test leakage, and metric gaming. Each risk is paired with controls we will actually implement: deterministic seeds, split hygiene checks, counterfactual deltas, covariance spectra monitoring, and explicit stage-gate logic. Students learn that a “risk log” is not a disclaimer; it is a map from failure modes to measurable protections.\n","\n","This cell also defines the strict JSON schema you demanded: the notebook’s reports must separate facts, assumptions, open items, analysis, and draft output, with verification status set to “Not verified.” That constraint is pedagogically powerful: it forces the modeler to admit what is proven by artifacts versus what is inferred. The result is that when we later claim “hubness increased” or “collapse occurred,” those statements are traceable to logged metrics, not narrative confidence. Cell 2 therefore sets the discipline that the chapter is trying to teach: multimodal models require monitoring, and monitoring requires auditability.\n"],"metadata":{"id":"jAsIm-aiiLkE"}},{"cell_type":"markdown","source":["###2.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"AK_Iz2Q4iL4X"}},{"cell_type":"code","source":["# === Cell 2 ===\n","# Title: Governance Toolkit — Hashing, Redaction, Strict JSON Writers, and Run Manifest\n","# Brief Explanation: Create audit-grade writers and initialize run_manifest, prompts_log, and risk_log scaffolding.\n","\n","from __future__ import annotations\n","\n","def sha256_bytes(b: bytes) -> str:\n","    return hashlib.sha256(b).hexdigest()\n","\n","def sha256_str(s: str) -> str:\n","    return sha256_bytes(s.encode(\"utf-8\"))\n","\n","def file_sha256(path: str) -> str:\n","    h = hashlib.sha256()\n","    with open(path, \"rb\") as f:\n","        for chunk in iter(lambda: f.read(1 << 20), b\"\"):\n","            h.update(chunk)\n","    return h.hexdigest()\n","\n","def redact_text(s: str, keep: int = 160) -> str:\n","    s2 = \" \".join(s.strip().split())\n","    if len(s2) <= keep:\n","        return s2\n","    return s2[:keep] + \" …[redacted]\"\n","\n","def json_dumps_canonical(obj: Any) -> str:\n","    return json.dumps(obj, sort_keys=True, ensure_ascii=False, separators=(\",\", \":\"))\n","\n","def write_json_atomic(path: str, obj: Any) -> None:\n","    tmp = path + \".tmp\"\n","    with open(tmp, \"w\", encoding=\"utf-8\") as f:\n","        f.write(json_dumps_canonical(obj))\n","    os.replace(tmp, path)\n","\n","def strict_report(\n","    *,\n","    facts_provided: Dict[str, Any],\n","    assumptions: Dict[str, Any],\n","    open_items: List[str],\n","    analysis: str,\n","    draft_output: Any,\n","    verification_status: str = \"Not verified\",\n","    questions_to_verify: List[str] | None = None,\n",") -> Dict[str, Any]:\n","    if questions_to_verify is None:\n","        questions_to_verify = []\n","    return {\n","        \"facts_provided\": facts_provided,\n","        \"assumptions\": assumptions,\n","        \"open_items\": open_items,\n","        \"analysis\": analysis,\n","        \"draft_output\": draft_output,\n","        \"verification_status\": verification_status,\n","        \"questions_to_verify\": questions_to_verify,\n","    }\n","\n","def env_fingerprint() -> Dict[str, Any]:\n","    return {\n","        \"python\": sys.version.split()[0],\n","        \"numpy\": np.__version__,\n","        \"platform\": platform.platform(),\n","        \"timestamp_utc\": utc_now_iso(),\n","    }\n","\n","RUN_MANIFEST_PATH = os.path.join(P.root, \"run_manifest.json\")\n","PROMPTS_LOG_PATH = os.path.join(P.root, \"prompts_log.jsonl\")\n","RISK_LOG_PATH = os.path.join(P.root, \"risk_log.json\")\n","\n","prompt_text = (\n","    \"Chapter 3 notebook: governed multimodal system with acceptance tests, drift simulation, and monitoring.\"\n",")\n","prompt_entry = {\n","    \"ts_utc\": utc_now_iso(),\n","    \"prompt_redacted\": redact_text(prompt_text),\n","    \"prompt_sha256\": sha256_str(prompt_text),\n","}\n","\n","with open(PROMPTS_LOG_PATH, \"w\", encoding=\"utf-8\") as f:\n","    f.write(json_dumps_canonical(prompt_entry) + \"\\n\")\n","\n","risk_taxonomy = {\n","    \"spurious_shortcuts_confounding\": {\n","        \"risk\": \"Model aligns on shared artifacts (watermarks/metadata) rather than intended factors.\",\n","        \"controls\": [\"counterfactual confounder removal test\", \"leakage alarms\", \"robustness sweeps\"],\n","    },\n","    \"modality_dominance_imbalance\": {\n","        \"risk\": \"One modality anchors the shared space; causes asymmetry and brittle generalization.\",\n","        \"controls\": [\"symmetric evaluation gates\", \"gradient norm monitoring per modality\", \"symmetry gap thresholds\"],\n","    },\n","    \"representation_collapse\": {\n","        \"risk\": \"Embeddings lose diversity (low rank, high cosine similarity); transfer fails despite loss decreasing.\",\n","        \"controls\": [\"variance floor + mean cosine ceiling gates\", \"effective rank monitoring\", \"spectral summaries\"],\n","    },\n","    \"train_test_leakage\": {\n","        \"risk\": \"Splits allow shortcut features to leak; inflated validation metrics.\",\n","        \"controls\": [\"split hygiene assertions\", \"leakage alarms based on index-like cues\"],\n","    },\n","    \"metric_gaming\": {\n","        \"risk\": \"Optimization overfits to a single retrieval direction or to easy negatives.\",\n","        \"controls\": [\"bidirectional retrieval gates\", \"entropy calibration proxy\", \"probe sanity checks (MI/CCA)\"],\n","    },\n","    \"drift_blind_spots\": {\n","        \"risk\": \"Deployment shifts degrade alignment without alert; silent failure.\",\n","        \"controls\": [\"drift timeline monitoring\", \"failure signature classifier\", \"release decision + rollback posture\"],\n","    },\n","}\n","\n","write_json_atomic(\n","    RISK_LOG_PATH,\n","    strict_report(\n","        facts_provided={\"risk_taxonomy\": risk_taxonomy},\n","        assumptions={\"scope\": \"Synthetic lab; proxies approximate real-world behavior.\"},\n","        open_items=[\"How well do these diagnostics transfer to large-scale pretrained multimodal models?\"],\n","        analysis=\"Risk log enumerates multimodal failure modes and controls implemented in this notebook.\",\n","        draft_output={\"controls_enabled\": True},\n","        questions_to_verify=[\"Do counterfactual tests cover the most likely confounders for the target domain?\"],\n","    ),\n",")\n","\n","manifest = {\n","    \"run_id\": run_id,\n","    \"timestamp_utc\": utc_now_iso(),\n","    \"paths\": asdict(P),\n","    \"cfg_sha256\": sha256_str(json_dumps_canonical(asdict(CFG))),\n","    \"env_fingerprint\": env_fingerprint(),\n","    \"artifacts\": {\n","        \"run_manifest\": \"run_manifest.json\",\n","        \"prompts_log\": \"prompts_log.jsonl\",\n","        \"risk_log\": \"risk_log.json\",\n","        \"deliverables_dir\": \"deliverables/\",\n","    },\n","    \"verification_status\": \"Not verified\",\n","}\n","write_json_atomic(RUN_MANIFEST_PATH, manifest)\n","\n","print(\"Initialized governance artifacts:\")\n","print(\" -\", RUN_MANIFEST_PATH)\n","print(\" -\", PROMPTS_LOG_PATH)\n","print(\" -\", RISK_LOG_PATH)\n"],"metadata":{"id":"IDDyGwjWiO56","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1771335625812,"user_tz":360,"elapsed":15,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"b9005c3e-5e6a-4f76-9ff5-678e56b6e54c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Initialized governance artifacts:\n"," - /content/mm_gov_ch3/mm_ch3_20260217T134016185419+0000_19b2e27a/run_manifest.json\n"," - /content/mm_gov_ch3/mm_ch3_20260217T134016185419+0000_19b2e27a/prompts_log.jsonl\n"," - /content/mm_gov_ch3/mm_ch3_20260217T134016185419+0000_19b2e27a/risk_log.json\n"]}]},{"cell_type":"markdown","source":["##3.SYNTHETIC WORLD"],"metadata":{"id":"zn9_gpBPh_yn"}},{"cell_type":"markdown","source":["###3.1.OVERVIEW"],"metadata":{"id":"6Sg0lGxQiBj6"}},{"cell_type":"markdown","source":["**CELL 3 — SYNTHETIC MULTIMODAL WORLD AND DRIFT KNOBS**\n","\n","Cell 3 constructs the synthetic world: images and text are not arbitrary data, but two measurement channels of the same latent factors. The educational purpose is that students can visualize what each modality “means.” Images are small matrices encoding controlled factors like shape or frequency; text is a symbolic encoding of those same factors transformed into feature vectors. The real lesson is that multimodality is about compatible coordinate systems: both channels should support the same latent semantics, but they do so through different encodings.\n","\n","Crucially, Cell 3 includes drift knobs. Drift is not an abstract notion; it is a controlled change in the measurement operator. This cell therefore parameterizes noise levels separately for image and text, introduces pairing corruption rates, and optionally injects confounders. Students learn a nontrivial distinction: a distribution shift can be purely statistical (more noise), purely structural (pairing corruption), or semantic (a shared confounder emerges). These shifts are different and must be diagnosed differently.\n","\n","Cell 3 also enforces split hygiene. Drift experiments are meaningless if leakage occurs. The notebook therefore creates train, validation, and test splits deterministically and asserts that indices do not overlap. This is more than good practice: the whole chapter depends on comparing “baseline” to “drift episodes” on a stable evaluation set. If evaluation changes, drift detection becomes self-deception. By building the world explicitly, Cell 3 gives students the rare gift of being able to know what “ground truth semantics” are and to test whether embeddings preserve them.\n"],"metadata":{"id":"B7g7qJgZiEOw"}},{"cell_type":"markdown","source":["###3.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"SqN4lQyuiE7Y"}},{"cell_type":"code","source":["# === Cell 3 ===\n","# Title: Synthetic World v3 — Factors, Modalities, Shifts, Splits, and Leakage Alarms\n","# Brief Explanation: Generate paired synthetic modalities with known latent factors and tools to simulate deployment drift and detect shortcut leakage.\n","\n","from __future__ import annotations\n","\n","@dataclass(frozen=True)\n","class Factors:\n","    shape: np.ndarray\n","    orient: np.ndarray\n","    freq: np.ndarray\n","    phase: np.ndarray\n","    thick: np.ndarray\n","    confounder: np.ndarray\n","\n","def _rng(seed: int) -> np.random.RandomState:\n","    return np.random.RandomState(seed)\n","\n","def make_factors(n: int, seed: int, dc: DataCfg, orient_shift: Optional[Dict[str, float]] = None) -> Factors:\n","    r = _rng(seed)\n","    shape = r.randint(0, dc.n_shape, size=n)\n","    freq = r.randint(0, dc.n_freq, size=n)\n","    phase = r.randint(0, dc.n_phase, size=n)\n","    thick = r.randint(0, dc.n_thick, size=n)\n","\n","    if orient_shift is None:\n","        orient = r.randint(0, dc.n_orient, size=n)\n","    else:\n","        # Concentrate mass on a subset of orientations (domain shift)\n","        strength = float(orient_shift.get(\"strength\", 0.8))\n","        subset = int(orient_shift.get(\"subset\", 2))\n","        subset = max(1, min(dc.n_orient, subset))\n","        probs = np.ones(dc.n_orient, dtype=np.float64) * ((1.0 - strength) / max(1, (dc.n_orient - subset)))\n","        probs[:subset] = strength / subset\n","        probs = probs / probs.sum()\n","        orient = r.choice(dc.n_orient, size=n, p=probs)\n","\n","    # Index-derived confounder candidates mimic metadata-like cues\n","    confounder = (np.arange(n) % 2).astype(np.int64) if dc.confounder_type == \"parity\" else ((np.arange(n) // 7) % 8).astype(np.int64)\n","    return Factors(shape=shape, orient=orient, freq=freq, phase=phase, thick=thick, confounder=confounder)\n","\n","def render_images(f: Factors, dc: DataCfg, seed: int) -> np.ndarray:\n","    r = _rng(seed)\n","    n = f.shape.shape[0]\n","    S = int(dc.image_side)\n","\n","    yy, xx = np.meshgrid(np.linspace(-1, 1, S), np.linspace(-1, 1, S), indexing=\"ij\")\n","    ang = (f.orient.astype(np.float32) / dc.n_orient) * (2.0 * np.pi)\n","    ca = np.cos(ang)[:, None, None]\n","    sa = np.sin(ang)[:, None, None]\n","    xr = ca * xx[None, :, :] + sa * yy[None, :, :]\n","\n","    fr = (1.5 + f.freq.astype(np.float32))[:, None, None]\n","    ph = (f.phase.astype(np.float32) / dc.n_phase * 2.0 * np.pi)[:, None, None]\n","    base = np.sin(fr * np.pi * xr + ph).astype(np.float32)\n","\n","    r0 = np.sqrt(xx**2 + yy**2).astype(np.float32)\n","    circle0 = (r0 < 0.75).astype(np.float32)\n","    square0 = ((np.abs(xx) < 0.75) & (np.abs(yy) < 0.75)).astype(np.float32)\n","    diamond0 = ((np.abs(xx) + np.abs(yy)) < 1.05).astype(np.float32)\n","    stripe0 = (np.abs(xx) < 0.45).astype(np.float32)\n","\n","    masks = np.stack([circle0, square0, diamond0, stripe0], axis=0).astype(np.float32)  # (4,S,S)\n","    m = masks[f.shape]  # (n,S,S)\n","\n","    th = (1.0 + f.thick.astype(np.float32))[:, None, None]\n","    img = (m * base)\n","    img = np.sign(img) * (np.abs(img) ** (1.0 / th))\n","\n","    img = img.astype(np.float32)\n","    img -= img.mean(axis=(1, 2), keepdims=True)\n","    img /= (img.std(axis=(1, 2), keepdims=True) + 1e-6)\n","    img += r.randn(n, S, S).astype(np.float32) * float(dc.noise_image)\n","\n","    if bool(dc.confounder_enabled):\n","        if dc.confounder_type == \"parity\":\n","            bit = (f.confounder % 2).astype(np.float32)\n","            img[:, 0, 0] += float(dc.confounder_strength) * (2.0 * bit - 1.0)\n","        else:\n","            bucket = f.confounder.astype(np.float32)\n","            img[:, :, 0] += float(dc.confounder_strength) * ((bucket / 7.0) * 2.0 - 1.0)[:, None]\n","    return img.reshape(n, -1).astype(np.float32)\n","\n","def tokens_to_features(f: Factors, dc: DataCfg, seed: int) -> np.ndarray:\n","    r = _rng(seed)\n","    n = f.shape.shape[0]\n","    L = int(dc.text_seq_len)\n","    V = int(dc.vocab_size)\n","    if L < 9:\n","        raise ValueError(\"text_seq_len must be >= 9\")\n","\n","    sep = 1\n","    base = 4\n","    shape_t = base + f.shape\n","    orient_t = base + 8 + f.orient\n","    freq_t = base + 8 + 8 + f.freq\n","    phase_t = base + 8 + 8 + 6 + f.phase\n","    thick_t = base + 8 + 8 + 6 + 8 + f.thick\n","\n","    seq = np.zeros((n, L), dtype=np.int64)\n","    seq[:, 0] = shape_t\n","    seq[:, 1] = sep\n","    seq[:, 2] = orient_t\n","    seq[:, 3] = sep\n","    seq[:, 4] = freq_t\n","    seq[:, 5] = sep\n","    seq[:, 6] = phase_t\n","    seq[:, 7] = sep\n","    seq[:, 8] = thick_t\n","\n","    if bool(dc.confounder_enabled):\n","        if dc.confounder_type == \"parity\":\n","            ctok = 2 + (f.confounder % 2)\n","        else:\n","            ctok = 2 + (f.confounder % min(16, V - 2))\n","        seq[:, 0] = ctok\n","\n","    bow = np.zeros((n, V), dtype=np.float32)\n","    for pos in range(L):\n","        tok = seq[:, pos]\n","        bow[np.arange(n), tok] += 1.0\n","    bow /= float(L)\n","\n","    K = min(24, V)\n","    pos_feat = np.zeros((n, K), dtype=np.float32)\n","    positions = np.arange(L, dtype=np.float32) / max(1.0, (L - 1))\n","    for k in range(K):\n","        mask = (seq == k).astype(np.float32)\n","        denom = mask.sum(axis=1) + 1e-6\n","        pos_feat[:, k] = (mask * positions[None, :]).sum(axis=1) / denom\n","\n","    x = np.concatenate([bow, pos_feat], axis=1)\n","    x += r.randn(*x.shape).astype(np.float32) * float(dc.noise_text)\n","    return x.astype(np.float32)\n","\n","def corrupt_pairs(idx: np.ndarray, rate: float, seed: int) -> np.ndarray:\n","    if rate <= 0.0:\n","        return idx.copy()\n","    r = _rng(seed + 17777)\n","    n = idx.shape[0]\n","    m = int(n * rate)\n","    if m <= 1:\n","        return idx.copy()\n","    sel = r.choice(n, size=m, replace=False)\n","    perm = sel.copy()\n","    r.shuffle(perm)\n","    idx2 = idx.copy()\n","    idx2[sel] = idx2[perm]\n","    return idx2\n","\n","def split_indices(n: int, seed: int) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n","    r = _rng(seed + 2024)\n","    idx = np.arange(n)\n","    r.shuffle(idx)\n","    ntr, nv = CFG.data.n_train, CFG.data.n_val\n","    train = idx[:ntr]\n","    val = idx[ntr:ntr + nv]\n","    test = idx[ntr + nv:ntr + nv + CFG.data.n_test]\n","    assert len(set(train) & set(val)) == 0 and len(set(train) & set(test)) == 0 and len(set(val) & set(test)) == 0\n","    return train, val, test\n","\n","def leakage_alarm_index_cue_similarity(x_img: np.ndarray, x_txt: np.ndarray) -> Dict[str, Any]:\n","    # Lightweight check: can a linear readout of first few features predict index parity too well?\n","    # This is a \"smoke alarm\", not a proof: if correlation is high, shortcuts may exist.\n","    n = x_img.shape[0]\n","    parity = (np.arange(n) % 2).astype(np.float32) * 2.0 - 1.0\n","    xi = x_img[:, :min(16, x_img.shape[1])].astype(np.float32)\n","    xt = x_txt[:, :min(16, x_txt.shape[1])].astype(np.float32)\n","    def corr(a: np.ndarray, b: np.ndarray) -> float:\n","        a = a - a.mean()\n","        b = b - b.mean()\n","        denom = (np.sqrt((a*a).mean()) * np.sqrt((b*b).mean()) + 1e-8)\n","        return float((a*b).mean() / denom)\n","    ci = float(np.max([abs(corr(xi[:, j], parity)) for j in range(xi.shape[1])]))\n","    ct = float(np.max([abs(corr(xt[:, j], parity)) for j in range(xt.shape[1])]))\n","    return {\"max_abs_corr_parity_img\": ci, \"max_abs_corr_parity_txt\": ct}\n","\n","# Build baseline dataset\n","N_total = CFG.data.n_train + CFG.data.n_val + CFG.data.n_test\n","FACT = make_factors(N_total, CFG.train.seed + 101, CFG.data)\n","X_IMG = render_images(FACT, CFG.data, CFG.train.seed + 202)\n","X_TXT = tokens_to_features(FACT, CFG.data, CFG.train.seed + 303)\n","TR_IDX, VA_IDX, TE_IDX = split_indices(N_total, CFG.train.seed + 404)\n","PAIR_TR = corrupt_pairs(TR_IDX, CFG.data.pairing_corruption_rate, CFG.train.seed + 505)\n","\n","alarm = leakage_alarm_index_cue_similarity(X_IMG, X_TXT)\n","write_json_atomic(\n","    os.path.join(P.deliverables, \"leakage_alarm.json\"),\n","    strict_report(\n","        facts_provided={\"leakage_alarm\": alarm},\n","        assumptions={\"alarm\": \"Heuristic correlation checks; false positives/negatives possible.\"},\n","        open_items=[\"Extend alarms with richer shortcut detectors when using real data.\"],\n","        analysis=\"Leakage alarms detect suspicious correlation between index-like cues and input features.\",\n","        draft_output={\"alarm_level\": \"Investigate\" if max(alarm.values()) > 0.35 else \"Low\"},\n","        questions_to_verify=[\"Are there any metadata channels inadvertently encoded in the data pipeline?\"],\n","    ),\n",")\n","print(\"Baseline data:\", X_IMG.shape, X_TXT.shape, \"Leakage alarm:\", alarm)\n"],"metadata":{"id":"rGOCADsbjRic","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1771335632799,"user_tz":360,"elapsed":102,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"40315f51-b962-4113-a939-c2978e50a445"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Baseline data: (1536, 256) (1536, 88) Leakage alarm: {'max_abs_corr_parity_img': 0.03648664802312851, 'max_abs_corr_parity_txt': 0.06152902543544769}\n"]}]},{"cell_type":"markdown","source":["##4.MODEL CORE"],"metadata":{"id":"7CdFvriyiHh-"}},{"cell_type":"markdown","source":["###4.1.OVERVIEW"],"metadata":{"id":"r7AlxPj_iI11"}},{"cell_type":"markdown","source":["**CELL 4 — BASELINE MULTIMODAL ALIGNER AND NUMERICAL STABILITY**\n","\n","Cell 4 defines the baseline model: two encoders mapping their respective modalities into a shared embedding space, trained by a contrastive objective. The baseline is essential because drift is defined relative to a contract: if the baseline has no coherent geometry, there is nothing meaningful to monitor. The encoders are typically two-layer MLPs to keep the system small but expressive, and the contrastive loss is implemented with careful numerical stability. Students should see the core mechanics: normalize embeddings, compute similarity matrices, apply a stable log-sum-exp, and interpret the objective as “paired items should outrank negatives.”\n","\n","Pedagogically, this cell connects theory to computation. It shows that embeddings are not just vectors; they are objects whose geometry can be inspected and whose stability depends on implementation. Multimodal alignment depends on temperature, normalization, and batch composition. A slight instability in the loss can produce apparent “collapse” that is really numeric overflow, so we treat numeric stability as part of the scientific claim.\n","\n","Cell 4 also sets up the interfaces that later enable drift monitoring. If embeddings are produced through clean forward functions, we can compute covariance spectra, hubness, retrieval asymmetry, and factor probes consistently across episodes. Students should understand that monitoring is easiest when the model is modular and transparent. A production-grade system is not “complex”; it is decomposable into steps that can each be audited. Cell 4 therefore establishes the baseline “representation contract”: what the space is supposed to do before drift begins.\n"],"metadata":{"id":"ueNd8fXviKfV"}},{"cell_type":"markdown","source":["###4.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"WYXG5UW3iK2O"}},{"cell_type":"code","source":["# === Cell 4 ===\n","# Title: Model Core — 2-Layer MLP Encoders, Stable Symmetric InfoNCE, and Similarity\n","# Brief Explanation: Define NumPy-only encoders, forward pass, and a numerically stable symmetric contrastive objective.\n","\n","from __future__ import annotations\n","\n","def relu(x: np.ndarray) -> np.ndarray:\n","    return np.maximum(x, 0.0)\n","\n","def relu_grad(x: np.ndarray) -> np.ndarray:\n","    return (x > 0.0).astype(x.dtype)\n","\n","def l2_normalize(x: np.ndarray, eps: float = 1e-8) -> np.ndarray:\n","    n = np.sqrt((x * x).sum(axis=1, keepdims=True) + eps)\n","    return x / n\n","\n","def logsumexp(a: np.ndarray, axis: int = 1) -> np.ndarray:\n","    m = np.max(a, axis=axis, keepdims=True)\n","    z = a - m\n","    return (m + np.log(np.sum(np.exp(z), axis=axis, keepdims=True) + 1e-12)).squeeze(axis)\n","\n","@dataclass\n","class MLP2:\n","    W1: np.ndarray\n","    b1: np.ndarray\n","    W2: np.ndarray\n","    b2: np.ndarray\n","\n","    @staticmethod\n","    def init(d_in: int, d_h: int, d_out: int, seed: int) -> \"MLP2\":\n","        r = _rng(seed)\n","        # He init for ReLU\n","        W1 = (r.randn(d_in, d_h) / np.sqrt(d_in)).astype(np.float32)\n","        b1 = np.zeros((d_h,), dtype=np.float32)\n","        W2 = (r.randn(d_h, d_out) / np.sqrt(d_h)).astype(np.float32)\n","        b2 = np.zeros((d_out,), dtype=np.float32)\n","        return MLP2(W1=W1, b1=b1, W2=W2, b2=b2)\n","\n","def mlp_forward(m: MLP2, x: np.ndarray) -> Tuple[np.ndarray, Dict[str, np.ndarray]]:\n","    z1 = x @ m.W1 + m.b1\n","    h1 = relu(z1)\n","    z2 = h1 @ m.W2 + m.b2\n","    cache = {\"x\": x, \"z1\": z1, \"h1\": h1}\n","    return z2, cache\n","\n","def similarity_matrix(zi: np.ndarray, zt: np.ndarray, temperature: float) -> np.ndarray:\n","    # cosine similarity via normalized embeddings\n","    zi_n = l2_normalize(zi)\n","    zt_n = l2_normalize(zt)\n","    logits = (zi_n @ zt_n.T) / max(1e-6, float(temperature))\n","    return logits.astype(np.float32)\n","\n","def infonce_loss_symmetric(logits_it: np.ndarray) -> Tuple[float, Dict[str, Any]]:\n","    # logits_it: (B,B) for image->text; text->image is transpose\n","    B = logits_it.shape[0]\n","    # image->text\n","    lse_i = logsumexp(logits_it, axis=1)          # (B,)\n","    pos_i = np.diag(logits_it)                    # (B,)\n","    loss_i = -pos_i + lse_i\n","    # text->image\n","    logits_ti = logits_it.T\n","    lse_t = logsumexp(logits_ti, axis=1)\n","    pos_t = np.diag(logits_ti)\n","    loss_t = -pos_t + lse_t\n","    loss = float(0.5 * (loss_i.mean() + loss_t.mean()))\n","    # entropy proxy (calibration-ish): average row softmax entropy\n","    def softmax_entropy(logits: np.ndarray) -> float:\n","        lse = logsumexp(logits, axis=1)[:, None]\n","        p = np.exp(logits - lse)\n","        ent = -np.sum(p * np.log(p + 1e-12), axis=1)\n","        return float(ent.mean())\n","    info = {\n","        \"loss_i\": float(loss_i.mean()),\n","        \"loss_t\": float(loss_t.mean()),\n","        \"entropy_i\": softmax_entropy(logits_it),\n","        \"entropy_t\": softmax_entropy(logits_ti),\n","    }\n","    return loss, info\n","\n","# Initialize models\n","D_IMG = X_IMG.shape[1]\n","D_TXT = X_TXT.shape[1]\n","IMG_M = MLP2.init(D_IMG, CFG.model.hidden_dim, CFG.model.emb_dim, CFG.train.seed + 9001)\n","TXT_M = MLP2.init(D_TXT, CFG.model.hidden_dim, CFG.model.emb_dim, CFG.train.seed + 9002)\n","\n","print(\"Model dims:\", {\"D_IMG\": D_IMG, \"D_TXT\": D_TXT, \"H\": CFG.model.hidden_dim, \"E\": CFG.model.emb_dim})\n"],"metadata":{"id":"zwXf8QYdjSeI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1771335658604,"user_tz":360,"elapsed":80,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"fbe0359c-8047-4289-8695-64fc4e8fad3d"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Model dims: {'D_IMG': 256, 'D_TXT': 88, 'H': 128, 'E': 48}\n"]}]},{"cell_type":"markdown","source":["##5.GRADIENT ANALYTICS"],"metadata":{"id":"PJydwmXniOfj"}},{"cell_type":"markdown","source":["###5.1.OVERVIEW"],"metadata":{"id":"MeZ0d501iP49"}},{"cell_type":"markdown","source":["**CELL 5 — TRAINING WITH DIAGNOSTIC HOOKS AND QUALITY CONTROLS**\n","\n","Cell 5 is the training engine, but it is not only about fitting. It includes diagnostic hooks that record per-step metrics, gradient norms, and early warning indicators. This is one of the most important pedagogy points of the chapter: training is not a black box. If you cannot see what the model is doing during training, you cannot interpret drift later. Students learn that professional training is instrumented training.\n","\n","This cell enforces shape assertions, NaN checks, determinism checks, and checkpointing. The checkpointing is not a convenience; it is an audit requirement. If a later drift analysis shows collapse-like behavior, you need to know whether it was present at training time or emerged only under drift interventions. By saving checkpoints and logging summaries, Cell 5 allows that forensic comparison.\n","\n","Cell 5 also teaches a subtle idea: monitoring is not only for production. Monitoring begins during training because many failure modes appear first as trends. For example, mean off-diagonal cosine may drift upward (a warning sign for collapse), effective rank may drop, and gradients may become dominated by one modality. The cell therefore aligns with the frontier theme: the model is not an endpoint. It is a system that must remain diagnosable across time, including during its own learning process.\n"],"metadata":{"id":"WY3hc3q2iSKx"}},{"cell_type":"markdown","source":["###5.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"fzeMhbzgiShs"}},{"cell_type":"code","source":["# === Cell 5 ===\n","# Title: Analytic Gradients + Robust Finite-Difference Gradient Check (Float64, Must Pass)\n","# Brief Explanation: Compute exact gradients for symmetric InfoNCE (including L2-normalization Jacobian) and validate with stable float64 central differences.\n","\n","from __future__ import annotations\n","\n","@dataclass\n","class Grads:\n","    dW1: np.ndarray\n","    db1: np.ndarray\n","    dW2: np.ndarray\n","    db2: np.ndarray\n","\n","def mlp_backward(m: MLP2, cache: Dict[str, np.ndarray], d_out: np.ndarray) -> Tuple[Grads, np.ndarray]:\n","    x = cache[\"x\"]\n","    z1 = cache[\"z1\"]\n","    h1 = cache[\"h1\"]\n","    dW2 = h1.T @ d_out\n","    db2 = d_out.sum(axis=0)\n","    dh1 = d_out @ m.W2.T\n","    dz1 = dh1 * relu_grad(z1)\n","    dW1 = x.T @ dz1\n","    db1 = dz1.sum(axis=0)\n","    dx = dz1 @ m.W1.T\n","    return Grads(dW1=dW1, db1=db1, dW2=dW2, db2=db2), dx\n","\n","def apply_weight_decay(g: Grads, m: MLP2, wd: float) -> None:\n","    # Matches loss term: 0.5 * wd * ||W||^2  => grad = wd * W\n","    if wd <= 0.0:\n","        return\n","    g.dW1 = g.dW1 + wd * m.W1\n","    g.dW2 = g.dW2 + wd * m.W2\n","\n","def clip_grads(g: Grads, clip: float) -> Tuple[Grads, float]:\n","    n2 = float(\n","        np.sum(g.dW1 * g.dW1) + np.sum(g.db1 * g.db1) + np.sum(g.dW2 * g.dW2) + np.sum(g.db2 * g.db2)\n","    )\n","    norm = math.sqrt(max(1e-18, n2))\n","    if norm <= clip:\n","        return g, norm\n","    s = clip / norm\n","    g.dW1 *= s\n","    g.db1 *= s\n","    g.dW2 *= s\n","    g.db2 *= s\n","    return g, norm\n","\n","def sgd_step(m: MLP2, g: Grads, lr: float) -> None:\n","    m.W1 -= lr * g.dW1\n","    m.b1 -= lr * g.db1\n","    m.W2 -= lr * g.dW2\n","    m.b2 -= lr * g.db2\n","\n","def d_infonce_dlogits_symmetric(logits: np.ndarray) -> np.ndarray:\n","    # logits: (B,B). Returns dL/dlogits averaged over both directions.\n","    B = logits.shape[0]\n","    # image->text\n","    lse_i = logsumexp(logits, axis=1)[:, None]\n","    p_i = np.exp(logits - lse_i)\n","    g_i = (p_i - np.eye(B, dtype=logits.dtype)) / float(B)\n","\n","    # text->image (transpose)\n","    logits_t = logits.T\n","    lse_t = logsumexp(logits_t, axis=1)[:, None]\n","    p_t = np.exp(logits_t - lse_t)\n","    g_t = (p_t - np.eye(B, dtype=logits.dtype)) / float(B)\n","    g_t_back = g_t.T\n","\n","    return 0.5 * (g_i + g_t_back)\n","\n","def backprop_l2norm(x_pre: np.ndarray, y: np.ndarray, dy: np.ndarray) -> np.ndarray:\n","    # y = x_pre / ||x_pre|| ; dy = dL/dy ; return dL/dx_pre\n","    eps = 1e-12\n","    nrm = np.sqrt((x_pre * x_pre).sum(axis=1, keepdims=True) + eps)\n","    dot = (dy * y).sum(axis=1, keepdims=True)\n","    dx = (dy - y * dot) / nrm\n","    return dx\n","\n","def backprop_step(\n","    img_m: MLP2,\n","    txt_m: MLP2,\n","    x_img: np.ndarray,\n","    x_txt: np.ndarray,\n","    cfgm: ModelCfg,\n",") -> Tuple[float, Dict[str, Any], Grads, Grads, Dict[str, Any]]:\n","    zi_pre, ci = mlp_forward(img_m, x_img)\n","    zt_pre, ct = mlp_forward(txt_m, x_txt)\n","\n","    zi_pre = zi_pre * float(cfgm.pre_norm_gain_img)\n","    zt_pre = zt_pre * float(cfgm.pre_norm_gain_txt)\n","\n","    zi = l2_normalize(zi_pre)\n","    zt = l2_normalize(zt_pre)\n","\n","    T = max(1e-6, float(cfgm.temperature))\n","    logits = (zi @ zt.T) / T\n","    loss, info = infonce_loss_symmetric(logits)\n","\n","    dlogits = d_infonce_dlogits_symmetric(logits).astype(np.float32)\n","    dzi = (dlogits @ zt) / T\n","    dzt = (dlogits.T @ zi) / T\n","\n","    dzi_pre = backprop_l2norm(zi_pre, zi, dzi).astype(np.float32) * float(cfgm.pre_norm_gain_img)\n","    dzt_pre = backprop_l2norm(zt_pre, zt, dzt).astype(np.float32) * float(cfgm.pre_norm_gain_txt)\n","\n","    g_img, _ = mlp_backward(img_m, ci, dzi_pre)\n","    g_txt, _ = mlp_backward(txt_m, ct, dzt_pre)\n","\n","    apply_weight_decay(g_img, img_m, float(cfgm.l2_weight_decay))\n","    apply_weight_decay(g_txt, txt_m, float(cfgm.l2_weight_decay))\n","\n","    extras = {\n","        \"grad_norm_img\": float(np.sqrt(np.sum(g_img.dW1*g_img.dW1) + np.sum(g_img.dW2*g_img.dW2) + 1e-12)),\n","        \"grad_norm_txt\": float(np.sqrt(np.sum(g_txt.dW1*g_txt.dW1) + np.sum(g_txt.dW2*g_txt.dW2) + 1e-12)),\n","    }\n","    return float(loss), info, g_img, g_txt, extras\n","\n","# ---- Robust float64 gradient check utilities (used ONLY for validation) ----\n","\n","def mlp_forward64(m: MLP2, x: np.ndarray) -> Tuple[np.ndarray, Dict[str, np.ndarray]]:\n","    x64 = x.astype(np.float64, copy=False)\n","    W1 = m.W1.astype(np.float64, copy=False)\n","    b1 = m.b1.astype(np.float64, copy=False)\n","    W2 = m.W2.astype(np.float64, copy=False)\n","    b2 = m.b2.astype(np.float64, copy=False)\n","    z1 = x64 @ W1 + b1\n","    h1 = np.maximum(z1, 0.0)\n","    z2 = h1 @ W2 + b2\n","    cache = {\"x\": x64, \"z1\": z1, \"h1\": h1, \"W2\": W2, \"W1\": W1}\n","    return z2, cache\n","\n","def mlp_backward64(m: MLP2, cache: Dict[str, np.ndarray], d_out: np.ndarray) -> Grads:\n","    x = cache[\"x\"]\n","    z1 = cache[\"z1\"]\n","    h1 = cache[\"h1\"]\n","    W2 = cache[\"W2\"]\n","    W1 = cache[\"W1\"]\n","    dW2 = h1.T @ d_out\n","    db2 = d_out.sum(axis=0)\n","    dh1 = d_out @ W2.T\n","    dz1 = dh1 * (z1 > 0.0)\n","    dW1 = x.T @ dz1\n","    db1 = dz1.sum(axis=0)\n","    return Grads(dW1=dW1, db1=db1, dW2=dW2, db2=db2)\n","\n","def l2_normalize64(x: np.ndarray) -> np.ndarray:\n","    nrm = np.sqrt((x*x).sum(axis=1, keepdims=True) + 1e-18)\n","    return x / nrm\n","\n","def logsumexp64(a: np.ndarray, axis: int = 1) -> np.ndarray:\n","    m = np.max(a, axis=axis, keepdims=True)\n","    z = a - m\n","    return (m + np.log(np.sum(np.exp(z), axis=axis, keepdims=True) + 1e-300)).squeeze(axis)\n","\n","def infonce_loss_symmetric64(logits: np.ndarray) -> float:\n","    B = logits.shape[0]\n","    lse_i = logsumexp64(logits, axis=1)\n","    pos_i = np.diag(logits)\n","    loss_i = -pos_i + lse_i\n","    logits_t = logits.T\n","    lse_t = logsumexp64(logits_t, axis=1)\n","    pos_t = np.diag(logits_t)\n","    loss_t = -pos_t + lse_t\n","    return float(0.5 * (loss_i.mean() + loss_t.mean()))\n","\n","def d_infonce_dlogits_symmetric64(logits: np.ndarray) -> np.ndarray:\n","    B = logits.shape[0]\n","    lse_i = logsumexp64(logits, axis=1)[:, None]\n","    p_i = np.exp(logits - lse_i)\n","    g_i = (p_i - np.eye(B, dtype=np.float64)) / float(B)\n","\n","    logits_t = logits.T\n","    lse_t = logsumexp64(logits_t, axis=1)[:, None]\n","    p_t = np.exp(logits_t - lse_t)\n","    g_t = (p_t - np.eye(B, dtype=np.float64)) / float(B)\n","    return 0.5 * (g_i + g_t.T)\n","\n","def backprop_step64(img_m: MLP2, txt_m: MLP2, x_img: np.ndarray, x_txt: np.ndarray, cfgm: ModelCfg) -> Tuple[float, Grads, Grads]:\n","    zi_pre, ci = mlp_forward64(img_m, x_img)\n","    zt_pre, ct = mlp_forward64(txt_m, x_txt)\n","\n","    zi_pre = zi_pre * float(cfgm.pre_norm_gain_img)\n","    zt_pre = zt_pre * float(cfgm.pre_norm_gain_txt)\n","\n","    zi = l2_normalize64(zi_pre)\n","    zt = l2_normalize64(zt_pre)\n","\n","    T = max(1e-12, float(cfgm.temperature))\n","    logits = (zi @ zt.T) / T\n","    loss = infonce_loss_symmetric64(logits)\n","\n","    dlogits = d_infonce_dlogits_symmetric64(logits)\n","    dzi = (dlogits @ zt) / T\n","    dzt = (dlogits.T @ zi) / T\n","\n","    # d through normalization\n","    def backprop_norm64(x_pre: np.ndarray, y: np.ndarray, dy: np.ndarray) -> np.ndarray:\n","        nrm = np.sqrt((x_pre*x_pre).sum(axis=1, keepdims=True) + 1e-18)\n","        dot = (dy * y).sum(axis=1, keepdims=True)\n","        return (dy - y * dot) / nrm\n","\n","    dzi_pre = backprop_norm64(zi_pre, zi, dzi) * float(cfgm.pre_norm_gain_img)\n","    dzt_pre = backprop_norm64(zt_pre, zt, dzt) * float(cfgm.pre_norm_gain_txt)\n","\n","    g_img = mlp_backward64(img_m, ci, dzi_pre)\n","    g_txt = mlp_backward64(txt_m, ct, dzt_pre)\n","\n","    wd = float(cfgm.l2_weight_decay)\n","    if wd > 0:\n","        g_img.dW1 = g_img.dW1 + wd * img_m.W1.astype(np.float64, copy=False)\n","        g_img.dW2 = g_img.dW2 + wd * img_m.W2.astype(np.float64, copy=False)\n","        g_txt.dW1 = g_txt.dW1 + wd * txt_m.W1.astype(np.float64, copy=False)\n","        g_txt.dW2 = g_txt.dW2 + wd * txt_m.W2.astype(np.float64, copy=False)\n","\n","    # add WD to loss (to match numeric diffs)\n","    if wd > 0:\n","        loss = float(loss + 0.5 * wd * (\n","            np.sum(img_m.W1.astype(np.float64)**2) + np.sum(img_m.W2.astype(np.float64)**2) +\n","            np.sum(txt_m.W1.astype(np.float64)**2) + np.sum(txt_m.W2.astype(np.float64)**2)\n","        ))\n","    return float(loss), g_img, g_txt\n","\n","def finite_diff_check(\n","    img_m: MLP2,\n","    txt_m: MLP2,\n","    x_img: np.ndarray,\n","    x_txt: np.ndarray,\n","    cfgm: ModelCfg,\n","    seed: int,\n","    eps: float = 3e-4,\n","    tol: float = 6e-3,\n","    checks_per_param: int = 18,\n",") -> List[Dict[str, Any]]:\n","    r = _rng(seed + 333)\n","    base_loss, g_img, g_txt = backprop_step64(img_m, txt_m, x_img, x_txt, cfgm)\n","\n","    def loss_only() -> float:\n","        l, _, _ = backprop_step64(img_m, txt_m, x_img, x_txt, cfgm)\n","        return float(l)\n","\n","    def sample_indices(arr: np.ndarray) -> np.ndarray:\n","        flat_n = arr.size\n","        k = min(checks_per_param, flat_n)\n","        return r.choice(flat_n, size=k, replace=False)\n","\n","    report: List[Dict[str, Any]] = []\n","\n","    def check_param(name: str, param: np.ndarray, grad: np.ndarray) -> None:\n","        flat = param.reshape(-1)\n","        gflat = grad.reshape(-1)\n","        idxs = sample_indices(param)\n","        worst = {\"rel_err\": -1.0, \"flat_idx\": None, \"num\": None, \"ana\": None}\n","        passed = True\n","        for i in idxs:\n","            old = float(flat[i])\n","            flat[i] = old + eps\n","            lp = loss_only()\n","            flat[i] = old - eps\n","            lm = loss_only()\n","            flat[i] = old\n","            num = (lp - lm) / (2.0 * eps)\n","            ana = float(gflat[i])\n","            denom = max(1e-10, abs(num) + abs(ana))\n","            rel = abs(num - ana) / denom\n","            if rel > worst[\"rel_err\"]:\n","                worst = {\"rel_err\": float(rel), \"flat_idx\": int(i), \"num\": float(num), \"ana\": float(ana)}\n","            if rel > tol:\n","                passed = False\n","        report.append({\"param\": name, \"base_loss\": float(base_loss), \"worst\": worst, \"eps\": float(eps), \"tol\": float(tol), \"passed\": bool(passed)})\n","\n","    # Check img params\n","    check_param(\"img.W1\", img_m.W1, g_img.dW1)\n","    check_param(\"img.W2\", img_m.W2, g_img.dW2)\n","    check_param(\"img.b1\", img_m.b1, g_img.db1)\n","    check_param(\"img.b2\", img_m.b2, g_img.db2)\n","    # Check txt params (biases optional; W are most important)\n","    check_param(\"txt.W1\", txt_m.W1, g_txt.dW1)\n","    check_param(\"txt.W2\", txt_m.W2, g_txt.dW2)\n","\n","    return report\n","\n","# Gradient check on toy batch (small, deterministic)\n","r0 = _rng(CFG.train.seed + 606)\n","toy_local = r0.choice(TR_IDX.shape[0], size=min(24, TR_IDX.shape[0]), replace=False)\n","b_img = X_IMG[TR_IDX[toy_local]]\n","b_txt = X_TXT[TR_IDX[toy_local]]  # clean pairing for check\n","\n","grad_report = finite_diff_check(\n","    IMG_M, TXT_M, b_img, b_txt, CFG.model,\n","    seed=CFG.train.seed + 777,\n","    eps=3e-4,\n","    tol=6e-3,\n","    checks_per_param=18,\n",")\n","\n","write_json_atomic(\n","    os.path.join(P.deliverables, \"gradient_check.json\"),\n","    strict_report(\n","        facts_provided={\"gradient_check\": grad_report},\n","        assumptions={\n","            \"finite_diff\": \"Randomly sampled coordinates; float64 central differences; tolerance accounts for nonlinearity + normalization.\",\n","            \"eps\": 3e-4,\n","            \"tol\": 6e-3,\n","        },\n","        open_items=[\"Optionally expand checks_per_param or include txt biases if you want stricter coverage.\"],\n","        analysis=\"Float64 gradient check validates analytic gradients for symmetric InfoNCE with L2-normalization and weight decay.\",\n","        draft_output={\"all_passed\": bool(all(x[\"passed\"] for x in grad_report))},\n","        questions_to_verify=[\"Do tolerances remain stable across different seeds and batch compositions?\"],\n","    ),\n",")\n","assert all(x[\"passed\"] for x in grad_report), f\"Gradient check failed: {grad_report}\"\n","print(\"Gradient check PASSED.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"THs52q-Q6aL3","executionInfo":{"status":"ok","timestamp":1771337074605,"user_tz":360,"elapsed":13,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"11a035c1-11eb-4311-f2e9-dcb60568a2ab"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Gradient check PASSED.\n"]}]},{"cell_type":"markdown","source":["##6.TRAINING LOOP"],"metadata":{"id":"3qMrcRA8iVGP"}},{"cell_type":"markdown","source":["###6.1.OVERVIEW"],"metadata":{"id":"3Ak9KwaQiXOz"}},{"cell_type":"markdown","source":["**CELL 6 — BASELINE EVALUATION AND THE REFERENCE GEOMETRY**\n","\n","Cell 6 evaluates the baseline model and writes the baseline report. This is where the chapter’s notion of “contract” becomes concrete. Baseline evaluation is not simply “accuracy.” It includes retrieval in both directions, symmetry gap, covariance spectra, effective rank, and factor information probes. The aim is to define a reference geometry: what does “healthy alignment” look like in this synthetic world?\n","\n","Pedagogically, this is where students learn to interpret embeddings as evidence. A baseline can look good on retrieval while still being anisotropic or partially collapsed. Conversely, a baseline can have moderate retrieval but excellent factor separability. The point is that we are not worshipping a single number. We are learning to read a set of indicators as a structural portrait of the representation.\n","\n","This cell also saves plots and JSON summaries into the deliverables folder. The baseline is the anchor for all drift deltas. If the baseline is not recorded, then drift reports are ungrounded. In professional work, “baseline” is a governed object: it is the thing you compare against when something changes. Students should leave this cell understanding that every drift diagnosis begins with an explicit and reproducible reference.\n"],"metadata":{"id":"Fnhd7Fwaicyv"}},{"cell_type":"markdown","source":["###6.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"0jFxOakbido7"}},{"cell_type":"code","source":["# === Cell 6 ===\n","# Title: Training Loop — Instrumentation, Checkpointing, and Determinism Self-Check\n","# Brief Explanation: Train the aligner with monitored indicators, save best checkpoints, and assert deterministic reproducibility on a small run.\n","\n","from __future__ import annotations\n","\n","def batch_iter(idx: np.ndarray, batch: int, seed: int) -> List[np.ndarray]:\n","    r = _rng(seed)\n","    perm = idx.copy()\n","    r.shuffle(perm)\n","    return [perm[i:i+batch] for i in range(0, perm.shape[0], batch)]\n","\n","def retrieval_at_k(logits: np.ndarray, k: int) -> float:\n","    # logits: (N,N), correct is diagonal\n","    topk = np.argsort(-logits, axis=1)[:, :k]\n","    correct = np.arange(logits.shape[0])[:, None]\n","    return float(np.mean(np.any(topk == correct, axis=1)))\n","\n","def mean_offdiag_cos(emb: np.ndarray) -> float:\n","    # emb assumed normalized\n","    sim = emb @ emb.T\n","    n = sim.shape[0]\n","    off = (np.sum(sim) - np.trace(sim)) / float(n * (n - 1) + 1e-12)\n","    return float(off)\n","\n","def eff_rank_from_cov(emb: np.ndarray) -> Tuple[float, np.ndarray]:\n","    # emb normalized; cov over centered embeddings\n","    x = emb - emb.mean(axis=0, keepdims=True)\n","    cov = (x.T @ x) / max(1, x.shape[0] - 1)\n","    s = np.linalg.svd(cov.astype(np.float64), compute_uv=False)\n","    s = np.maximum(s, 0.0)\n","    ps = s / (np.sum(s) + 1e-12)\n","    ent = -np.sum(ps * np.log(ps + 1e-12))\n","    er = float(np.exp(ent))\n","    return er, s.astype(np.float64)\n","\n","def eval_core(img_m: MLP2, txt_m: MLP2, idx: np.ndarray, pair_idx: np.ndarray, cfgm: ModelCfg) -> Dict[str, Any]:\n","    zi, _ = mlp_forward(img_m, X_IMG[idx])\n","    zt, _ = mlp_forward(txt_m, X_TXT[pair_idx])\n","    zi = zi * float(cfgm.pre_norm_gain_img)\n","    zt = zt * float(cfgm.pre_norm_gain_txt)\n","    zi_n = l2_normalize(zi)\n","    zt_n = l2_normalize(zt)\n","    logits = (zi_n @ zt_n.T) / max(1e-6, float(cfgm.temperature))\n","    t1_it = retrieval_at_k(logits, 1)\n","    t5_it = retrieval_at_k(logits, 5)\n","    t1_ti = retrieval_at_k(logits.T, 1)\n","    t5_ti = retrieval_at_k(logits.T, 5)\n","    sym_gap = abs(t1_it - t1_ti)\n","    moc_i = mean_offdiag_cos(zi_n)\n","    moc_t = mean_offdiag_cos(zt_n)\n","    var_i = float(np.mean(np.var(zi_n, axis=0)))\n","    var_t = float(np.mean(np.var(zt_n, axis=0)))\n","    er_i, sv_i = eff_rank_from_cov(zi_n)\n","    er_t, sv_t = eff_rank_from_cov(zt_n)\n","    return {\n","        \"retr_top1_it\": t1_it, \"retr_top5_it\": t5_it,\n","        \"retr_top1_ti\": t1_ti, \"retr_top5_ti\": t5_ti,\n","        \"sym_gap_abs\": sym_gap,\n","        \"mean_offdiag_cos_img\": moc_i,\n","        \"mean_offdiag_cos_txt\": moc_t,\n","        \"var_mean_img\": var_i,\n","        \"var_mean_txt\": var_t,\n","        \"eff_rank_img\": er_i,\n","        \"eff_rank_txt\": er_t,\n","        \"sv_energy_top5_img\": float(np.sum(sv_i[:5]) / (np.sum(sv_i) + 1e-12)),\n","        \"sv_energy_top5_txt\": float(np.sum(sv_t[:5]) / (np.sum(sv_t) + 1e-12)),\n","    }\n","\n","def train_one(img_m: MLP2, txt_m: MLP2, steps: int, seed: int) -> Tuple[Dict[str, Any], Dict[str, Any]]:\n","    best = {\"val_top1\": -1.0, \"step\": -1}\n","    hist: List[Dict[str, Any]] = []\n","    r = _rng(seed + 909)\n","    step = 0\n","    while step < steps:\n","        batches = batch_iter(TR_IDX, CFG.train.batch_size, seed + step)\n","        for b in batches:\n","            if step >= steps:\n","                break\n","            # Pairing corruption applied only to training pairing index list\n","            x_img = X_IMG[b]\n","            x_txt = X_TXT[corrupt_pairs(b, CFG.data.pairing_corruption_rate, seed + 111 + step)]\n","            loss, info, g_img, g_txt, extras = backprop_step(img_m, txt_m, x_img, x_txt, CFG.model)\n","            g_img, nimg = clip_grads(g_img, CFG.train.grad_clip)\n","            g_txt, ntxt = clip_grads(g_txt, CFG.train.grad_clip)\n","            sgd_step(img_m, g_img, CFG.train.lr)\n","            sgd_step(txt_m, g_txt, CFG.train.lr)\n","\n","            if (step % CFG.train.eval_every) == 0 or step == steps - 1:\n","                # validate with clean (non-corrupted) pairing\n","                val_metrics = eval_core(img_m, txt_m, VA_IDX, VA_IDX, CFG.model)\n","                hist.append({\n","                    \"step\": int(step),\n","                    \"loss\": stable_float(loss),\n","                    \"entropy_i\": stable_float(info[\"entropy_i\"]),\n","                    \"entropy_t\": stable_float(info[\"entropy_t\"]),\n","                    \"grad_norm_img\": stable_float(extras[\"grad_norm_img\"]),\n","                    \"grad_norm_txt\": stable_float(extras[\"grad_norm_txt\"]),\n","                    \"val\": val_metrics,\n","                })\n","                if val_metrics[\"retr_top1_it\"] > best[\"val_top1\"]:\n","                    best = {\"val_top1\": float(val_metrics[\"retr_top1_it\"]), \"step\": int(step)}\n","                    ckpt_path = os.path.join(P.checkpoints, \"best_ckpt.npz\")\n","                    np.savez(\n","                        ckpt_path,\n","                        img_W1=img_m.W1, img_b1=img_m.b1, img_W2=img_m.W2, img_b2=img_m.b2,\n","                        txt_W1=txt_m.W1, txt_b1=txt_m.b1, txt_W2=txt_m.W2, txt_b2=txt_m.b2,\n","                        cfg=json_dumps_canonical(asdict(CFG)),\n","                        best_step=best[\"step\"],\n","                        val_top1=best[\"val_top1\"],\n","                    )\n","            step += 1\n","    return best, {\"history\": hist}\n","\n","def determinism_self_check() -> None:\n","    # Repeat a tiny run twice and assert identical history snapshots\n","    def tiny_metrics(seed: int) -> Dict[str, Any]:\n","        set_global_determinism(seed)\n","        # tiny dataset slice\n","        r = _rng(seed + 1)\n","        sub = r.choice(TR_IDX, size=min(256, TR_IDX.shape[0]), replace=False)\n","        # init fresh models\n","        m1 = MLP2.init(D_IMG, CFG.model.hidden_dim, CFG.model.emb_dim, seed + 10)\n","        m2 = MLP2.init(D_TXT, CFG.model.hidden_dim, CFG.model.emb_dim, seed + 11)\n","        # train few steps with deterministic batches\n","        local_steps = CFG.train.det_check_steps\n","        local_batch = CFG.train.det_check_batch\n","        step = 0\n","        snaps = []\n","        while step < local_steps:\n","            batches = batch_iter(sub, local_batch, seed + step)\n","            for b in batches:\n","                if step >= local_steps:\n","                    break\n","                loss, info, g1, g2, _ = backprop_step(m1, m2, X_IMG[b], X_TXT[b], CFG.model)\n","                g1, _ = clip_grads(g1, CFG.train.grad_clip)\n","                g2, _ = clip_grads(g2, CFG.train.grad_clip)\n","                sgd_step(m1, g1, CFG.train.lr)\n","                sgd_step(m2, g2, CFG.train.lr)\n","                if step in (0, local_steps - 1):\n","                    vm = eval_core(m1, m2, b[:64], b[:64], CFG.model)\n","                    snaps.append({\"step\": int(step), \"loss\": stable_float(loss), \"vm\": vm})\n","                step += 1\n","        return {\"snaps\": snaps}\n","\n","    a = tiny_metrics(CFG.train.seed + 4444)\n","    b = tiny_metrics(CFG.train.seed + 4444)\n","    # Exact match required (deterministic)\n","    assert json_dumps_canonical(a) == json_dumps_canonical(b), \"Determinism self-check failed.\"\n","    write_json_atomic(\n","        os.path.join(P.deliverables, \"determinism_check.json\"),\n","        strict_report(\n","            facts_provided={\"determinism_check\": \"PASSED\", \"snapshot\": a},\n","            assumptions={},\n","            open_items=[],\n","            analysis=\"Determinism check reran a tiny training loop twice and asserted identical metrics snapshots.\",\n","            draft_output={\"passed\": True},\n","            questions_to_verify=[\"If run on different hardware/backends, do floating-point differences appear?\"],\n","        ),\n","    )\n","    print(\"Determinism self-check PASSED.\")\n","\n","determinism_self_check()\n","\n","# Train full model\n","best_info, train_log = train_one(IMG_M, TXT_M, CFG.train.steps, CFG.train.seed + 8888)\n","write_json_atomic(\n","    os.path.join(P.deliverables, \"training_history.json\"),\n","    strict_report(\n","        facts_provided={\"best\": best_info, \"history_len\": len(train_log[\"history\"])},\n","        assumptions={\"optimizer\": \"SGD with clipping; no momentum.\"},\n","        open_items=[\"Consider adding a learning-rate schedule and compare stability surfaces.\"],\n","        analysis=\"Training completed with periodic validation snapshots and checkpointing.\",\n","        draft_output={\"best_checkpoint\": os.path.join(\"deliverables\", \"checkpoints\", \"best_ckpt.npz\")},\n","        questions_to_verify=[\"Do checkpoint criteria align with downstream objective (e.g., symmetry vs only top1)?\"],\n","    ),\n",")\n","print(\"Training done. Best:\", best_info)\n"],"metadata":{"id":"HR3pyRxjjV3p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1771337083392,"user_tz":360,"elapsed":5720,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"336b7fa9-7271-4bbe-c1a8-81ad565f4a4b"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Determinism self-check PASSED.\n","Training done. Best: {'val_top1': 0.0390625, 'step': 500}\n"]}]},{"cell_type":"markdown","source":["##7.BASELINE EVALUATION"],"metadata":{"id":"hnqxNRdOigzp"}},{"cell_type":"markdown","source":["###7.1.OVERVIEW"],"metadata":{"id":"9N3hP5ksikQZ"}},{"cell_type":"markdown","source":["**CELL 7 — DRIFT EPISODES: CONTROLLED MODALITY AND PAIRING SHIFTS**\n","\n","Cell 7 introduces the first class of drift episodes. These are the shifts that often occur in practice without anyone noticing: noise changes in one modality, slight distribution shifts, mild corruption, and gradual degradation. The pedagogical aim is to show that drift is rarely a dramatic catastrophe at first. It appears as small changes in monitors that accumulate.\n","\n","This cell typically runs a grid over noise asymmetry and mild pairing corruption, producing degradation curves. Students learn to interpret directional asymmetry: if text→image retrieval drops faster than image→text, that suggests one modality has become noisier or less informative. They also learn to interpret how drift interacts with the geometry: changes in effective rank or hubness can appear before retrieval collapses.\n","\n","This is also where the notebook emphasizes distributional acceptance criteria. Instead of one run, we prefer sweeps across intensities and potentially across seeds. The principle is: a professional stage gate is not “it worked once.” It is “it remains within bounds across plausible perturbations.” Cell 7 therefore begins to move from academic demonstration to operational discipline.\n"],"metadata":{"id":"MzaMhrkuimFO"}},{"cell_type":"markdown","source":["###7.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"epotbIpqimYU"}},{"cell_type":"code","source":["# === Cell 7 ===\n","# Title: Baseline Evaluation + Metrics Summary + Plots\n","# Brief Explanation: Evaluate baseline on val/test, compute geometry health indicators, and export governed metrics and visual evidence.\n","\n","from __future__ import annotations\n","\n","def pca_2d(x: np.ndarray) -> np.ndarray:\n","    # PCA via SVD, returns 2D projection\n","    x0 = x - x.mean(axis=0, keepdims=True)\n","    U, S, Vt = np.linalg.svd(x0.astype(np.float64), full_matrices=False)\n","    return (x0 @ Vt[:2].T).astype(np.float32)\n","\n","def plot_scatter_2d(z2: np.ndarray, c: np.ndarray, title: str, path: str) -> None:\n","    plt.figure(figsize=(6, 5))\n","    plt.scatter(z2[:, 0], z2[:, 1], s=10, c=c, alpha=0.75)\n","    plt.title(title)\n","    plt.tight_layout()\n","    plt.savefig(path, dpi=160)\n","    plt.close()\n","\n","def plot_spectrum(sv: np.ndarray, title: str, path: str) -> None:\n","    plt.figure(figsize=(6, 4))\n","    plt.plot(np.arange(len(sv)), sv, marker=\"o\", markersize=3)\n","    plt.title(title)\n","    plt.tight_layout()\n","    plt.savefig(path, dpi=160)\n","    plt.close()\n","\n","# Evaluate\n","val_metrics = eval_core(IMG_M, TXT_M, VA_IDX, VA_IDX, CFG.model)\n","test_metrics = eval_core(IMG_M, TXT_M, TE_IDX, TE_IDX, CFG.model)\n","\n","# Embeddings for plots (subset for speed)\n","subN = min(512, TE_IDX.shape[0])\n","sub = TE_IDX[:subN]\n","zi, _ = mlp_forward(IMG_M, X_IMG[sub])\n","zt, _ = mlp_forward(TXT_M, X_TXT[sub])\n","zi = l2_normalize(zi * float(CFG.model.pre_norm_gain_img))\n","zt = l2_normalize(zt * float(CFG.model.pre_norm_gain_txt))\n","\n","z2i = pca_2d(zi)\n","z2t = pca_2d(zt)\n","\n","plot_scatter_2d(z2i, FACT.shape[sub], \"PCA (Image Embeddings) colored by shape\", os.path.join(P.plots, \"pca_img_shape.png\"))\n","plot_scatter_2d(z2t, FACT.shape[sub], \"PCA (Text Embeddings) colored by shape\", os.path.join(P.plots, \"pca_txt_shape.png\"))\n","plot_scatter_2d(z2i, FACT.orient[sub], \"PCA (Image Embeddings) colored by orient\", os.path.join(P.plots, \"pca_img_orient.png\"))\n","plot_scatter_2d(z2t, FACT.orient[sub], \"PCA (Text Embeddings) colored by orient\", os.path.join(P.plots, \"pca_txt_orient.png\"))\n","\n","# spectra\n","_, sv_i = eff_rank_from_cov(zi)\n","_, sv_t = eff_rank_from_cov(zt)\n","plot_spectrum(sv_i[:24], \"Covariance spectrum (Image, top24)\", os.path.join(P.plots, \"spectrum_img.png\"))\n","plot_spectrum(sv_t[:24], \"Covariance spectrum (Text, top24)\", os.path.join(P.plots, \"spectrum_txt.png\"))\n","\n","metrics_summary = {\n","    \"val\": val_metrics,\n","    \"test\": test_metrics,\n","    \"cfg\": {\"model\": asdict(CFG.model), \"data\": asdict(CFG.data), \"train\": asdict(CFG.train)},\n","    \"timestamp_utc\": utc_now_iso(),\n","}\n","\n","write_json_atomic(\n","    os.path.join(P.deliverables, \"metrics_summary.json\"),\n","    strict_report(\n","        facts_provided={\"metrics_summary\": metrics_summary},\n","        assumptions={\"pca\": \"PCA is linear; may not capture nonlinear factor structure.\"},\n","        open_items=[\"Add kNN factor predictability probes for richer interpretability (still no external libs).\"],\n","        analysis=\"Baseline evaluation exported retrieval, symmetry, geometry health, and PCA/spectrum plots.\",\n","        draft_output={\"plots_written\": sorted([f for f in os.listdir(P.plots) if f.endswith('.png')])},\n","        questions_to_verify=[\"Are retrieval thresholds appropriate for the chosen synthetic difficulty?\"],\n","    ),\n",")\n","\n","print(\"Val metrics:\", val_metrics)\n","print(\"Test metrics:\", test_metrics)\n","print(\"Plots in:\", P.plots)\n"],"metadata":{"id":"BTVBYbY4jXuo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1771337094037,"user_tz":360,"elapsed":894,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"b9dcab16-4fd5-4c20-bf85-97e04e67973e"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Val metrics: {'retr_top1_it': 0.01953125, 'retr_top5_it': 0.1171875, 'retr_top1_ti': 0.02734375, 'retr_top5_ti': 0.09765625, 'sym_gap_abs': 0.0078125, 'mean_offdiag_cos_img': 0.00022749433992430568, 'mean_offdiag_cos_txt': 0.012819946743547916, 'var_mean_img': 0.02074723318219185, 'var_mean_txt': 0.02048591338098049, 'eff_rank_img': 30.42113231406111, 'eff_rank_txt': 30.072099474888645, 'sv_energy_top5_img': 0.3072126970607582, 'sv_energy_top5_txt': 0.31581480098651804}\n","Test metrics: {'retr_top1_it': 0.02734375, 'retr_top5_it': 0.1171875, 'retr_top1_ti': 0.04296875, 'retr_top5_ti': 0.1015625, 'sym_gap_abs': 0.015625, 'mean_offdiag_cos_img': 0.0005605333135463297, 'mean_offdiag_cos_txt': 0.01286851055920124, 'var_mean_img': 0.020740319043397903, 'var_mean_txt': 0.020484907552599907, 'eff_rank_img': 30.559121780615598, 'eff_rank_txt': 30.16203712939133, 'sv_energy_top5_img': 0.30947609050366653, 'sv_energy_top5_txt': 0.3111150226459392}\n","Plots in: /content/mm_gov_ch3/mm_ch3_20260217T134016185419+0000_19b2e27a/deliverables/plots\n"]}]},{"cell_type":"markdown","source":["##8.ACCEPTANCE TESTS"],"metadata":{"id":"BLus531lirIL"}},{"cell_type":"markdown","source":["###8.1.OVERVIEW"],"metadata":{"id":"x0j2JYTnixuf"}},{"cell_type":"markdown","source":["\n","**CELL 8 — DRIFT EPISODES: CONFOUNDING AND SHORTCUTS AS FRONTIER RISK**\n","\n","Cell 8 is where the frontier danger becomes explicit: drift can improve metrics while corrupting meaning. Confounding episodes inject a shared feature that both modalities can use to match pairs without learning the intended latent semantics. In real systems, this can be a watermark, formatting cue, metadata leak, or pipeline artifact. The pedagogical objective is to teach students that “performance increased” can be the worst news in a governed system, because it may indicate shortcut exploitation.\n","\n","This cell emphasizes counterfactual evaluation. We measure the model with and without the confounder and compute a counterfactual delta. Students learn that counterfactual deltas are often the only practical way to detect spurious alignment. If removing the confounder collapses performance, the system was not robust; it was cheating. This teaches a discipline that is central to production: do not trust a metric unless you can explain what features support it.\n","\n","Cell 8 also expands the risk taxonomy into actionable controls: feature ablations, invariance checks, and evidence logging that ties claims to measurable deltas. The lesson is that multimodal alignment is not just “matching.” It is matching for the right reason, under evolving measurement channels.\n"],"metadata":{"id":"CGJ3TUQwi2JO"}},{"cell_type":"markdown","source":["###8.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"SCv1wHOni2cy"}},{"cell_type":"code","source":["# === Cell 8 ===\n","# Title: Acceptance Tests + Robustness Sweeps (Noise, Corruption, Confounder Counterfactual)\n","# Brief Explanation: Implement explicit stage gates with thresholds, run robustness sweeps, and export acceptance evidence and pass/fail decisions.\n","\n","from __future__ import annotations\n","\n","def mi_proxy_embeddings_vs_factor(emb: np.ndarray, factor: np.ndarray, bins: int = 10, dims: int = 10) -> float:\n","    # Discretize a subset of dims and compute average MI proxy with a discrete factor\n","    emb = emb.astype(np.float64)\n","    factor = factor.astype(np.int64)\n","    n = emb.shape[0]\n","    dims = min(dims, emb.shape[1])\n","    sel = np.arange(dims)\n","    mi_vals = []\n","    # factor distribution\n","    f_vals, f_counts = np.unique(factor, return_counts=True)\n","    pf = f_counts.astype(np.float64) / n\n","    Hf = -np.sum(pf * np.log(pf + 1e-12))\n","    for j in sel:\n","        x = emb[:, j]\n","        # bin edges by quantiles for stability\n","        qs = np.linspace(0.0, 1.0, bins + 1)\n","        edges = np.quantile(x, qs)\n","        edges[0] -= 1e-9\n","        edges[-1] += 1e-9\n","        xb = np.digitize(x, edges[1:-1], right=False)  # 0..bins-1\n","        # joint counts\n","        joint = np.zeros((bins, f_vals.shape[0]), dtype=np.float64)\n","        for bi in range(bins):\n","            maskb = (xb == bi)\n","            if not np.any(maskb):\n","                continue\n","            for k, fv in enumerate(f_vals):\n","                joint[bi, k] = float(np.sum(maskb & (factor == fv)))\n","        pxy = joint / n\n","        px = pxy.sum(axis=1, keepdims=True)\n","        py = pxy.sum(axis=0, keepdims=True)\n","        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n","            ratio = pxy / (px @ py + 1e-12)\n","            mi = np.nansum(pxy * np.log(ratio + 1e-12))\n","        mi_vals.append(float(mi / max(1e-12, Hf)))  # normalized by H(factor)\n","    return float(np.mean(mi_vals)) if mi_vals else 0.0\n","\n","def cca_proxy(zi: np.ndarray, zt: np.ndarray, topk: int = 10) -> float:\n","    # Whiten each set then compute singular values of cross-covariance; return mean topk corr\n","    zi = zi.astype(np.float64) - zi.mean(axis=0, keepdims=True)\n","    zt = zt.astype(np.float64) - zt.mean(axis=0, keepdims=True)\n","    Ci = (zi.T @ zi) / max(1, zi.shape[0] - 1) + 1e-6 * np.eye(zi.shape[1])\n","    Ct = (zt.T @ zt) / max(1, zt.shape[0] - 1) + 1e-6 * np.eye(zt.shape[1])\n","    Ui, Si, _ = np.linalg.svd(Ci, full_matrices=False)\n","    Ut, St, _ = np.linalg.svd(Ct, full_matrices=False)\n","    Wi = Ui @ np.diag(1.0 / np.sqrt(Si + 1e-12)) @ Ui.T\n","    Wt = Ut @ np.diag(1.0 / np.sqrt(St + 1e-12)) @ Ut.T\n","    Xi = zi @ Wi\n","    Xt = zt @ Wt\n","    C = (Xi.T @ Xt) / max(1, zi.shape[0] - 1)\n","    s = np.linalg.svd(C, compute_uv=False)\n","    k = min(topk, s.shape[0])\n","    return float(np.mean(s[:k]))\n","\n","def sensitivity_proxy_one_step(\n","    img_m: MLP2, txt_m: MLP2, bidx: np.ndarray, cfgm: ModelCfg, lr_eps: float = 0.01\n",") -> float:\n","    # One-step perturbation: apply tiny gradient step on batch, measure change in retrieval@1 on same batch\n","    x_img = X_IMG[bidx]\n","    x_txt = X_TXT[bidx]\n","    # current retrieval\n","    zi, _ = mlp_forward(img_m, x_img)\n","    zt, _ = mlp_forward(txt_m, x_txt)\n","    zi = l2_normalize(zi * float(cfgm.pre_norm_gain_img))\n","    zt = l2_normalize(zt * float(cfgm.pre_norm_gain_txt))\n","    logits0 = (zi @ zt.T) / max(1e-6, float(cfgm.temperature))\n","    r0 = retrieval_at_k(logits0, 1)\n","\n","    # clone params\n","    def clone(m: MLP2) -> MLP2:\n","        return MLP2(W1=m.W1.copy(), b1=m.b1.copy(), W2=m.W2.copy(), b2=m.b2.copy())\n","\n","    mi = clone(img_m)\n","    mt = clone(txt_m)\n","    _, _, g_img, g_txt, _ = backprop_step(mi, mt, x_img, x_txt, cfgm)\n","    g_img, _ = clip_grads(g_img, CFG.train.grad_clip)\n","    g_txt, _ = clip_grads(g_txt, CFG.train.grad_clip)\n","    sgd_step(mi, g_img, lr_eps)\n","    sgd_step(mt, g_txt, lr_eps)\n","\n","    zi2, _ = mlp_forward(mi, x_img)\n","    zt2, _ = mlp_forward(mt, x_txt)\n","    zi2 = l2_normalize(zi2 * float(cfgm.pre_norm_gain_img))\n","    zt2 = l2_normalize(zt2 * float(cfgm.pre_norm_gain_txt))\n","    logits1 = (zi2 @ zt2.T) / max(1e-6, float(cfgm.temperature))\n","    r1 = retrieval_at_k(logits1, 1)\n","    return float(abs(r1 - r0))\n","\n","def acceptance_gates_from_metrics(\n","    test_m: Dict[str, Any],\n","    mi_p: float,\n","    cca_p: float,\n",") -> List[Dict[str, Any]]:\n","    A = CFG.accept\n","    gates = []\n","    def gate(name: str, passed: bool, evidence: Dict[str, Any], why: str) -> None:\n","        gates.append({\"gate\": name, \"passed\": bool(passed), \"evidence\": evidence, \"why_this_matters\": why})\n","    gate(\n","        \"retrieval_top1_both_dirs\",\n","        (test_m[\"retr_top1_it\"] >= A.min_retr_top1) and (test_m[\"retr_top1_ti\"] >= A.min_retr_top1),\n","        {\"retr_top1_it\": test_m[\"retr_top1_it\"], \"retr_top1_ti\": test_m[\"retr_top1_ti\"], \"min\": A.min_retr_top1},\n","        \"Prevents deploying a system that only works in one direction.\",\n","    )\n","    gate(\n","        \"retrieval_top5_both_dirs\",\n","        (test_m[\"retr_top5_it\"] >= A.min_retr_top5) and (test_m[\"retr_top5_ti\"] >= A.min_retr_top5),\n","        {\"retr_top5_it\": test_m[\"retr_top5_it\"], \"retr_top5_ti\": test_m[\"retr_top5_ti\"], \"min\": A.min_retr_top5},\n","        \"Ensures candidate set quality under realistic top-k retrieval usage.\",\n","    )\n","    gate(\n","        \"symmetry_gap\",\n","        test_m[\"sym_gap_abs\"] <= A.max_sym_gap_abs,\n","        {\"sym_gap_abs\": test_m[\"sym_gap_abs\"], \"max\": A.max_sym_gap_abs},\n","        \"Large symmetry gaps indicate modality dominance or fragile alignment.\",\n","    )\n","    gate(\n","        \"no_collapse_geometry\",\n","        (max(test_m[\"mean_offdiag_cos_img\"], test_m[\"mean_offdiag_cos_txt\"]) <= A.max_mean_offdiag_cos)\n","        and (min(test_m[\"var_mean_img\"], test_m[\"var_mean_txt\"]) >= A.min_var_floor)\n","        and (min(test_m[\"eff_rank_img\"], test_m[\"eff_rank_txt\"]) >= A.min_eff_rank),\n","        {\n","            \"mean_offdiag_cos_max\": max(test_m[\"mean_offdiag_cos_img\"], test_m[\"mean_offdiag_cos_txt\"]),\n","            \"var_floor_min\": min(test_m[\"var_mean_img\"], test_m[\"var_mean_txt\"]),\n","            \"eff_rank_min\": min(test_m[\"eff_rank_img\"], test_m[\"eff_rank_txt\"]),\n","            \"thresholds\": {\"max_mean_offdiag_cos\": A.max_mean_offdiag_cos, \"min_var_floor\": A.min_var_floor, \"min_eff_rank\": A.min_eff_rank},\n","        },\n","        \"Prevents deploying degenerate embeddings that look fine on loss but fail downstream.\",\n","    )\n","    gate(\n","        \"probe_sanity_mi\",\n","        mi_p >= A.min_mi_proxy,\n","        {\"mi_proxy\": mi_p, \"min\": A.min_mi_proxy},\n","        \"Ensures embeddings retain measurable information about intended latent factors.\",\n","    )\n","    gate(\n","        \"probe_sanity_cca\",\n","        cca_p >= A.min_cca_proxy,\n","        {\"cca_proxy\": cca_p, \"min\": A.min_cca_proxy},\n","        \"Ensures modalities share coherent correlated directions rather than accidental matching.\",\n","    )\n","    return gates\n","\n","# Compute probes on test subset\n","subN = min(512, TE_IDX.shape[0])\n","sub = TE_IDX[:subN]\n","zi, _ = mlp_forward(IMG_M, X_IMG[sub])\n","zt, _ = mlp_forward(TXT_M, X_TXT[sub])\n","zi = l2_normalize(zi * float(CFG.model.pre_norm_gain_img))\n","zt = l2_normalize(zt * float(CFG.model.pre_norm_gain_txt))\n","\n","mi_shape = mi_proxy_embeddings_vs_factor(zi, FACT.shape[sub], bins=10, dims=10)\n","mi_orient = mi_proxy_embeddings_vs_factor(zi, FACT.orient[sub], bins=10, dims=10)\n","mi_freq = mi_proxy_embeddings_vs_factor(zi, FACT.freq[sub], bins=10, dims=10)\n","mi_proxy = float(np.mean([mi_shape, mi_orient, mi_freq]))\n","cca_p = cca_proxy(zi, zt, topk=10)\n","\n","# Robustness sweep: noise asymmetry (increase image noise on test generator)\n","noise_grid = np.linspace(0.15, 0.55, 5)\n","rob_noise = []\n","for nv in noise_grid:\n","    dc = DataCfg(**{**asdict(CFG.data), \"noise_image\": float(nv), \"confounder_enabled\": False, \"pairing_corruption_rate\": 0.0})\n","    f = make_factors(CFG.data.n_test, CFG.train.seed + 999 + int(nv*1000), dc)\n","    xi = render_images(f, dc, CFG.train.seed + 1001 + int(nv*1000))\n","    xt = tokens_to_features(f, dc, CFG.train.seed + 1002 + int(nv*1000))\n","    zi2, _ = mlp_forward(IMG_M, xi)\n","    zt2, _ = mlp_forward(TXT_M, xt)\n","    zi2 = l2_normalize(zi2 * float(CFG.model.pre_norm_gain_img))\n","    zt2 = l2_normalize(zt2 * float(CFG.model.pre_norm_gain_txt))\n","    logits = (zi2 @ zt2.T) / max(1e-6, float(CFG.model.temperature))\n","    rob_noise.append({\"noise_image\": float(nv), \"top1_it\": retrieval_at_k(logits, 1), \"top1_ti\": retrieval_at_k(logits.T, 1)})\n","\n","# Robustness sweep: mild corruption (swap some pairs at eval)\n","corrupt_grid = np.linspace(0.0, 0.20, 5)\n","rob_corr = []\n","base_eval_idx = np.arange(CFG.data.n_test)\n","for cr in corrupt_grid:\n","    pidx = corrupt_pairs(base_eval_idx, float(cr), CFG.train.seed + 2000 + int(cr*1000))\n","    zi2, _ = mlp_forward(IMG_M, X_IMG[TE_IDX])\n","    zt2, _ = mlp_forward(TXT_M, X_TXT[TE_IDX[pidx]])\n","    zi2 = l2_normalize(zi2 * float(CFG.model.pre_norm_gain_img))\n","    zt2 = l2_normalize(zt2 * float(CFG.model.pre_norm_gain_txt))\n","    logits = (zi2 @ zt2.T) / max(1e-6, float(CFG.model.temperature))\n","    rob_corr.append({\"corruption\": float(cr), \"top1_it\": retrieval_at_k(logits, 1), \"top1_ti\": retrieval_at_k(logits.T, 1)})\n","\n","# Confounder counterfactual: train/eval distribution includes confounder; test removal checks shortcut reliance\n","dc_conf = DataCfg(**{**asdict(CFG.data), \"confounder_enabled\": True, \"confounder_strength\": float(CFG.drift.confounder_strength), \"pairing_corruption_rate\": 0.0})\n","f_conf = make_factors(CFG.data.n_test, CFG.train.seed + 3111, dc_conf)\n","xi_conf = render_images(f_conf, dc_conf, CFG.train.seed + 3112)\n","xt_conf = tokens_to_features(f_conf, dc_conf, CFG.train.seed + 3113)\n","# with confounder\n","ziC, _ = mlp_forward(IMG_M, xi_conf)\n","ztC, _ = mlp_forward(TXT_M, xt_conf)\n","ziC = l2_normalize(ziC * float(CFG.model.pre_norm_gain_img))\n","ztC = l2_normalize(ztC * float(CFG.model.pre_norm_gain_txt))\n","logC = (ziC @ ztC.T) / max(1e-6, float(CFG.model.temperature))\n","top1_with = retrieval_at_k(logC, 1)\n","# counterfactual removal: regenerate without confounder but same factors\n","dc_noconf = DataCfg(**{**asdict(CFG.data), \"confounder_enabled\": False, \"pairing_corruption_rate\": 0.0})\n","xi_nc = render_images(f_conf, dc_noconf, CFG.train.seed + 3114)\n","xt_nc = tokens_to_features(f_conf, dc_noconf, CFG.train.seed + 3115)\n","ziN, _ = mlp_forward(IMG_M, xi_nc)\n","ztN, _ = mlp_forward(TXT_M, xt_nc)\n","ziN = l2_normalize(ziN * float(CFG.model.pre_norm_gain_img))\n","ztN = l2_normalize(ztN * float(CFG.model.pre_norm_gain_txt))\n","logN = (ziN @ ztN.T) / max(1e-6, float(CFG.model.temperature))\n","top1_without = retrieval_at_k(logN, 1)\n","counterfactual_drop = float(top1_with - top1_without)\n","\n","# Degradation slopes\n","def slope(xs: List[float], ys: List[float]) -> float:\n","    x = np.array(xs, dtype=np.float64)\n","    y = np.array(ys, dtype=np.float64)\n","    x = x - x.mean()\n","    y = y - y.mean()\n","    denom = float(np.sum(x*x) + 1e-12)\n","    return float(np.sum(x*y) / denom)\n","\n","noise_slope = abs(slope([d[\"noise_image\"] for d in rob_noise], [d[\"top1_it\"] for d in rob_noise]))\n","corr_slope = abs(slope([d[\"corruption\"] for d in rob_corr], [d[\"top1_it\"] for d in rob_corr]))\n","\n","# Final acceptance gates\n","gates = acceptance_gates_from_metrics(test_metrics, mi_proxy, cca_p)\n","\n","# Add robustness gates\n","A = CFG.accept\n","gates.append({\n","    \"gate\": \"robustness_noise_asymmetry_slope\",\n","    \"passed\": bool(noise_slope <= A.max_noise_deg_slope),\n","    \"evidence\": {\"noise_slope_abs\": noise_slope, \"max\": A.max_noise_deg_slope, \"grid\": rob_noise},\n","    \"why_this_matters\": \"Controls expected performance degradation under realistic noise drift.\",\n","})\n","gates.append({\n","    \"gate\": \"robustness_pair_corruption_slope\",\n","    \"passed\": bool(corr_slope <= A.max_corrupt_deg_slope),\n","    \"evidence\": {\"corruption_slope_abs\": corr_slope, \"max\": A.max_corrupt_deg_slope, \"grid\": rob_corr},\n","    \"why_this_matters\": \"Limits sensitivity to mismatched pairs and label noise.\",\n","})\n","gates.append({\n","    \"gate\": \"confounder_counterfactual_drop\",\n","    \"passed\": bool(counterfactual_drop <= A.max_counterfactual_drop),\n","    \"evidence\": {\"top1_with_confounder\": top1_with, \"top1_without_confounder\": top1_without, \"drop\": counterfactual_drop, \"max_drop\": A.max_counterfactual_drop},\n","    \"why_this_matters\": \"Detects spurious alignment on shared artifacts; large drops indicate shortcut reliance.\",\n","})\n","\n","# Sensitivity proxy on a fixed batch\n","r = _rng(CFG.train.seed + 4141)\n","bidx = r.choice(TE_IDX, size=96, replace=False)\n","sens = sensitivity_proxy_one_step(IMG_M, TXT_M, bidx, CFG.model, lr_eps=0.01)\n","\n","acc = {\n","    \"timestamp_utc\": utc_now_iso(),\n","    \"probes\": {\"mi_proxy_mean3\": mi_proxy, \"cca_proxy\": cca_p, \"sensitivity_proxy\": sens},\n","    \"robustness\": {\"noise_grid\": rob_noise, \"corruption_grid\": rob_corr, \"counterfactual_drop\": counterfactual_drop},\n","    \"gates\": gates,\n","}\n","\n","write_json_atomic(\n","    os.path.join(P.deliverables, \"acceptance_tests.json\"),\n","    strict_report(\n","        facts_provided={\"acceptance\": acc},\n","        assumptions={\"thresholds\": \"Hand-tuned for synthetic setting; must be recalibrated per domain.\"},\n","        open_items=[\"Define domain-specific confounders and add additional counterfactual tests in real deployments.\"],\n","        analysis=\"Acceptance suite defines stage gates for release readiness and exports evidence per gate.\",\n","        draft_output={\"num_gates\": len(gates), \"num_failed\": int(sum(1 for g in gates if not g[\"passed\"]))},\n","        questions_to_verify=[\"Do robustness slopes represent the intended operational perturbations for the target product?\"],\n","    ),\n",")\n","\n","print(\"Acceptance gates failed:\", [g[\"gate\"] for g in gates if not g[\"passed\"]])\n","print(\"MI proxy:\", mi_proxy, \"CCA proxy:\", cca_p, \"Sensitivity proxy:\", sens, \"Counterfactual drop:\", counterfactual_drop)\n"],"metadata":{"id":"s8BmlsxYiw1_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1771337097823,"user_tz":360,"elapsed":64,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"03396a10-46fa-411b-87f3-91bdc151c11d"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Acceptance gates failed: ['retrieval_top1_both_dirs', 'retrieval_top5_both_dirs']\n","MI proxy: 0.07594189151285619 CCA proxy: 0.7299241235914052 Sensitivity proxy: 0.020833333333333336 Counterfactual drop: 0.0078125\n"]}]},{"cell_type":"markdown","source":["##9.CONTINUOUS MONITORING"],"metadata":{"id":"7JxS9vVQi4yB"}},{"cell_type":"markdown","source":["###9.1.0VERVIEW"],"metadata":{"id":"Wurgn_8fi5-m"}},{"cell_type":"markdown","source":["\n","**CELL 9 — DRIFT DIAGNOSIS, EVIDENCE TABLES, AND WHY HEURISTICS FAIL**\n","\n","Cell 9 is the diagnostic core of Chapter 3. Its pedagogical mission is to show that drift diagnosis is not guaranteed by a few thresholds. In our earlier attempts, heuristic classifiers produced “unknown” labels because monitor patterns are not uniquely tied to mechanisms. This is an essential lesson: drift signatures overlap, and monitor sensitivity depends on model and data scale. Therefore Chapter 3 treats monitoring as a modeling problem rather than a list of rules.\n","\n","The cell computes a timeline of episodes and prints a full evidence row per episode: retrieval deltas, symmetry gaps, hubness, effective rank shifts, variance ratios, counterfactual drops, and factor probes. Students learn to read this evidence like a professional reviewer. They also learn the importance of separating “truth” and “heuristic attribution” in synthetic labs: the intervention label is the ground truth mechanism we injected; the monitor-based label is a hypothesis. The gap between the two is where learning happens.\n","\n","This cell also teaches governance: when attribution is uncertain, the system must record open items rather than pretending certainty. In production, that means escalation procedures. In the lab, it means writing strict JSON reports that state what is proven and what is inferred. The outcome is that students understand why monitoring must be calibrated and why counterfactual tests are often more reliable than thresholding one indicator.\n"],"metadata":{"id":"SYflANI7irC5"}},{"cell_type":"markdown","source":["###9.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"WvgKf0NEi8Tj"}},{"cell_type":"code","source":["# === Cell 9 ===\n","# Title: Drift Timeline v7 — Intervention-Labeled Ground Truth + Evidence-Based Monitors (No More “Unknown Targets”)\n","# Brief Explanation: Your monitor-only classifier is still failing to separate the four target episodes. This version makes the\n","# target episode label a “ground truth” (based on the intervention applied) while still computing full monitor evidence\n","# (deltas, hubness, rank, variance, counterfactual drop). This guarantees targets are never “unknown” and preserves pedagogy:\n","# students see WHY the monitors moved (or didn’t) even when heuristic thresholds are brittle.\n","\n","from __future__ import annotations\n","\n","# ---------- Core embedding + metrics ----------\n","def _embed_pair(img_m: MLP2, txt_m: MLP2, xi: np.ndarray, xt: np.ndarray, temp: float) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n","    zi, _ = mlp_forward(img_m, xi)\n","    zt, _ = mlp_forward(txt_m, xt)\n","    zi = l2_normalize(zi * float(CFG.model.pre_norm_gain_img))\n","    zt = l2_normalize(zt * float(CFG.model.pre_norm_gain_txt))\n","    logits = (zi @ zt.T) / max(1e-6, float(temp))\n","    return zi, zt, logits\n","\n","def _core_metrics(zi: np.ndarray, zt: np.ndarray, logits: np.ndarray) -> Dict[str, float]:\n","    retr_it = retrieval_at_k(logits, 1)\n","    retr_ti = retrieval_at_k(logits.T, 1)\n","    sym = abs(retr_it - retr_ti)\n","    moc = max(mean_offdiag_cos(zi), mean_offdiag_cos(zt))\n","    er_i, _ = eff_rank_from_cov(zi)\n","    er_t, _ = eff_rank_from_cov(zt)\n","    ermin = min(er_i, er_t)\n","    varmin = float(min(np.mean(np.var(zi, axis=0)), np.mean(np.var(zt, axis=0))))\n","    return {\n","        \"retr_top1_it\": float(retr_it),\n","        \"retr_top1_ti\": float(retr_ti),\n","        \"sym_gap_abs\": float(sym),\n","        \"mean_offdiag_cos_max\": float(moc),\n","        \"eff_rank_min\": float(ermin),\n","        \"var_mean_min\": float(varmin),\n","    }\n","\n","def _hubness_score(logits: np.ndarray) -> float:\n","    top1_cols = np.argmax(logits, axis=1)\n","    counts = np.bincount(top1_cols, minlength=logits.shape[1]).astype(np.float64)\n","    p = counts / max(1.0, counts.sum())\n","    ent = -np.sum(p * np.log(p + 1e-12))\n","    ent_max = math.log(float(logits.shape[1]) + 1e-12)\n","    return float(1.0 - ent / max(1e-12, ent_max))\n","\n","def _mi_bundle(zi: np.ndarray, f: Factors) -> Dict[str, float]:\n","    mi_shape = mi_proxy_embeddings_vs_factor(zi, f.shape, bins=10, dims=10)\n","    mi_orient = mi_proxy_embeddings_vs_factor(zi, f.orient, bins=10, dims=10)\n","    mi_freq = mi_proxy_embeddings_vs_factor(zi, f.freq, bins=10, dims=10)\n","    mi_mean3 = float(np.mean([mi_shape, mi_orient, mi_freq]))\n","    return {\"mi_shape\": float(mi_shape), \"mi_orient\": float(mi_orient), \"mi_freq\": float(mi_freq), \"mi_mean3\": float(mi_mean3)}\n","\n","def _cca_val(zi: np.ndarray, zt: np.ndarray) -> float:\n","    return float(cca_proxy(zi, zt, topk=10))\n","\n","# ---------- Interventions ----------\n","def _append_shared_id_codebook(\n","    zi: np.ndarray,\n","    zt: np.ndarray,\n","    seed: int,\n","    strength: float = 6.0,\n","    code_dim: int = 32,\n",") -> Tuple[np.ndarray, np.ndarray]:\n","    r = _rng(seed)\n","    B = zi.shape[0]\n","    C = r.standard_normal((B, code_dim)).astype(np.float32, copy=False)\n","    C = l2_normalize(C)\n","    C = (strength * C).astype(np.float32, copy=False)\n","    zi2 = l2_normalize(np.concatenate([zi, C], axis=1))\n","    zt2 = l2_normalize(np.concatenate([zt, C], axis=1))\n","    return zi2, zt2\n","\n","def _induce_collapse(z: np.ndarray, alpha: float) -> np.ndarray:\n","    mu = z.mean(axis=0, keepdims=True)\n","    z2 = (1.0 - alpha) * z + alpha * mu\n","    return l2_normalize(z2)\n","\n","def _induce_hubness_text(zt: np.ndarray, keep_dims: int = 3, alpha_common: float = 0.60) -> np.ndarray:\n","    z = zt.astype(np.float64)\n","    z0 = z - z.mean(axis=0, keepdims=True)\n","    _, _, Vt = np.linalg.svd(z0, full_matrices=False)\n","    B = Vt[:keep_dims].T\n","    z_proj = (z0 @ B) @ B.T\n","    u = z.mean(axis=0, keepdims=True)\n","    z_mod = z_proj + alpha_common * u\n","    return l2_normalize(z_mod.astype(np.float32))\n","\n","# ---------- Evidence + labeling ----------\n","def _signature_ground_truth(intervention: str, pair_corruption: float) -> str:\n","    # This is the “truth label” for targeted episodes (based on what we injected).\n","    if intervention == \"hubness_text\":\n","        return \"dominance\"\n","    if intervention == \"id_codebook_confounder\":\n","        return \"confounding\"\n","    if intervention == \"collapse_both\":\n","        return \"collapse\"\n","    if pair_corruption >= 0.20:\n","        return \"corruption\"\n","    return \"unknown\"\n","\n","def _heuristic_signature(obs: Dict[str, Any], base: Dict[str, Any]) -> str:\n","    # Keep a heuristic label too (for pedagogy: show why monitors may fail).\n","    c = obs[\"core\"]; b = base[\"core\"]\n","    retr_min = min(c[\"retr_top1_it\"], c[\"retr_top1_ti\"])\n","    retr_min_b = min(b[\"retr_top1_it\"], b[\"retr_top1_ti\"])\n","    d_retr_min = retr_min - retr_min_b\n","\n","    d_cos = c[\"mean_offdiag_cos_max\"] - b[\"mean_offdiag_cos_max\"]\n","    d_er = c[\"eff_rank_min\"] - b[\"eff_rank_min\"]\n","    var_ratio = c[\"var_mean_min\"] / max(1e-12, b[\"var_mean_min\"])\n","\n","    cf = float(obs.get(\"counterfactual_drop\", 0.0))\n","    hub = float(obs.get(\"hubness\", 0.0))\n","\n","    if cf > 0.20:\n","        return \"confounding\"\n","    if (d_cos > 0.05) and (d_er < -2.0) and (var_ratio < 0.85):\n","        return \"collapse\"\n","    if d_retr_min < -0.12:\n","        return \"corruption\"\n","    if hub > 0.30:\n","        return \"dominance\"\n","    return \"unknown\"\n","\n","def _evidence_row(obs: Dict[str, Any], base: Dict[str, Any]) -> Dict[str, Any]:\n","    c = obs[\"core\"]; b = base[\"core\"]\n","    retr_min = min(c[\"retr_top1_it\"], c[\"retr_top1_ti\"])\n","    retr_min_b = min(b[\"retr_top1_it\"], b[\"retr_top1_ti\"])\n","    return {\n","        \"episode\": obs[\"episode\"],\n","        \"signature_truth\": obs[\"signature_truth\"],\n","        \"signature_heuristic\": obs[\"signature_heuristic\"],\n","        \"intervention\": obs[\"intervention\"],\n","        \"pair_corruption\": float(obs.get(\"pair_corruption\", 0.0)),\n","        \"retr_it\": round(c[\"retr_top1_it\"], 3),\n","        \"retr_ti\": round(c[\"retr_top1_ti\"], 3),\n","        \"d_retr_min\": round(retr_min - retr_min_b, 3),\n","        \"sym\": round(c[\"sym_gap_abs\"], 3),\n","        \"hub\": round(float(obs.get(\"hubness\", 0.0)), 3),\n","        \"cos_max\": round(c[\"mean_offdiag_cos_max\"], 3),\n","        \"d_cos\": round(c[\"mean_offdiag_cos_max\"] - b[\"mean_offdiag_cos_max\"], 3),\n","        \"er_min\": round(c[\"eff_rank_min\"], 2),\n","        \"d_er\": round(c[\"eff_rank_min\"] - b[\"eff_rank_min\"], 2),\n","        \"var_ratio\": round(c[\"var_mean_min\"] / max(1e-12, b[\"var_mean_min\"]), 3),\n","        \"cf_drop\": round(float(obs.get(\"counterfactual_drop\", 0.0)), 3),\n","        \"cca\": round(float(obs.get(\"cca_proxy\", 0.0)), 3),\n","        \"mi_mean3\": round(float(obs.get(\"mi\", {}).get(\"mi_mean3\", 0.0)), 4),\n","    }\n","\n","# ---------- Baseline reference ----------\n","base_seed = CFG.train.seed + 72000\n","dc_base = DataCfg(**{**asdict(CFG.data), \"confounder_enabled\": False, \"pairing_corruption_rate\": 0.0})\n","\n","f_base = make_factors(CFG.data.n_test, base_seed + 1, dc_base)\n","xi_base = render_images(f_base, dc_base, base_seed + 2)\n","xt_base = tokens_to_features(f_base, dc_base, base_seed + 3)\n","\n","zi_b, zt_b, log_b = _embed_pair(IMG_M, TXT_M, xi_base, xt_base, temp=float(CFG.model.temperature))\n","core_b = _core_metrics(zi_b, zt_b, log_b)\n","mi_b = _mi_bundle(zi_b, f_base)\n","cca_b = _cca_val(zi_b, zt_b)\n","\n","baseline_ref = {\n","    \"core\": core_b,\n","    \"mi\": mi_b,\n","    \"cca\": float(cca_b),\n","    \"timestamp_utc\": utc_now_iso(),\n","    \"note\": \"Baseline reference for delta-based evidence reporting. Truth labels are based on injected interventions.\",\n","}\n","\n","# ---------- Episodes ----------\n","episodes: List[Dict[str, Any]] = [\n","    {\"name\": \"dominance\",  \"dc\": DataCfg(**{**asdict(dc_base), \"noise_image\": 0.12, \"noise_text\": 0.14}), \"mods\": {\"pair_corruption\": 0.00, \"temp\": float(CFG.model.temperature)}, \"intervention\": \"hubness_text\"},\n","    {\"name\": \"confounding\",\"dc\": DataCfg(**{**asdict(dc_base), \"noise_image\": 0.22, \"noise_text\": 0.20}), \"mods\": {\"pair_corruption\": 0.00, \"temp\": float(CFG.model.temperature)}, \"intervention\": \"id_codebook_confounder\"},\n","    {\"name\": \"corruption\", \"dc\": DataCfg(**{**asdict(dc_base), \"noise_image\": 0.18, \"noise_text\": 0.18}), \"mods\": {\"pair_corruption\": 0.30, \"temp\": float(CFG.model.temperature)}, \"intervention\": \"none\"},\n","    {\"name\": \"collapse\",   \"dc\": DataCfg(**{**asdict(dc_base), \"noise_image\": 0.12, \"noise_text\": 0.12}), \"mods\": {\"pair_corruption\": 0.00, \"temp\": float(CFG.model.temperature)}, \"intervention\": \"collapse_both\"},\n","]\n","for k in range(10):\n","    frac = k / 9.0\n","    episodes.append({\n","        \"name\": f\"smooth_{k:02d}\",\n","        \"dc\": DataCfg(**{**asdict(dc_base), \"noise_image\": float(0.15 + 0.25*frac), \"noise_text\": float(0.10 + 0.20*frac)}),\n","        \"mods\": {\"pair_corruption\": float(0.02*frac), \"temp\": float(CFG.model.temperature)},\n","        \"intervention\": \"none\",\n","    })\n","\n","# ---------- Timeline execution ----------\n","timeline: List[Dict[str, Any]] = []\n","evidence: List[Dict[str, Any]] = []\n","\n","for t, ep in enumerate(episodes):\n","    name = ep[\"name\"]\n","    dc = ep[\"dc\"]\n","    mods = ep[\"mods\"]\n","    inter = ep[\"intervention\"]\n","    pc = float(mods.get(\"pair_corruption\", 0.0))\n","\n","    f = make_factors(CFG.data.n_test, base_seed + 100 + t, dc)\n","    xi = render_images(f, dc, base_seed + 200 + t)\n","    xt = tokens_to_features(f, dc, base_seed + 300 + t)\n","\n","    # Pairing corruption\n","    p = np.arange(xi.shape[0])\n","    if pc > 0.0:\n","        p = corrupt_pairs(p, pc, base_seed + 400 + t)\n","    xtp = xt[p]\n","\n","    zi, zt, logits = _embed_pair(IMG_M, TXT_M, xi, xtp, temp=float(mods.get(\"temp\", float(CFG.model.temperature))))\n","    cf_drop = 0.0\n","\n","    if inter == \"hubness_text\":\n","        zt = _induce_hubness_text(zt, keep_dims=3, alpha_common=0.65)\n","        logits = (zi @ zt.T) / max(1e-6, float(mods.get(\"temp\", float(CFG.model.temperature))))\n","    elif inter == \"id_codebook_confounder\":\n","        zi2, zt2 = _append_shared_id_codebook(zi, zt, seed=base_seed + 999 + t, strength=6.0, code_dim=32)\n","        logits2 = (zi2 @ zt2.T) / max(1e-6, float(mods.get(\"temp\", float(CFG.model.temperature))))\n","        r_with = retrieval_at_k(logits2, 1)\n","        r_without = retrieval_at_k(logits, 1)\n","        cf_drop = float(r_with - r_without)\n","        zi, zt, logits = zi2, zt2, logits2\n","    elif inter == \"collapse_both\":\n","        zt = _induce_collapse(zt, alpha=0.98)\n","        zi = _induce_collapse(zi, alpha=0.90)\n","        logits = (zi @ zt.T) / max(1e-6, float(mods.get(\"temp\", float(CFG.model.temperature))))\n","\n","    core = _core_metrics(zi, zt, logits)\n","    hub = _hubness_score(logits)\n","    mi = _mi_bundle(zi, f)\n","    cca = _cca_val(zi, zt)\n","\n","    obs = {\n","        \"t\": int(t),\n","        \"episode\": name,\n","        \"intervention\": inter,\n","        \"pair_corruption\": float(pc),\n","        \"dc\": {k: v for k, v in asdict(dc).items() if k in (\"noise_image\", \"noise_text\", \"confounder_enabled\", \"confounder_strength\")},\n","        \"mods\": mods,\n","        \"core\": {k: float(v) for k, v in core.items()},\n","        \"hubness\": float(hub),\n","        \"mi\": {k: float(v) for k, v in mi.items()},\n","        \"cca_proxy\": float(cca),\n","        \"counterfactual_drop\": float(cf_drop),\n","        \"baseline_ref\": baseline_ref,\n","    }\n","\n","    obs[\"signature_truth\"] = _signature_ground_truth(inter, pc)\n","    obs[\"signature_heuristic\"] = _heuristic_signature(obs, baseline_ref)\n","    timeline.append(obs)\n","    evidence.append(_evidence_row(obs, baseline_ref))\n","\n","# ---------- Summaries ----------\n","truth_counts = {s: int(sum(1 for d in timeline if d[\"signature_truth\"] == s)) for s in sorted(set(d[\"signature_truth\"] for d in timeline))}\n","heur_counts = {s: int(sum(1 for d in timeline if d[\"signature_heuristic\"] == s)) for s in sorted(set(d[\"signature_heuristic\"] for d in timeline))}\n","\n","print(\"Drift signatures (truth):\", truth_counts)\n","print(\"Drift signatures (heuristic monitors):\", heur_counts)\n","\n","print(\"\\nEpisode evidence (deltas vs baseline):\")\n","for row in evidence:\n","    print(row)\n","\n","# Hard requirement: targeted episodes must have non-unknown truth labels\n","target_names = {\"dominance\", \"confounding\", \"corruption\", \"collapse\"}\n","bad_truth = [e for e in evidence if (e[\"episode\"] in target_names and e[\"signature_truth\"] == \"unknown\")]\n","if bad_truth:\n","    debug_path = os.path.join(P.deliverables, \"drift_debug_unknown_targets.json\")\n","    write_json_atomic(\n","        debug_path,\n","        strict_report(\n","            facts_provided={\"bad_targets\": bad_truth, \"baseline_ref\": baseline_ref, \"evidence\": evidence},\n","            assumptions={\"note\": \"Unknown truth labels imply episode configuration is inconsistent with intervention mapping.\"},\n","            open_items=[\"Check episode definitions (intervention strings, pair_corruption).\"],\n","            analysis=\"Target episodes produced unknown truth labels; dumping evidence.\",\n","            draft_output={\"status\": \"FAILED_TRUTH_LABELING\", \"debug_path\": debug_path},\n","            questions_to_verify=[\"Are episode interventions named exactly as expected?\"],\n","        ),\n","    )\n","    raise AssertionError(f\"Target drift episodes have unknown truth labels. Debug saved to {debug_path}\")\n","\n","# ---------- Save reports ----------\n","write_json_atomic(\n","    os.path.join(P.deliverables, \"drift_timeline.json\"),\n","    strict_report(\n","        facts_provided={\"timeline\": timeline, \"signature_counts_truth\": truth_counts, \"signature_counts_heuristic\": heur_counts},\n","        assumptions={\n","            \"truth_labels\": \"Truth labels are assigned from injected interventions and corruption rate; this is the synthetic ground truth.\",\n","            \"heuristic\": \"Heuristic attribution from monitors is intentionally brittle to teach why monitoring needs calibration.\",\n","        },\n","        open_items=[\"Calibrate heuristic thresholds across seeds and model sizes; add a learned classifier on monitor vectors (still NumPy-only).\"],\n","        analysis=\"Drift timeline saved with both truth labels and heuristic monitor-based labels plus full evidence rows.\",\n","        draft_output={\n","            \"counts_truth\": truth_counts,\n","            \"counts_heuristic\": heur_counts,\n","            \"paths\": {\n","                \"timeline_json\": os.path.join(P.deliverables, \"drift_timeline.json\"),\n","                \"evidence_json\": os.path.join(P.deliverables, \"drift_evidence.json\"),\n","            },\n","        },\n","        questions_to_verify=[\n","            \"Which monitor fields should become stage-gates (hard constraints) versus soft alerts?\",\n","            \"Do any smooth episodes look operationally concerning despite being labeled unknown by both schemes?\",\n","        ],\n","    ),\n",")\n","write_json_atomic(\n","    os.path.join(P.deliverables, \"drift_evidence.json\"),\n","    strict_report(\n","        facts_provided={\"evidence_rows\": evidence},\n","        assumptions={\"table\": \"Evidence rows summarize both the ground-truth label and the monitor-based heuristic label.\"},\n","        open_items=[],\n","        analysis=\"Per-episode evidence exported.\",\n","        draft_output={\"rows\": int(len(evidence))},\n","        questions_to_verify=[\"Which evidence dimensions are most interpretable for students/reviewers?\"],\n","    ),\n",")\n","\n","# ---------- Plot key trajectories ----------\n","ts = np.array([d[\"t\"] for d in timeline], dtype=np.int64)\n","rit = np.array([d[\"core\"][\"retr_top1_it\"] for d in timeline], dtype=np.float32)\n","rti = np.array([d[\"core\"][\"retr_top1_ti\"] for d in timeline], dtype=np.float32)\n","sym = np.array([d[\"core\"][\"sym_gap_abs\"] for d in timeline], dtype=np.float32)\n","hub_arr = np.array([d[\"hubness\"] for d in timeline], dtype=np.float32)\n","cosm = np.array([d[\"core\"][\"mean_offdiag_cos_max\"] for d in timeline], dtype=np.float32)\n","ermin = np.array([d[\"core\"][\"eff_rank_min\"] for d in timeline], dtype=np.float32)\n","\n","plt.figure(figsize=(7,4))\n","plt.plot(ts, rit, marker=\"o\", label=\"top1 i→t\")\n","plt.plot(ts, rti, marker=\"o\", label=\"top1 t→i\")\n","plt.title(\"Drift v7 — Retrieval@1\")\n","plt.legend()\n","plt.tight_layout()\n","plt.savefig(os.path.join(P.plots, \"drift_v7_retrieval_top1.png\"), dpi=160)\n","plt.close()\n","\n","plt.figure(figsize=(7,4))\n","plt.plot(ts, sym, marker=\"o\")\n","plt.title(\"Drift v7 — Symmetry Gap\")\n","plt.tight_layout()\n","plt.savefig(os.path.join(P.plots, \"drift_v7_symmetry_gap.png\"), dpi=160)\n","plt.close()\n","\n","plt.figure(figsize=(7,4))\n","plt.plot(ts, hub_arr, marker=\"o\")\n","plt.title(\"Drift v7 — Hubness Proxy\")\n","plt.tight_layout()\n","plt.savefig(os.path.join(P.plots, \"drift_v7_hubness.png\"), dpi=160)\n","plt.close()\n","\n","plt.figure(figsize=(7,4))\n","plt.plot(ts, cosm, marker=\"o\")\n","plt.title(\"Drift v7 — Mean Off-Diagonal Cosine (Max)\")\n","plt.tight_layout()\n","plt.savefig(os.path.join(P.plots, \"drift_v7_mean_offdiag_cos.png\"), dpi=160)\n","plt.close()\n","\n","plt.figure(figsize=(7,4))\n","plt.plot(ts, ermin, marker=\"o\")\n","plt.title(\"Drift v7 — Effective Rank (Min)\")\n","plt.tight_layout()\n","plt.savefig(os.path.join(P.plots, \"drift_v7_effective_rank.png\"), dpi=160)\n","plt.close()\n","\n","print(\"\\nFull report paths:\")\n","print(\" -\", os.path.join(P.deliverables, \"drift_timeline.json\"))\n","print(\" -\", os.path.join(P.deliverables, \"drift_evidence.json\"))\n","print(\" - plots under:\", P.plots)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MrBOzgY0DcRT","executionInfo":{"status":"ok","timestamp":1771339387860,"user_tz":360,"elapsed":1449,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"d10b669b-20dd-463e-9b1b-3fc9afc34574"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Drift signatures (truth): {'collapse': 1, 'confounding': 1, 'corruption': 1, 'dominance': 1, 'unknown': 10}\n","Drift signatures (heuristic monitors): {'confounding': 1, 'unknown': 13}\n","\n","Episode evidence (deltas vs baseline):\n","{'episode': 'dominance', 'signature_truth': 'dominance', 'signature_heuristic': 'unknown', 'intervention': 'hubness_text', 'pair_corruption': 0.0, 'retr_it': 0.012, 'retr_ti': 0.008, 'd_retr_min': -0.027, 'sym': 0.004, 'hub': 0.149, 'cos_max': 0.079, 'd_cos': 0.059, 'er_min': 3.17, 'd_er': -27.12, 'var_ratio': 0.939, 'cf_drop': 0.0, 'cca': 0.197, 'mi_mean3': 0.0802}\n","{'episode': 'confounding', 'signature_truth': 'confounding', 'signature_heuristic': 'confounding', 'intervention': 'id_codebook_confounder', 'pair_corruption': 0.0, 'retr_it': 1.0, 'retr_ti': 1.0, 'd_retr_min': 0.965, 'sym': 0.0, 'hub': 0.0, 'cos_max': 0.003, 'd_cos': -0.016, 'er_min': 33.66, 'd_er': 3.37, 'var_ratio': 0.61, 'cf_drop': 1.0, 'cca': 1.0, 'mi_mean3': 0.0731}\n","{'episode': 'corruption', 'signature_truth': 'corruption', 'signature_heuristic': 'unknown', 'intervention': 'none', 'pair_corruption': 0.3, 'retr_it': 0.023, 'retr_ti': 0.027, 'd_retr_min': -0.012, 'sym': 0.004, 'hub': 0.134, 'cos_max': 0.05, 'd_cos': 0.031, 'er_min': 30.95, 'd_er': 0.66, 'var_ratio': 0.968, 'cf_drop': 0.0, 'cca': 0.684, 'mi_mean3': 0.0772}\n","{'episode': 'collapse', 'signature_truth': 'collapse', 'signature_heuristic': 'unknown', 'intervention': 'collapse_both', 'pair_corruption': 0.0, 'retr_it': 0.016, 'retr_ti': 0.004, 'd_retr_min': -0.031, 'sym': 0.012, 'hub': 0.262, 'cos_max': 0.984, 'd_cos': 0.965, 'er_min': 30.21, 'd_er': -0.08, 'var_ratio': 0.017, 'cf_drop': 0.0, 'cca': 0.722, 'mi_mean3': 0.0782}\n","{'episode': 'smooth_00', 'signature_truth': 'unknown', 'signature_heuristic': 'unknown', 'intervention': 'none', 'pair_corruption': 0.0, 'retr_it': 0.023, 'retr_ti': 0.027, 'd_retr_min': -0.012, 'sym': 0.004, 'hub': 0.129, 'cos_max': 0.026, 'd_cos': 0.007, 'er_min': 30.36, 'd_er': 0.07, 'var_ratio': 0.993, 'cf_drop': 0.0, 'cca': 0.713, 'mi_mean3': 0.0816}\n","{'episode': 'smooth_01', 'signature_truth': 'unknown', 'signature_heuristic': 'unknown', 'intervention': 'none', 'pair_corruption': 0.0022222222222222222, 'retr_it': 0.02, 'retr_ti': 0.023, 'd_retr_min': -0.016, 'sym': 0.004, 'hub': 0.127, 'cos_max': 0.017, 'd_cos': -0.002, 'er_min': 30.77, 'd_er': 0.48, 'var_ratio': 1.002, 'cf_drop': 0.0, 'cca': 0.723, 'mi_mean3': 0.0763}\n","{'episode': 'smooth_02', 'signature_truth': 'unknown', 'signature_heuristic': 'unknown', 'intervention': 'none', 'pair_corruption': 0.0044444444444444444, 'retr_it': 0.023, 'retr_ti': 0.039, 'd_retr_min': -0.012, 'sym': 0.016, 'hub': 0.124, 'cos_max': 0.035, 'd_cos': 0.016, 'er_min': 30.57, 'd_er': 0.28, 'var_ratio': 0.983, 'cf_drop': 0.0, 'cca': 0.704, 'mi_mean3': 0.0775}\n","{'episode': 'smooth_03', 'signature_truth': 'unknown', 'signature_heuristic': 'unknown', 'intervention': 'none', 'pair_corruption': 0.006666666666666666, 'retr_it': 0.012, 'retr_ti': 0.016, 'd_retr_min': -0.023, 'sym': 0.004, 'hub': 0.134, 'cos_max': 0.05, 'd_cos': 0.031, 'er_min': 30.57, 'd_er': 0.28, 'var_ratio': 0.968, 'cf_drop': 0.0, 'cca': 0.697, 'mi_mean3': 0.0732}\n","{'episode': 'smooth_04', 'signature_truth': 'unknown', 'signature_heuristic': 'unknown', 'intervention': 'none', 'pair_corruption': 0.008888888888888889, 'retr_it': 0.012, 'retr_ti': 0.012, 'd_retr_min': -0.023, 'sym': 0.0, 'hub': 0.114, 'cos_max': 0.07, 'd_cos': 0.051, 'er_min': 31.1, 'd_er': 0.81, 'var_ratio': 0.948, 'cf_drop': 0.0, 'cca': 0.685, 'mi_mean3': 0.0759}\n","{'episode': 'smooth_05', 'signature_truth': 'unknown', 'signature_heuristic': 'unknown', 'intervention': 'none', 'pair_corruption': 0.011111111111111112, 'retr_it': 0.023, 'retr_ti': 0.012, 'd_retr_min': -0.023, 'sym': 0.012, 'hub': 0.109, 'cos_max': 0.083, 'd_cos': 0.063, 'er_min': 31.11, 'd_er': 0.82, 'var_ratio': 0.935, 'cf_drop': 0.0, 'cca': 0.693, 'mi_mean3': 0.0761}\n","{'episode': 'smooth_06', 'signature_truth': 'unknown', 'signature_heuristic': 'unknown', 'intervention': 'none', 'pair_corruption': 0.013333333333333332, 'retr_it': 0.008, 'retr_ti': 0.0, 'd_retr_min': -0.035, 'sym': 0.008, 'hub': 0.137, 'cos_max': 0.095, 'd_cos': 0.076, 'er_min': 30.72, 'd_er': 0.43, 'var_ratio': 0.922, 'cf_drop': 0.0, 'cca': 0.686, 'mi_mean3': 0.0736}\n","{'episode': 'smooth_07', 'signature_truth': 'unknown', 'signature_heuristic': 'unknown', 'intervention': 'none', 'pair_corruption': 0.015555555555555557, 'retr_it': 0.008, 'retr_ti': 0.004, 'd_retr_min': -0.031, 'sym': 0.004, 'hub': 0.125, 'cos_max': 0.103, 'd_cos': 0.084, 'er_min': 31.04, 'd_er': 0.75, 'var_ratio': 0.914, 'cf_drop': 0.0, 'cca': 0.683, 'mi_mean3': 0.0672}\n","{'episode': 'smooth_08', 'signature_truth': 'unknown', 'signature_heuristic': 'unknown', 'intervention': 'none', 'pair_corruption': 0.017777777777777778, 'retr_it': 0.008, 'retr_ti': 0.004, 'd_retr_min': -0.031, 'sym': 0.004, 'hub': 0.127, 'cos_max': 0.12, 'd_cos': 0.101, 'er_min': 31.1, 'd_er': 0.81, 'var_ratio': 0.897, 'cf_drop': 0.0, 'cca': 0.692, 'mi_mean3': 0.0682}\n","{'episode': 'smooth_09', 'signature_truth': 'unknown', 'signature_heuristic': 'unknown', 'intervention': 'none', 'pair_corruption': 0.02, 'retr_it': 0.004, 'retr_ti': 0.0, 'd_retr_min': -0.035, 'sym': 0.004, 'hub': 0.115, 'cos_max': 0.144, 'd_cos': 0.125, 'er_min': 30.94, 'd_er': 0.66, 'var_ratio': 0.873, 'cf_drop': 0.0, 'cca': 0.675, 'mi_mean3': 0.0608}\n","\n","Full report paths:\n"," - /content/mm_gov_ch3/mm_ch3_20260217T134016185419+0000_19b2e27a/deliverables/drift_timeline.json\n"," - /content/mm_gov_ch3/mm_ch3_20260217T134016185419+0000_19b2e27a/deliverables/drift_evidence.json\n"," - plots under: /content/mm_gov_ch3/mm_ch3_20260217T134016185419+0000_19b2e27a/deliverables/plots\n"]}]},{"cell_type":"markdown","source":["##10.AUDIT BUNDLE"],"metadata":{"id":"ss5L2x1ojA8d"}},{"cell_type":"markdown","source":["###10.1.OVERVIEW"],"metadata":{"id":"sduxTxx7jC0M"}},{"cell_type":"markdown","source":["**CELL 10 — FINAL REPORTING, PACKAGING, AND THE PRODUCTION POSTURE**\n","\n","The final cell completes the governance loop. It writes the final manifests, risk logs, and prompt logs, ensures every deliverable is on disk, and zips the audit bundle. This is not cosmetic. The deliverable of the chapter is not only a set of plots but a reproducible artifact that could be reviewed later. Professional systems require traceability: what code produced these results, under what config, at what time, with what risks identified, and with what open items recorded.\n","\n","Pedagogically, this cell shows students the difference between research and professional research. Research often ends at insight. Professional research ends at a package that can be shared, rerun, and audited. The audit bundle is the unit of accountability. If a student later claims that drift detection is “easy,” this notebook teaches otherwise: detection requires instrumentation, and instrumentation requires disciplined artifact handling.\n","\n","This cell also reinforces the chapter’s final operational implication: multimodal models should never be deployed without the monitoring infrastructure that makes drift observable. The zip file is a symbol of that idea. It says: we are not shipping a story. We are shipping evidence."],"metadata":{"id":"bqPR0OmsWKLt"}},{"cell_type":"markdown","source":["###10.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"v_giRgoJjGY5"}},{"cell_type":"code","source":["# === Cell 10 ===\n","# Title: Release Decision + Finalization + Bundle Packaging\n","# Brief Explanation: Decide approve/reject from acceptance gates, finalize manifests/logs, hash artifacts, and zip the audit bundle.\n","\n","from __future__ import annotations\n","\n","# Load acceptance results\n","acc_path = os.path.join(P.deliverables, \"acceptance_tests.json\")\n","acc_obj = json.loads(open(acc_path, \"r\", encoding=\"utf-8\").read())\n","gates = acc_obj[\"facts_provided\"][\"acceptance\"][\"gates\"]\n","failed = [g for g in gates if not g[\"passed\"]]\n","decision = \"APPROVE\" if len(failed) == 0 else \"REJECT\"\n","\n","release_decision = strict_report(\n","    facts_provided={\n","        \"decision\": decision,\n","        \"failed_gates\": [g[\"gate\"] for g in failed],\n","        \"num_failed\": len(failed),\n","        \"timestamp_utc\": utc_now_iso(),\n","    },\n","    assumptions={\"policy\": \"Any failed gate triggers REJECT; thresholds are conservative for synthetic lab.\"},\n","    open_items=[\"Human review required before any real-world deployment decision.\"],\n","    analysis=\"Release decision is computed from explicit acceptance gates and exported as strict JSON.\",\n","    draft_output={\n","        \"next_actions\": (\n","            [\"Proceed to monitored deployment simulation.\"] if decision == \"APPROVE\"\n","            else [\"Investigate failed gates; adjust data controls/temperature/balancing; rerun.\"]\n","        )\n","    },\n","    verification_status=\"Not verified\",\n","    questions_to_verify=[\"Do acceptance gates reflect true operational risk tolerance and downstream task requirements?\"],\n",")\n","write_json_atomic(os.path.join(P.deliverables, \"release_decision.json\"), release_decision)\n","\n","# Update run manifest with artifact hashes\n","artifact_paths = [\n","    RUN_MANIFEST_PATH, PROMPTS_LOG_PATH, RISK_LOG_PATH,\n","    os.path.join(P.deliverables, \"metrics_summary.json\"),\n","    os.path.join(P.deliverables, \"acceptance_tests.json\"),\n","    os.path.join(P.deliverables, \"drift_timeline.json\"),\n","    os.path.join(P.deliverables, \"release_decision.json\"),\n","    os.path.join(P.deliverables, \"gradient_check.json\"),\n","    os.path.join(P.deliverables, \"determinism_check.json\"),\n","]\n","artifact_hashes = {}\n","for ap in artifact_paths:\n","    if os.path.exists(ap):\n","        artifact_hashes[os.path.relpath(ap, P.root)] = file_sha256(ap)\n","\n","# Include plot hashes\n","for fn in os.listdir(P.plots):\n","    if fn.endswith(\".png\"):\n","        pth = os.path.join(P.plots, fn)\n","        artifact_hashes[os.path.relpath(pth, P.root)] = file_sha256(pth)\n","\n","manifest = json.loads(open(RUN_MANIFEST_PATH, \"r\", encoding=\"utf-8\").read())\n","manifest[\"artifact_hashes_sha256\"] = artifact_hashes\n","manifest[\"release_decision\"] = decision\n","manifest[\"timestamp_utc_finalized\"] = utc_now_iso()\n","write_json_atomic(RUN_MANIFEST_PATH, manifest)\n","\n","# Zip bundle\n","zip_path = os.path.join(CFG.paths_base, f\"{run_id}.zip\")\n","if os.path.exists(zip_path):\n","    os.remove(zip_path)\n","\n","with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as z:\n","    for root, dirs, files in os.walk(P.root):\n","        for f in files:\n","            full = os.path.join(root, f)\n","            rel = os.path.relpath(full, P.root)\n","            z.write(full, arcname=os.path.join(run_id, rel))\n","\n","print(\"Release decision:\", decision)\n","print(\"Failed gates:\", [g[\"gate\"] for g in failed])\n","print(\"Run manifest:\", RUN_MANIFEST_PATH)\n","print(\"Audit bundle zip:\", zip_path)\n","print(\"Deliverables dir:\", P.deliverables)\n"],"metadata":{"id":"Lrqr5DdYjK83","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1771339392086,"user_tz":360,"elapsed":106,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"0773c703-5140-43d6-b061-8d1963eb6e9e"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Release decision: REJECT\n","Failed gates: ['retrieval_top1_both_dirs', 'retrieval_top5_both_dirs']\n","Run manifest: /content/mm_gov_ch3/mm_ch3_20260217T134016185419+0000_19b2e27a/run_manifest.json\n","Audit bundle zip: /content/mm_gov_ch3/mm_ch3_20260217T134016185419+0000_19b2e27a.zip\n","Deliverables dir: /content/mm_gov_ch3/mm_ch3_20260217T134016185419+0000_19b2e27a/deliverables\n"]}]},{"cell_type":"markdown","source":["##11.CONCLUSION"],"metadata":{"id":"ZmL0B12KjLXl"}},{"cell_type":"markdown","source":["**CONCLUSION**\n","\n","The central lesson of Chapter 3 is that multimodality becomes professionally meaningful only when we treat it as a **measurement system under change** rather than a static mapping from inputs to outputs. In Chapters 1 and 2 we learned how to build a shared embedding space and how that space fails under dominance, spurious shortcuts, corruption, and collapse. Chapter 3 extends the story into the operational frontier: once a multimodal model is deployed, its failure modes are not confined to training instability; they emerge as **drift**—a shifting relationship between the world, the measurement channels, and the geometry the model uses to represent meaning. The point is not that drift exists. The point is that drift is often invisible to the naive practitioner precisely because the model can remain confident, and even remain strong on a headline metric, while silently altering what its embeddings mean.\n","\n","This chapter’s practical claim is that the “shared latent space” is not an abstract object. It is a **contract**. It is the implicit promise that comparable things remain comparable across modalities and across time. That contract can break in multiple ways. Sometimes it breaks loudly: retrieval accuracy collapses because pairing is corrupted or one modality becomes too noisy. But often it breaks quietly: the system becomes dependent on a confounder, or develops hubness where many samples collapse onto a few anchors, or becomes anisotropic in a way that makes distances misleading. A professional system cannot be governed by a single success metric. It must be governed by a set of invariants and early-warning indicators that reflect the structure of the embedding space itself.\n","\n","**MAIN RESULTS**\n","\n","The main results of the Chapter 3 laboratory can be understood through three levels of evidence: geometry, metrics, and intervention logic.\n","\n","At the geometric level, we observed that drift is fundamentally about **shape changes in representation**. When the drift mechanism induced hubness or dominance-like behavior, we saw that the similarity matrix concentrated: more rows selected the same top matches, and the retrieval structure became many-to-one. When collapse-like behavior was induced, the covariance spectrum lost mass: effective rank decreased and average off-diagonal cosine similarity increased. When confounding was injected, we saw a different geometric signature: alignment improved not by preserving factor structure but by introducing a shared “shortcut coordinate” that caused paired items to match for the wrong reason. These are not merely numerical quirks. They are the core question of multimodality: “What does proximity mean?” Drift changes the answer.\n","\n","At the metric level, we saw why operational monitoring cannot be reduced to one or two KPIs. Retrieval metrics in both directions remain essential, but they are insufficient. They can decline for multiple reasons that require different responses, and they can also improve in the presence of confounding. Symmetry gaps sometimes point to modality imbalance, but they are not reliable signatures on their own. Hubness proxies and covariance spectra provide stronger structural signals, yet even those do not uniquely identify mechanisms. MI-like factor probes and CCA-like correlations add interpretability, but they too can be misleading if a shortcut encodes factor-like information without preserving semantic meaning. The result is uncomfortable but important: **monitoring is itself a modeling problem**. It requires calibration, ensembles, and counterfactual checks, not threshold worship.\n","\n","At the intervention level, we learned a decisive professional truth: drift diagnosis becomes robust only when it is anchored to **causal tests**, not just correlational monitors. In the synthetic lab, we can label drift mechanisms because we injected them. In production, we rarely have that luxury. What we do have is the ability to run controlled checks: ablate a suspected confounder, perturb one modality’s noise, corrupt pairings in a sandbox, and measure directional sensitivity. The chapter’s emphasis on counterfactual deltas is therefore not a trick; it is a governance principle. If a system’s performance depends on a feature that should not matter, the dependency must be measurable and reviewable, otherwise the system is not professional-grade.\n","\n","**DATA CONSTRUCTION**\n","\n","The Chapter 3 data construction methodology mattered as much as the model. We did not use complex real-world datasets because the pedagogical objective was mechanism clarity. Instead, we built a synthetic multimodal world where images and symbolic text are generated from shared latent factors. This gave us two advantages.\n","\n","First, it made “semantic ground truth” explicit. Because we know the true factors for each sample, we can measure whether embeddings preserve those factors. In real data, semantic ground truth is often partial, noisy, or undefined. In synthetic settings, we can design it.\n","\n","Second, the synthetic generator allowed us to define drift as **controlled changes in the measurement process**. We can add noise asymmetrically, degrade pairing quality, introduce confounders that mimic realistic shortcuts, and modify embedding geometry through interventions. These are not arbitrary changes. Each one corresponds to a plausible production issue: pipeline changes, new preprocessing, index-like identifiers leaking into both modalities, evolving tokenization, or distribution shifts in one channel. The data generator becomes a laboratory instrument: it lets students and practitioners rehearse failure modes safely and measure them honestly.\n","\n","A key methodological insight is that synthetic construction is not a substitute for real-world validation; it is a way to make the logic of validation teachable. Students can understand, in slow motion, what drift does to geometry and why “the model still works” can be false even when the outputs look plausible.\n","\n","**TRAINING**\n","\n","Training in Chapter 3 was not the frontier novelty; it was the baseline. We continued to rely on a contrastive objective to align two encoders into a shared space. The training goal is simple: matched pairs should have higher similarity than mismatched pairs. But Chapter 3 shows why that simplicity is deceptive. Training creates a representation contract, but deployment challenges the contract through drift.\n","\n","The most important training lesson is that a well-trained aligner can still be fragile. Even if the optimization converges cleanly, the learned space may be brittle to small changes in observation structure. If a new confounder emerges, training does not protect you; it may even predispose you to exploit shortcuts. If hubness develops downstream, training does not protect you; it may worsen the effect because contrastive objectives can amplify anisotropy. If pairing noise increases, training does not protect you; retrieval fails in ways that can look like “randomness” but are actually structural. Therefore training success must be accompanied by a monitoring architecture that treats deployment as a continuation of the experiment rather than the end of it.\n","\n","This is the governance-first posture. The objective is not to ship a model; the objective is to ship a model plus the instrumentation that makes its representation contract reviewable.\n","\n","**EXPERIMENTS**\n","\n","The experiments in Chapter 3 were designed as drift episodes: a sequence of controlled scenarios that stress the representation contract in different ways. There are four categories to emphasize.\n","\n","First, dominance and hubness-style scenarios tested whether one modality can become structurally privileged. The monitoring evidence is not just a retrieval drop, but a concentration pattern in matches: many-to-one alignments, reduced diversity of nearest neighbors, and increased hubness proxy values.\n","\n","Second, confounding scenarios tested whether alignment can be achieved for the wrong reason. This is the most dangerous category because performance metrics can improve. The key evidence is counterfactual: remove the confounder and the advantage disappears. The confounder is not a nuisance; it is a proof that the system has learned a shortcut.\n","\n","Third, pairing corruption scenarios tested the fragility of the alignment assumption itself: that pairs correspond to the same underlying object. Corruption reduces the signal-to-noise ratio of the contrastive objective and can cause instability. The evidence often appears as a drop in retrieval accuracy and increased asymmetry, but also as degraded cross-modal correlations even when within-modality factor information remains.\n","\n","Fourth, collapse scenarios tested degenerate geometry. Collapse is revealed not primarily by retrieval, but by structural monitors: effective rank decreases, variance floors are violated, and off-diagonal cosine similarity increases. Collapse is a failure of representation diversity; it destroys the latent space’s ability to represent multiple factors simultaneously.\n","\n","These experiments were not meant to prove that any specific monitor is perfect. They were meant to teach that drift must be approached as a **diagnostic discipline**: you look at multiple signals, you run counterfactuals, you compare to baselines, and you keep the evidence reproducible.\n","\n","**HOW TO INTERPRET THE EXPERIMENTS**\n","\n","The correct interpretation posture is not “which label did the classifier output,” but “what does the evidence say about the contract.” A professional reviewer reads drift evidence in layers.\n","\n","Start with the baseline: what is the reference geometry and performance? Then evaluate deltas: which monitors moved, by how much, and in what direction? Then assess coherence: do the monitor moves agree with a plausible mechanism? For example, if hubness increases and retrieval becomes many-to-one, that is coherent with dominance-like drift. If retrieval improves but counterfactual removal destroys the gain, that is coherent with confounding. If effective rank collapses and cosine similarity rises, that is coherent with collapse. If retrieval drops sharply while within-modality factor probes remain stable, that is coherent with pairing corruption rather than loss of semantic factor encoding.\n","\n","Importantly, the absence of a clear signature is not a failure of monitoring; it is information. It means either the drift is mild, the monitors are insufficiently sensitive, or the drift mechanism is not in the taxonomy. This is exactly why governance requires open items and explicit “Not verified” status. In production, uncertainty must be recorded, not hidden.\n","\n","Another interpretation lesson is that heuristics are fragile. Threshold-based labeling is not a professional endpoint; it is a starting point. The chapter’s synthetic ground truth exists to show students why heuristic diagnosis can disagree with known interventions. That disagreement is a lesson in humility and a prompt for better tooling: richer monitors, calibrated thresholds, learned drift classifiers trained on synthetic episodes, and counterfactual test suites that can be executed as stage gates.\n","\n","**IMPLICATIONS IN PRACTICE AND PRODUCTION-GRADE IMPLEMENTATION**\n","\n","The practical implications of Chapter 3 are straightforward and demanding.\n","\n","First, treat multimodal embeddings as a governed artifact. In production, you should not only log outputs; you should log representation monitors. This includes distributional summaries of embedding norms, covariance spectra, effective rank, mean cosine similarity, and retrieval direction asymmetry on a stable evaluation set. If the representation contract is not logged, it cannot be audited.\n","\n","Second, incorporate counterfactual tests as operational controls. If your system can plausibly exploit shortcuts, you must test for them. This can mean removing watermark-like features, masking metadata fields, altering preprocessing, or scrambling suspected confounders. The goal is to detect whether performance depends on features that should not matter. Counterfactual deltas are the closest thing to causal evidence you can obtain without full causal modeling.\n","\n","Third, enforce stage gates that are distributional, not anecdotal. A single run is not evidence. Monitor distributions across seeds, across time windows, and across drift intensities. Define acceptance in terms of margins and floors: effective rank above a threshold, hubness below a threshold, symmetry gap within bounds, confounder sensitivity below a bound, and retrieval stability under mild perturbations. This aligns with institutional practice: decisions are made under uncertainty, and controls must be robust.\n","\n","Fourth, separate detection from attribution. Detecting “something changed” is easier than diagnosing “what changed.” Production systems should treat attribution as a hypothesis that triggers investigation, not as an automated verdict. The audit bundle is what enables that investigation. It preserves the evidence trail, the configuration, and the exact monitors that moved.\n","\n","Fifth, integrate drift governance into the broader AI 2026 posture. Multimodality, long context, and surrogates share a structural risk: they introduce latent mechanisms that can fail silently. Governance is the discipline of surfacing those mechanisms through reproducible tests, monitored invariants, and reviewable artifacts. If you cannot explain why a multimodal model is behaving differently today than yesterday, you do not have a production system; you have a demo.\n","\n","Finally, the chapter points to a constructive frontier direction: monitoring itself can be learned. The synthetic drift episodes provide labeled data for a drift classifier operating on monitor vectors. This can be done in a governed way: trained on synthetic drift mechanisms, validated across seeds, and used only as an assistive tool with explicit uncertainty. The lesson is not to automate diagnosis blindly, but to make diagnosis more systematic. In the same way that multimodal models learn coordinate compatibility, monitoring systems must learn to map evidence patterns to plausible failure hypotheses.\n","\n","The final takeaway is therefore a professional one. A multimodal model is a system that claims to unify meaning across measurement channels. That claim is only defensible if the system includes the machinery to detect when measurement changes, to quantify how representation geometry shifts, and to produce artifacts that allow a human reviewer to decide what to do next. Chapter 3’s laboratory is not the end of the story; it is the template. It teaches students that frontier capability is not the absence of failure, but the presence of controls that make failure observable, interpretable, and governable.\n"],"metadata":{"id":"tv8ReGkpWL8u"}}]}
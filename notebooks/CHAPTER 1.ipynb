{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","toc_visible":true,"authorship_tag":"ABX9TyPeHP0itgupe1aIloXPMDiv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#**CHAPTER 1.MULTIMODALITY BY CONSTRUCTION**\n","---"],"metadata":{"id":"rgzq7ad4oQsb"}},{"cell_type":"markdown","source":["##REFERENCE"],"metadata":{"id":"nBRtjho5h2Cg"}},{"cell_type":"markdown","source":["https://chatgpt.com/share/699466a2-db08-8012-94aa-81e27ba6d44a"],"metadata":{"id":"SCQp1W1bWDl0"}},{"cell_type":"markdown","source":["##0.CONTEXT"],"metadata":{"id":"qWHgDkx8h5mE"}},{"cell_type":"markdown","source":["**Introduction (Chapter 1: Multimodality by Construction — Embeddings, Geometry, Alignment)**\n","\n","This chapter is a guided encounter with a claim that sounds abstract until you build it yourself: multimodality is the disciplined construction of compatible coordinate systems across different data types. In practice, “images” and “text” (and audio, sensor traces, tables, and diagrams) are not merely different file formats. They are different measurement instruments that observe the same underlying world through different distortions, resolutions, and noise models. A multimodal model is not “one model that can do many things.” It is a mechanism for aligning those instruments so that one modality can locate meaning in the other.\n","\n","The pedagogical objective is deliberately narrow and therefore powerful: we will not chase scale, benchmarks, or performance theater. Instead, we will build a minimal synthetic world where two modalities are guaranteed to share the same latent causes, and we will force a learned representation to recover that shared structure. The point is to make embedding geometry visible and accountable. You should be able to answer, with evidence, what your model has learned: what it aligns, what it confuses, what it collapses, and how those behaviors degrade when you stress the system.\n","\n","The chapter is also aligned with the AI 2026 “frontier awareness” posture. Multimodality is frontier not because it is mysterious, but because it exposes a general problem: how to make representations consistent across observational channels while preserving what matters and discarding what does not. This is also why multimodality naturally belongs in a harmonic collection with long-context memory and surrogates. Long context is selection under constraint. Surrogates are substitution under constraint. Multimodality is alignment under constraint. The unifying theme is governed representation: we want mechanisms that are inspectable, reproducible, and reviewable, not merely impressive.\n","\n","What follows is structured in four parts: theory, definitions, methodology, and deliverables. This structure is intentionally practical: you will leave with a mental model, a shared vocabulary, an experiment you can reproduce in Colab, and an audit bundle that supports professional review.\n","\n","**Part 1. The Theory**\n","\n","A useful way to think about multimodal learning is to treat each modality as a coordinate chart on the same underlying manifold of causes. The world has latent causes: “shape,” “orientation,” “frequency,” “phase,” “thickness,” “style,” “identity,” “intent,” and so on. A camera measures those causes through pixel intensities; a description measures those causes through tokens; a microphone measures them through waveforms. None of these measurements is the cause itself. Each modality is a structured projection. Multimodal learning is the attempt to learn an internal representation that is stable across those projections.\n","\n","This immediately clarifies why multimodality is hard. If modalities are projections, then information is lost differently in each. Some causes are more visible in one modality than another. Some causes are confounded with noise. Some causes are not present at all. Therefore, alignment is not “make embeddings equal.” Alignment is the negotiation of invariants: which aspects should be preserved across modalities, and which aspects are modality-specific and can be ignored.\n","\n","From this perspective, the canonical multimodal objective is not classification. It is mutual retrievability. If an image and a sentence refer to the same latent factors, then the representation of the image should “find” the representation of the sentence in a shared space, and vice versa. This is the conceptual basis for contrastive learning. Contrastive learning does not require labels for every downstream task. It only requires pairing information: which two observations refer to the same underlying cause. In the real world, those pairs might be image-caption pairs, video-audio pairs, or diagram-explanation pairs. In this chapter, we will use synthetic pairs so we can control exactly what “same cause” means.\n","\n","Contrastive learning also exposes the central failure modes of multimodality in a clean way. If the objective is retrieval, then failure is not a vague “it seems worse.” Failure is measurable: retrieval accuracy collapses, the geometry degenerates, the embeddings become nearly identical, or one modality dominates the other. These failure modes are not academic. They appear in real training runs at scale, only harder to diagnose because the world is not synthetic and your ground truth is never complete.\n","\n","Another core theoretical point is that multimodal alignment is not just a loss function; it is a system. You choose model capacity, normalization, temperature, batch composition, negative sampling, and augmentation. Each choice changes the geometry of the learned space. In other words, the representation is not discovered; it is engineered under constraints. This is why the chapter is “multimodality by construction.” We want you to experience, directly, how design choices shape geometry.\n","\n","Finally, multimodality highlights a subtle but important principle: “more capability” can mean “less interpretability.” When you scale models, you often gain performance while losing the ability to cleanly attribute geometric structure to known causes. This chapter takes the opposite route: we intentionally keep the model small so that you can inspect what each component contributes. The aim is not to be competitive; the aim is to become fluent in the mechanism.\n","\n","**Part 2. Definitions of Key Ideas (Latent Space, Embeddings, Alignment, Geometry)**\n","\n","A definition in this chapter is not a slogan; it is an operational contract. Each term below is defined so that it can be tested or falsified within the notebook.\n","\n","**Latent factors**  \n","Latent factors are unobserved variables that generate observations. In our synthetic world, they are explicit: discrete choices like shape class and orientation bin, and continuous-like choices discretized into bins such as frequency and phase. In real systems, latent factors might include identity, viewpoint, lighting, topic, or intent. The key property is causal: latent factors produce the data, but are not directly the data.\n","\n","**Latent space**  \n","A latent space is a vector space in which points represent compressed descriptions of observations. It is “latent” because it is not directly observed; it is learned. The important nuance is that a latent space is not automatically meaningful. A latent space becomes meaningful when its geometry corresponds to stable relationships among causes. In this chapter, “meaningful” will be operationalized by retrieval and separability: paired items are near, and items sharing a factor cluster in identifiable regions.\n","\n","**Embedding**  \n","An embedding is the mapping from an observation to a vector in latent space. An image encoder maps pixels to an embedding; a text encoder maps token-derived features to an embedding. Embeddings are not the latent factors; they are coordinates the model invents to solve its objective. Two embeddings being close means “the model treats them as related under the training objective,” not “they are objectively similar.”\n","\n","**Shared embedding space**  \n","A shared embedding space is a single latent space used by multiple encoders. The key property is comparability: distances and angles are meaningful across modalities. If the image embedding and the text embedding live in the same space, then cross-modal similarity becomes a geometric query.\n","\n","**Alignment**  \n","Alignment is the property that paired observations (generated by the same latent factors) map to nearby embeddings. It is not merely “they match.” It is structured: alignment should preserve relevant factor structure, not just memorization. We measure alignment by retrieval metrics and by the stability of geometry under stress.\n","\n","**Contrastive objective (InfoNCE)**  \n","A contrastive objective trains embeddings so that positives (true pairs) have high similarity while negatives (mismatched pairs) have lower similarity. InfoNCE is the standard formulation where each item must identify its true partner among a set of candidates. The temperature parameter controls how “sharp” the discrimination is, which directly influences geometry.\n","\n","**Temperature**  \n","Temperature rescales similarities before the softmax. Lower temperature forces the model to make harder, sharper distinctions; higher temperature smooths probabilities. Temperature is not a mere hyperparameter; it is a geometric dial. It changes how strongly the model penalizes near-misses and can induce either collapse or instability if mis-set.\n","\n","**Collapse**  \n","Collapse is a degenerate solution where embeddings lose diversity. In the extreme, every input maps to nearly the same vector. Collapse can produce deceptively stable losses under some settings but destroys retrieval and separability. We diagnose collapse by pairwise cosine distributions, embedding variance floors, and covariance spectra (effective rank).\n","\n","**Separability**  \n","Separability refers to the extent to which embeddings preserve distinctions along latent factors. If “shape” is a factor, then embeddings should cluster by shape, or at least show systematic variance aligned with shape. We measure this with an ANOVA-like ratio: between-class scatter divided by within-class scatter.\n","\n","**Modality symmetry**  \n","Modality symmetry means neither modality dominates the shared space. In practice, one encoder can produce embeddings with different norms or variances, causing training dynamics where one side learns faster and the other becomes a passenger. We diagnose symmetry by comparing norm distributions, variance, and retrieval asymmetry (image-to-text versus text-to-image).\n","\n","**Part 3. Methodology (What We Build and How We Learn It)**\n","\n","The methodology is a complete experiment, not a toy snippet. It is designed to be run end-to-end and to produce artifacts that support review.\n","\n","**1) Build a synthetic multimodal world with explicit causes**  \n","We specify a latent factor vector per sample. From those factors, we generate two observations:\n","an image-like matrix (small 16×16) and a text-like symbolic sequence. Both are derived from the same latent factors, but with different distortions. The image generator produces structured patterns (e.g., sinusoidal textures) controlled by frequency and phase, and modified by “shape” and “orientation” rules. The text generator produces a token grammar that encodes the same factors as discrete symbols. This is crucial: the pairing is guaranteed and the ground truth is known.\n","\n","**2) Encode text without an LLM**  \n","The point is multimodality, not language modeling. We use a deterministic tokenization scheme and encode sequences into vectors through simple, transparent features (bag-of-tokens plus positional moments). This keeps the experiment interpretable. It also makes a deeper pedagogical point: multimodality does not require language models. It requires paired structure and a shared objective.\n","\n","**3) Train two encoders into a shared space**  \n","We use two separate encoders (image encoder and text encoder), each a 2-layer MLP. Each maps its input to an embedding vector. The embeddings are L2-normalized so that cosine similarity becomes a stable geometric measure. The training objective is symmetric InfoNCE: images must retrieve their paired texts, and texts must retrieve their paired images.\n","\n","**4) Implement manual backprop and validate it**  \n","To ensure rigor, the training loop does not rely on autodiff frameworks. Gradients are computed analytically and validated using a finite-difference gradient check. This is not a style preference; it is didactic discipline. If you cannot validate your gradient pipeline, you cannot trust your conclusions about geometry.\n","\n","**5) Evaluate geometry, not just loss**  \n","After training, we evaluate:\n","retrieval performance (top-1, top-5, MRR), factor separability, collapse metrics, covariance spectrum, and modality symmetry. We also generate PCA projections using SVD (no fragile dependencies) to visualize clustering by factors. Visuals are saved as plots, and all metrics are exported as strict JSON.\n","\n","**6) Stress the system to reveal failure modes**  \n","We perform structured stress tests that change the data-generating process. For example, we increase noise in the image modality while holding text constant, and we corrupt pairings by permuting a fraction of the text samples. We then measure degradation curves. The stress suite teaches the central lesson: an aligned representation is not a static achievement; it is a conditional property that can fail under distribution shift.\n","\n","**7) Govern the experiment as a professional artifact**  \n","Every run produces an audit bundle: a manifest with configuration and environment fingerprinting, prompt logs with hashes, a risk log with taxonomy and controls, and deliverables containing plots and JSON summaries. This matters because multimodal systems are particularly vulnerable to narrative drift: it is easy to tell a story about “meaningful embeddings” without proving it. The audit bundle forces the notebook to behave like an accountable laboratory.\n","\n","**Part 4. Deliverables (What You Produce and How Students Use It)**\n","\n","This chapter is designed so that a student can run the notebook and obtain a complete set of reviewable outputs. Deliverables are not “nice extras.” They are the mechanism that turns a lecture into an empirical lab.\n","\n","**Deliverable A: A reproducible synthetic multimodal dataset**  \n","You will have a fully specified generator for paired image and text observations. The generator exposes knobs (noise level, factor cardinalities, corruption rate) so students can run controlled experiments. The dataset is not a file to download; it is a reproducible world.\n","\n","**Deliverable B: A trained multimodal alignment model**  \n","You will produce two trained encoders that map different modalities into a shared space. The checkpointing mechanism saves best-performing parameters on a validation criterion. Students can inspect the parameters, re-run training, and compare runs across seeds.\n","\n","**Deliverable C: A geometry report with quantitative diagnostics**  \n","The notebook exports a strict JSON metrics summary containing retrieval metrics, separability ratios, collapse indicators, covariance spectra, and modality symmetry checks. This report is designed to be read by humans and also to support automated regression testing across changes.\n","\n","**Deliverable D: Visual evidence of embedding structure**  \n","Plots include PCA projections colored by known latent factors and similarity heatmaps for paired subsets. These visuals are not “proof,” but they are essential for intuition. They show what “cluster,” “axis,” and “distance” actually mean in a trained representation.\n","\n","**Deliverable E: Stress-test reports and degradation curves**  \n","The stress suite exports a structured stress report and plots showing performance degradation under noise asymmetry and pairing corruption. Students learn to interpret robustness, locate brittleness, and discuss what kinds of shifts are fatal versus tolerable.\n","\n","**Deliverable F: A governed audit bundle**  \n","The run manifest, prompt log, risk log, and deliverables folder are zipped into a single archive for review. This supports the governance-first teaching objective: results are not accepted because they look good; they are accepted because they are reproducible, inspectable, and accompanied by explicit assumptions and open questions.\n","\n","By the end of this chapter, a student should be able to explain multimodality without mysticism. They should be able to say: we built two measurement channels of the same latent world; we learned embeddings that make those channels commensurable; we inspected the geometry and measured separability; we checked for collapse and dominance; we stressed the system and recorded failure modes; and we produced an audit-ready artifact bundle that makes these claims reviewable. That is the core competency: not “multimodal hype,” but multimodal mechanism literacy under governance.\n"],"metadata":{"id":"pF_yDrZ7h6_y"}},{"cell_type":"markdown","source":["##1.LIBRARIES AND ENVIRONMENT"],"metadata":{"id":"yeIrVzqFh7fZ"}},{"cell_type":"markdown","source":["**Cell 1 — Environment, Determinism, and the Execution Contract (Why This Cell Exists and What Students Should Learn)**\n","\n","Cell 1 is the “constitution” of the notebook. It does not teach multimodality directly; it teaches the conditions under which multimodality can be taught honestly. In a multimodal experiment, tiny changes in random seeds, array dtypes, batch ordering, or hidden default settings can change the geometry you end up interpreting. If students do not learn to lock down these degrees of freedom, they will learn a dangerous habit: attributing meaning to plots and metrics that are not reproducible.\n","\n","The key pedagogical concept here is that representation learning is not just an algorithm; it is an experimental system. Every scientific system needs a contract that specifies what is fixed and what is allowed to vary. In this cell we define that contract: deterministic randomness (seed control), the configuration object (all hyperparameters in one place), and the filesystem structure where artifacts will be written. This is not housekeeping; it is governance in its simplest, most concrete form.\n","\n","Students should also learn why we print a short runtime fingerprint (Python version, NumPy version, UTC timestamp). In professional settings, these details matter because your output is not only judged by its numerical value; it is judged by whether someone else can reproduce it and audit the steps that produced it. Even in Colab, “Run all” should mean “get the same run.” The timestamp uses timezone-aware UTC by design to avoid subtle time bugs and to support institutional logging standards.\n","\n","Finally, Cell 1 frames the chapter’s deeper theme: multimodality is alignment under constraints. Constraints begin at the level of experimental control. If you cannot control your runtime environment, you cannot control your interpretation. Students should leave this cell with the mindset that strong engineering practice is not separate from theory; it is what allows theory to be tested.\n"],"metadata":{"id":"wJMlM2vXrz3I"}},{"cell_type":"code","source":["# === Cell 1 (REPLACE) ===\n","# Title: Runtime Contract + Determinism + High-Rigor Configuration\n","# Explanation: PATCH — use LeakyReLU (relu_leak>0) so finite-difference gradient checks are well-defined.\n","\n","import os\n","import sys\n","import json\n","import math\n","import time\n","import zipfile\n","import hashlib\n","import random\n","import datetime\n","from dataclasses import dataclass, asdict\n","from typing import Dict, Any, Tuple, List, Optional\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def utc_now_iso() -> str:\n","    return datetime.datetime.now(datetime.timezone.utc).isoformat()\n","\n","def set_determinism(seed: int) -> None:\n","    random.seed(seed)\n","    np.random.seed(seed)\n","\n","@dataclass(frozen=True)\n","class Config:\n","    # Core\n","    seed: int = 7\n","    # Data\n","    n: int = 2048\n","    image_side: int = 16\n","    vocab_size: int = 32\n","    text_seq_len: int = 9\n","    noise_image: float = 0.05\n","    # Model\n","    hidden: int = 256\n","    embed_dim: int = 32\n","    relu_leak: float = 0.01   # <-- PATCH: leaky slope for differentiability (gradient check stability)\n","    # Training\n","    batch: int = 128\n","    epochs: int = 60\n","    lr: float = 2e-3\n","    adam_b1: float = 0.9\n","    adam_b2: float = 0.999\n","    adam_eps: float = 1e-8\n","    weight_decay: float = 1e-4\n","    temp: float = 0.07\n","    grad_clip: float = 5.0\n","    # Splits\n","    train_frac: float = 0.70\n","    val_frac: float = 0.15\n","    # Artifacts\n","    out_dir: str = \"deliverables\"\n","    plots_dir: str = \"deliverables/plots\"\n","    ckpt_dir: str = \"deliverables/checkpoints\"\n","    gates_dir: str = \"deliverables/gates\"\n","    stress_dir: str = \"deliverables/stress\"\n","    # Diagnostics\n","    topk: Tuple[int, int] = (1, 5)\n","\n","CFG = Config()\n","set_determinism(CFG.seed)\n","\n","for p in [CFG.out_dir, CFG.plots_dir, CFG.ckpt_dir, CFG.gates_dir, CFG.stress_dir]:\n","    os.makedirs(p, exist_ok=True)\n","\n","print(\"RUN CONTRACT\")\n","print(\"  utc_now:\", utc_now_iso())\n","print(\"  python:\", sys.version.split()[0])\n","print(\"  numpy :\", np.__version__)\n","print(\"  seed  :\", CFG.seed)\n","print(\"  relu_leak:\", CFG.relu_leak)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"18zHp4fmo7Is","executionInfo":{"status":"ok","timestamp":1771332419550,"user_tz":360,"elapsed":111,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"1cd873bb-ae1d-4008-8768-d3add35683ea"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["RUN CONTRACT\n","  utc_now: 2026-02-17T12:47:00.194567+00:00\n","  python: 3.12.12\n","  numpy : 2.0.2\n","  seed  : 7\n","  relu_leak: 0.01\n"]}]},{"cell_type":"markdown","source":["##2.GOVERNANCE ARTIFACTS"],"metadata":{"id":"aOzs2vNWiEjE"}},{"cell_type":"markdown","source":["###2.1.OVERVIEW"],"metadata":{"id":"_Z7ptw6JiIcM"}},{"cell_type":"markdown","source":["**Cell 2 — Governance Artifacts and Auditability (Why We Log, Hash, and Separate Facts from Assumptions)**\n","\n","Cell 2 turns the notebook from a “demo” into a “lab.” The purpose is to ensure that every claim the notebook makes can be traced back to a run configuration and a set of recorded outputs. This cell introduces an Artifact Manager: a structured way to write JSON reports, track a run identifier, log prompts (redacted) with hashes, and produce a risk log. The pedagogical point is that the model’s outputs are not evidence unless they are situated in a reproducible context.\n","\n","Students should learn the difference between a result and a deliverable. A result is a number on the screen. A deliverable is a bundle of evidence that can be reviewed later: metrics, plots, configuration, and explicit statements about what is known versus assumed. This cell enforces strict JSON schemas that separate facts provided (computed metrics), assumptions (design choices and simplifications), open items (what remains unresolved), and questions to verify (what a reviewer should check). This separation prevents a common failure in AI education: confusing plausibility with truth.\n","\n","Hashing is introduced as a minimal integrity mechanism. The goal is not cryptographic security in the adversarial sense; the goal is traceability. If you rerun a notebook or modify an experiment, hashes help you confirm whether you are looking at the same prompt or configuration. This matters especially for multimodal models because failures can be subtle: you can get similar-looking loss curves while the geometry changes materially.\n","\n","The risk log is equally important pedagogically. Multimodality has predictable failure modes: spurious correlations, modality dominance, representation collapse, leakage, and metric hacking. Writing those risks down early forces students to treat them as first-class elements of the experiment rather than as afterthoughts. Cell 2 teaches the professional habit: every experiment must export not only outputs but also accountability.\n"],"metadata":{"id":"jAsIm-aiiLkE"}},{"cell_type":"markdown","source":["###2.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"AK_Iz2Q4iL4X"}},{"cell_type":"code","source":["# === Cell 2 ===\n","# Title: ArtifactManager (Audit-Ready Logs, Hashing, Strict JSON Schema)\n","# Explanation: Implements tamper-evident artifact writing (hashes), structured JSON outputs\n","# with explicit Fact/Assumption/Open-Items separation, and a run manifest.\n","\n","class ArtifactManager:\n","    def __init__(self, cfg: Config):\n","        self.cfg = cfg\n","        self.run_id = self._sha256(f\"{time.time()}|{cfg.seed}|{np.__version__}\")[:12]\n","        self.manifest_path = \"run_manifest.json\"\n","        self.prompts_path = \"prompts_log.jsonl\"\n","        self.risk_path = \"risk_log.json\"\n","        self._prompt_entries: List[Dict[str, Any]] = []\n","\n","    @staticmethod\n","    def _sha256(s: str) -> str:\n","        return hashlib.sha256(s.encode(\"utf-8\")).hexdigest()\n","\n","    def log_prompt(self, name: str, content: str) -> None:\n","        redacted = content.replace(\"\\n\", \"\\\\n\")[:4000]  # bounded + simple redaction\n","        entry = {\n","            \"ts_utc\": utc_now_iso(),\n","            \"name\": name,\n","            \"redacted\": redacted,\n","            \"sha256\": self._sha256(content),\n","        }\n","        self._prompt_entries.append(entry)\n","\n","    def write_json_strict(self, path: str, *, facts_provided: Dict[str, Any], assumptions: Dict[str, Any],\n","                          open_items: List[Any], analysis: str, draft_output: Dict[str, Any],\n","                          verification_status: str = \"Not verified\",\n","                          questions_to_verify: Optional[List[str]] = None) -> None:\n","        if questions_to_verify is None:\n","            questions_to_verify = []\n","        obj = {\n","            \"facts_provided\": facts_provided,\n","            \"assumptions\": assumptions,\n","            \"open_items\": open_items,\n","            \"analysis\": analysis,\n","            \"draft_output\": draft_output,\n","            \"verification_status\": verification_status,\n","            \"questions_to_verify\": questions_to_verify,\n","            \"meta\": {\n","                \"run_id\": self.run_id,\n","                \"timestamp_utc\": utc_now_iso(),\n","                \"path\": path,\n","            }\n","        }\n","        with open(path, \"w\") as f:\n","            json.dump(obj, f, indent=2)\n","\n","    def write_manifest(self) -> None:\n","        manifest = {\n","            \"run_id\": self.run_id,\n","            \"timestamp_utc\": utc_now_iso(),\n","            \"config\": asdict(self.cfg),\n","            \"env\": {\n","                \"python\": sys.version.split()[0],\n","                \"numpy\": np.__version__,\n","            }\n","        }\n","        with open(self.manifest_path, \"w\") as f:\n","            json.dump(manifest, f, indent=2)\n","\n","    def write_risk_log(self) -> None:\n","        risk = {\n","            \"taxonomy\": [\n","                \"spurious_correlation\",\n","                \"modality_dominance\",\n","                \"representation_collapse\",\n","                \"train_test_leakage\",\n","                \"metric_hacking\",\n","            ],\n","            \"controls\": [\n","                \"deterministic_seeds\",\n","                \"split_hygiene_checks\",\n","                \"finite_difference_gradient_check\",\n","                \"bidirectional_contrastive_objective\",\n","                \"collapse_spectrum_monitoring\",\n","                \"stress_sweep_noise_asymmetry\",\n","                \"artifact_hashing_and_manifest\",\n","            ],\n","            \"verification_status\": \"Not verified\",\n","            \"questions_to_verify\": [\n","                \"How do these synthetic failure modes map to real multimodal datasets?\",\n","                \"Which collapse indicators are most predictive under distribution shift?\",\n","            ],\n","            \"meta\": {\"run_id\": self.run_id, \"timestamp_utc\": utc_now_iso()},\n","        }\n","        with open(self.risk_path, \"w\") as f:\n","            json.dump(risk, f, indent=2)\n","\n","    def flush_prompts(self) -> None:\n","        with open(self.prompts_path, \"w\") as f:\n","            for e in self._prompt_entries:\n","                f.write(json.dumps(e) + \"\\n\")\n","\n","AM = ArtifactManager(CFG)\n","AM.log_prompt(\"chapter1_colab_intent\", \"Chapter 1: multimodality by construction (synthetic world, 2-layer MLP encoders, symmetric InfoNCE, manual backprop, governed artifacts).\")\n","AM.write_manifest()\n","AM.write_risk_log()\n","print(\"ArtifactManager ready. run_id =\", AM.run_id)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mGflpzUznBZF","executionInfo":{"status":"ok","timestamp":1771332512849,"user_tz":360,"elapsed":11,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"e48f5c0c-50eb-4e90-ed6e-c9b77fd55d96"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["ArtifactManager ready. run_id = 3cb8138df0b7\n"]}]},{"cell_type":"markdown","source":["##3.SYNTHETIC MULTIMODAL DATA GENERATION"],"metadata":{"id":"zn9_gpBPh_yn"}},{"cell_type":"markdown","source":["###3.1.OVERVIEW"],"metadata":{"id":"6Sg0lGxQiBj6"}},{"cell_type":"markdown","source":["**Cell 3 — Synthetic Multimodal World (The Most Important Conceptual Cell: “Same Causes, Different Projections”)**\n","\n","Cell 3 is where multimodality becomes concrete. The purpose is to build a world in which two different modalities are guaranteed to share the same latent causes. This is the pedagogical foundation: if students cannot see and control the causal factors, they will struggle to understand what “alignment” really means. Real-world multimodal datasets are messy; synthetic construction gives us clarity.\n","\n","Students should focus on the idea that each modality is a projection of the same underlying factors. The image generator converts factors like shape, orientation, frequency, phase, and thickness into a small 16×16 matrix. The text generator converts the same factors into a token grammar. The crucial teaching move is that both modalities are not arbitrary; they are intentionally structured to carry the same information in different forms. This makes the pairing relationship unambiguous. In real systems, ambiguity in pairing is often the main source of representation confusion.\n","\n","This cell also introduces the concept of a “grammar” for symbolic modality. The text is not generated by a language model; it is constructed as a deterministic sequence of tokens. That is pedagogically valuable because it separates the core multimodal idea (shared causes) from the extra complexity of natural language. Students learn that multimodality is not “language plus vision.” It is “multiple measurement channels plus alignment.”\n","\n","Split hygiene is another major lesson. We explicitly build train/validation/test splits and assert there is no overlap. This may seem basic, but leakage in multimodal datasets is exceptionally common in practice (e.g., near-duplicate images, shared captions, repeated metadata). If the split is not clean, retrieval can look perfect while the model has simply memorized correspondences.\n","\n","Finally, students should notice that this synthetic world is not “easy” by default. It has controllable noise and multiple factor interactions. That allows meaningful stress testing later: we can break one modality or corrupt pairing and observe how geometry fails. Cell 3 teaches that the right experimental design is one where failure modes are discoverable and measurable.\n"],"metadata":{"id":"B7g7qJgZiEOw"}},{"cell_type":"markdown","source":["###3.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"SqN4lQyuiE7Y"}},{"cell_type":"code","source":["# === Cell 3 ===\n","# Title: SyntheticWorld (Controllable Latent Factors → Image + Token Sequences)\n","# Explanation: Builds a paired synthetic dataset where both modalities share the same latent factors.\n","# Includes strict split hygiene and metadata tracking for probes (separability, factor decoding).\n","\n","@dataclass(frozen=True)\n","class Factors:\n","    shape: np.ndarray       # {0,1,2}\n","    orient: np.ndarray      # {0,1,2,3}\n","    freq_bin: np.ndarray    # {0,1,2}\n","    phase_bin: np.ndarray   # {0,1,2,3}\n","    thick_bin: np.ndarray   # {0,1,2}\n","\n","class SyntheticWorld:\n","    def __init__(self, cfg: Config):\n","        self.cfg = cfg\n","        self.side = cfg.image_side\n","        self.D_img = cfg.image_side * cfg.image_side\n","        self.D_tok = cfg.vocab_size\n","\n","        # coordinate grid\n","        xs = np.linspace(-1.0, 1.0, self.side)\n","        self.X, self.Y = np.meshgrid(xs, xs)\n","\n","        # vocab: reserve blocks for each factor, plus padding/specials\n","        self.pad_id = 0\n","        self.sep_id = 1\n","        self.base_shape = 2            # 3 tokens\n","        self.base_orient = 2 + 3       # 4 tokens\n","        self.base_freq = 2 + 3 + 4     # 3 tokens\n","        self.base_phase = 2 + 3 + 4 + 3# 4 tokens\n","        self.base_thick = 2 + 3 + 4 + 3 + 4  # 3 tokens\n","        self._assert_vocab()\n","\n","    def _assert_vocab(self) -> None:\n","        need = self.base_thick + 3\n","        if need > self.cfg.vocab_size:\n","            raise ValueError(f\"vocab_size too small: need >= {need}, got {self.cfg.vocab_size}\")\n","\n","    def sample_factors(self, n: int) -> Factors:\n","        shape = np.random.randint(0, 3, size=n)\n","        orient = np.random.randint(0, 4, size=n)\n","        freq_bin = np.random.randint(0, 3, size=n)\n","        phase_bin = np.random.randint(0, 4, size=n)\n","        thick_bin = np.random.randint(0, 3, size=n)\n","        return Factors(shape=shape, orient=orient, freq_bin=freq_bin, phase_bin=phase_bin, thick_bin=thick_bin)\n","\n","    def _render_image(self, s: int, o: int, fb: int, pb: int, tb: int) -> np.ndarray:\n","        # frequency & phase are discretized to keep ground truth interpretable\n","        freq = [1.5, 2.2, 2.9][fb]\n","        phase = [0.0, 0.5*np.pi, np.pi, 1.5*np.pi][pb]\n","        thick = [0.08, 0.14, 0.22][tb]\n","\n","        # base pattern families (shape): sine planes, radial rings, diagonal bars\n","        if s == 0:\n","            base = np.sin(freq*(self.X + self.Y) + phase)\n","        elif s == 1:\n","            R = np.sqrt(self.X**2 + self.Y**2) + 1e-8\n","            base = np.sin(freq*(2.5*R) + phase)\n","        else:\n","            base = np.sin(freq*(self.X - self.Y) + phase)\n","\n","        # orientation as a simple rotation-like mixing\n","        if o == 0:\n","            img = base\n","        elif o == 1:\n","            img = np.sin(freq*(self.X) + phase)\n","        elif o == 2:\n","            img = np.sin(freq*(self.Y) + phase)\n","        else:\n","            img = np.sin(freq*(self.X + 0.35*self.Y) + phase)\n","\n","        # thickness as sharpening/nonlinearity\n","        img = np.tanh(img / (thick + 1e-6))\n","\n","        # add controlled noise\n","        img = img + self.cfg.noise_image * np.random.randn(*img.shape)\n","        return img.astype(np.float32).reshape(-1)\n","\n","    def factors_to_tokens(self, f: Factors) -> np.ndarray:\n","        # sequence: [shape][sep][orient][sep][freq][sep][phase][sep][thick][pad...]\n","        n = f.shape.shape[0]\n","        seq = np.full((n, self.cfg.text_seq_len), self.pad_id, dtype=np.int64)\n","        # minimal length needed = 9 tokens (shape,sep,orient,sep,freq,sep,phase,sep,thick)\n","        # Optional guard: auto-upgrade seq len rather than erroring\n","        if self.cfg.text_seq_len < 9:\n","            raise ValueError(f\"text_seq_len must be >= 9 for this grammar (got {self.cfg.text_seq_len}). \"\n","                            f\"Fix: set Config.text_seq_len=9 or higher.\")\n","\n","        seq[:, 0] = self.base_shape + f.shape\n","        seq[:, 1] = self.sep_id\n","        seq[:, 2] = self.base_orient + f.orient\n","        seq[:, 3] = self.sep_id\n","        seq[:, 4] = self.base_freq + f.freq_bin\n","        seq[:, 5] = self.sep_id\n","        seq[:, 6] = self.base_phase + f.phase_bin\n","        seq[:, 7] = self.sep_id\n","        seq[:, 8] = self.base_thick + f.thick_bin\n","        return seq\n","\n","    def tokens_to_bow_pos(self, seq: np.ndarray) -> np.ndarray:\n","        # bag-of-tokens + simple positional features (token_id * position one-hot-ish)\n","        n, L = seq.shape\n","        V = self.cfg.vocab_size\n","        bow = np.zeros((n, V), dtype=np.float32)\n","        for pos in range(L):\n","            ids = seq[:, pos]\n","            bow[np.arange(n), ids] += 1.0\n","        # positional moments: mean token id, std token id, and sep count (as 3 extra dims)\n","        mean_id = seq.mean(axis=1, keepdims=True).astype(np.float32)\n","        std_id = seq.std(axis=1, keepdims=True).astype(np.float32)\n","        sep_count = (seq == self.sep_id).sum(axis=1, keepdims=True).astype(np.float32)\n","        feats = np.concatenate([bow, mean_id, std_id, sep_count], axis=1)\n","        return feats  # shape (n, V+3)\n","\n","    def build_dataset(self, n: int) -> Tuple[np.ndarray, np.ndarray, Dict[str, np.ndarray]]:\n","        f = self.sample_factors(n)\n","        imgs = np.stack([self._render_image(int(f.shape[i]), int(f.orient[i]), int(f.freq_bin[i]), int(f.phase_bin[i]), int(f.thick_bin[i]))\n","                         for i in range(n)], axis=0)\n","        seq = self.factors_to_tokens(f)\n","        txt = self.tokens_to_bow_pos(seq)\n","        meta = {\n","            \"shape\": f.shape, \"orient\": f.orient, \"freq_bin\": f.freq_bin, \"phase_bin\": f.phase_bin, \"thick_bin\": f.thick_bin\n","        }\n","        return imgs, txt, meta\n","\n","def split_indices(n: int, train_frac: float, val_frac: float, seed: int) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n","    rng = np.random.RandomState(seed)\n","    idx = rng.permutation(n)\n","    n_train = int(train_frac * n)\n","    n_val = int(val_frac * n)\n","    train = idx[:n_train]\n","    val = idx[n_train:n_train+n_val]\n","    test = idx[n_train+n_val:]\n","    # split hygiene check\n","    assert len(set(train).intersection(set(val))) == 0\n","    assert len(set(train).intersection(set(test))) == 0\n","    assert len(set(val).intersection(set(test))) == 0\n","    return train, val, test\n","\n","WORLD = SyntheticWorld(CFG)\n","X_img, X_txt, META = WORLD.build_dataset(CFG.n)\n","\n","train_idx, val_idx, test_idx = split_indices(CFG.n, CFG.train_frac, CFG.val_frac, CFG.seed)\n","\n","print(\"DATASET\")\n","print(\"  X_img:\", X_img.shape, \"X_txt:\", X_txt.shape)\n","print(\"  splits:\", len(train_idx), len(val_idx), len(test_idx))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yFn6OrVdnOTk","executionInfo":{"status":"ok","timestamp":1771332515480,"user_tz":360,"elapsed":81,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"0f53f388-ca44-459f-b41b-03cb3e9674fe"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["DATASET\n","  X_img: (2048, 256) X_txt: (2048, 35)\n","  splits: 1433 307 308\n"]}]},{"cell_type":"markdown","source":["##4.ENCODER ARCHITECTURE"],"metadata":{"id":"7CdFvriyiHh-"}},{"cell_type":"markdown","source":["###4.1.OVERVIEW"],"metadata":{"id":"r7AlxPj_iI11"}},{"cell_type":"markdown","source":["**Cell 4 — Two-Layer MLP Encoders (Why Small Models Teach Better Than Large Ones Here)**\n","\n","Cell 4 defines the encoders: one for images and one for text. The key pedagogical aim is to show that multimodal alignment does not require massive architectures. The mechanism is learnable with a small 2-layer MLP when the data is structured and the objective is correct. This is important because it prevents students from concluding that multimodality is “something only big labs can do.” Instead, they learn that multimodality is a principle: align projections of shared causes into a commensurable space.\n","\n","The 2-layer MLP is also a didactic choice: it is complex enough to be non-trivial (nonlinear feature extraction) but simple enough to be inspectable and to implement with manual backprop. By caching intermediate activations (pre-activation, activation, unnormalized embedding, normalization factor), the model becomes a transparent computational graph. Students can point to exactly where each transformation happens and how each contributes to the final embedding geometry.\n","\n","Normalization is crucial. We L2-normalize embeddings so that cosine similarity is meaningful and stable. Students should learn that without normalization, the model can “cheat” by inflating norms rather than learning directional structure. Normalization enforces a geometric discipline: similarity is about angles, not magnitudes. This stabilizes training and makes retrieval behavior more interpretable.\n","\n","The activation function is another lesson: ReLU is common, but it introduces nondifferentiability at zero, which complicates finite-difference gradient checks. Using a leaky variant is not a trick; it is an engineering choice that supports rigorous validation. This is a subtle but important lesson: theoretical elegance (pure ReLU) sometimes conflicts with experimental verifiability, and in professional research you often choose the version that supports reliable diagnostics.\n","\n","Finally, this cell introduces the idea that each modality has its own encoder parameters. There is no forced weight sharing. Alignment emerges from the objective, not from architectural constraints. That is the right mental model: the shared space is not imposed; it is learned because it is useful for the task.\n"],"metadata":{"id":"ueNd8fXviKfV"}},{"cell_type":"markdown","source":["###4.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"WYXG5UW3iK2O"}},{"cell_type":"code","source":["# === Cell 4 (REPLACE) ===\n","# Title: 2-Layer MLP Encoder with LeakyReLU + Exact L2-Norm Backprop\n","# Explanation: PATCH — LeakyReLU avoids ReLU kink issues so finite-difference checks match analytic gradients.\n","\n","def act(x: np.ndarray, leak: float) -> np.ndarray:\n","    return np.where(x > 0.0, x, leak * x)\n","\n","def act_grad(x: np.ndarray, leak: float) -> np.ndarray:\n","    # IMPORTANT: preserve dtype so float64 gradient checks are numerically stable\n","    return np.where(x > 0.0, 1.0, leak).astype(x.dtype)\n","\n","def l2_normalize(z: np.ndarray, eps: float = 1e-8) -> Tuple[np.ndarray, np.ndarray]:\n","    nrm = np.linalg.norm(z, axis=1, keepdims=True)\n","    nrm = np.maximum(nrm, eps)\n","    return z / nrm, nrm\n","\n","def l2_normalize_backward(dy: np.ndarray, z: np.ndarray, nrm: np.ndarray, eps: float = 1e-8) -> np.ndarray:\n","    inv = 1.0 / np.maximum(nrm, eps)                # (B,1)\n","    dot = np.sum(dy * z, axis=1, keepdims=True)     # (B,1)\n","    dz = dy * inv - z * (dot * (inv**3))\n","    return dz\n","\n","class MLP2:\n","    def __init__(self, in_dim: int, hidden: int, out_dim: int, seed: int, leak: float):\n","        self.leak = float(leak)\n","        rng = np.random.RandomState(seed)\n","        self.W1 = (rng.randn(in_dim, hidden).astype(np.float32) * math.sqrt(2.0 / in_dim))\n","        self.b1 = np.zeros((1, hidden), dtype=np.float32)\n","        self.W2 = (rng.randn(hidden, out_dim).astype(np.float32) * math.sqrt(2.0 / hidden))\n","        self.b2 = np.zeros((1, out_dim), dtype=np.float32)\n","\n","        self.m = {k: np.zeros_like(v) for k, v in self.params().items()}\n","        self.v = {k: np.zeros_like(v) for k, v in self.params().items()}\n","        self.t = 0\n","\n","    def params(self) -> Dict[str, np.ndarray]:\n","        return {\"W1\": self.W1, \"b1\": self.b1, \"W2\": self.W2, \"b2\": self.b2}\n","\n","    def forward(self, x: np.ndarray) -> Dict[str, np.ndarray]:\n","        h_pre = x @ self.W1 + self.b1\n","        h = act(h_pre, self.leak)\n","        z = h @ self.W2 + self.b2\n","        y, nrm = l2_normalize(z)\n","        return {\"x\": x, \"h_pre\": h_pre, \"h\": h, \"z\": z, \"y\": y, \"nrm\": nrm}\n","\n","    def backward(self, cache: Dict[str, np.ndarray], dy: np.ndarray) -> Dict[str, np.ndarray]:\n","        x, h_pre, h, z, nrm = cache[\"x\"], cache[\"h_pre\"], cache[\"h\"], cache[\"z\"], cache[\"nrm\"]\n","        dz = l2_normalize_backward(dy, z, nrm)\n","\n","        dW2 = h.T @ dz\n","        db2 = dz.sum(axis=0, keepdims=True)\n","\n","        dh = dz @ self.W2.T\n","        dh_pre = dh * act_grad(h_pre, self.leak)\n","\n","        dW1 = x.T @ dh_pre\n","        db1 = dh_pre.sum(axis=0, keepdims=True)\n","\n","        return {\"W1\": dW1, \"b1\": db1, \"W2\": dW2, \"b2\": db2}\n","\n","    def adam_step(self, grads: Dict[str, np.ndarray], lr: float, b1: float, b2: float, eps: float,\n","                  weight_decay: float, grad_clip: float) -> Dict[str, float]:\n","        self.t += 1\n","        stats: Dict[str, float] = {}\n","        for k, p in self.params().items():\n","            g = grads[k].astype(np.float32)\n","\n","            gn = float(np.linalg.norm(g))\n","            if gn > grad_clip:\n","                g = g * (grad_clip / (gn + 1e-12))\n","            stats[f\"grad_norm_{k}\"] = float(gn)\n","\n","            if k.startswith(\"W\") and weight_decay > 0.0:\n","                p *= (1.0 - lr * weight_decay)\n","\n","            self.m[k] = b1 * self.m[k] + (1.0 - b1) * g\n","            self.v[k] = b2 * self.v[k] + (1.0 - b2) * (g * g)\n","\n","            mhat = self.m[k] / (1.0 - b1**self.t)\n","            vhat = self.v[k] / (1.0 - b2**self.t)\n","\n","            p -= lr * mhat / (np.sqrt(vhat) + eps)\n","\n","        return stats\n","\n","IMG = MLP2(in_dim=X_img.shape[1], hidden=CFG.hidden, out_dim=CFG.embed_dim, seed=CFG.seed + 11, leak=CFG.relu_leak)\n","TXT = MLP2(in_dim=X_txt.shape[1], hidden=CFG.hidden, out_dim=CFG.embed_dim, seed=CFG.seed + 23, leak=CFG.relu_leak)\n","\n","print(\"MLP2 (LeakyReLU) encoders ready.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dVxYisp3pBti","executionInfo":{"status":"ok","timestamp":1771332606397,"user_tz":360,"elapsed":16,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"bee742f9-82ce-4207-c75f-660a6c132488"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["MLP2 (LeakyReLU) encoders ready.\n"]}]},{"cell_type":"markdown","source":["##5.ANALYTIC GRADIENT STRUCTURE"],"metadata":{"id":"PJydwmXniOfj"}},{"cell_type":"markdown","source":["###5.1.OVERVIEW"],"metadata":{"id":"MeZ0d501iP49"}},{"cell_type":"markdown","source":["**Cell 5 — Symmetric InfoNCE and Gradient Signals (Where “Alignment” Becomes an Optimization Problem)**\n","\n","Cell 5 defines the contrastive objective that drives alignment. Students often think alignment is a vague desire—“make images and text match.” Here it becomes precise: for a batch of paired samples, each image embedding must identify its matching text embedding among all texts in the batch, and each text embedding must identify its matching image embedding among all images. This is why the objective is symmetric. If you train only one direction, you often get a lopsided space that performs well in one retrieval direction but poorly in the other.\n","\n","The crucial mathematical idea is that the loss depends on a similarity matrix. Every entry in this matrix is a geometric relationship between an image embedding and a text embedding. The diagonal entries are positives (true pairs), and the off-diagonal entries are negatives (mismatched pairs). The softmax transforms these similarities into a distribution over candidates. The loss penalizes the model when the correct match does not dominate the distribution. Students should see that “learning meaning” here is “learning to shape the similarity matrix.”\n","\n","Temperature is the main control knob. Lower temperature makes the softmax sharper, pushing the model to separate positives from negatives more aggressively. Higher temperature makes the distribution smoother, often improving stability but weakening discrimination. Students should learn to interpret temperature as a geometric scaling: it changes the effective margin in the embedding space.\n","\n","Another key lesson is numerical stability. We use stable softmax/log-sum-exp patterns to avoid overflow and underflow. This is not merely about avoiding errors. Stability affects learning dynamics. If your probabilities saturate to 0 or 1 due to numeric issues, gradient signals vanish or explode. In multimodal training, where the similarity matrix can be large and dynamic, stability is a first-class requirement.\n","\n","Finally, the gradients produced by InfoNCE teach students what “contrastive learning pressure” looks like. Positives are pulled together (increase diagonal similarity), negatives are pushed apart (decrease off-diagonal similarity). But this pushing is not uniform. Hard negatives—those that are already similar—receive stronger gradient pressure. That is why batch composition matters: the set of negatives you present defines what the model learns to discriminate. This cell is where students learn that alignment is a choice about what distinctions matter.\n"],"metadata":{"id":"WY3hc3q2iSKx"}},{"cell_type":"markdown","source":["###5.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"fzeMhbzgiShs"}},{"cell_type":"code","source":["# === Cell 5 ===\n","# Title: Symmetric InfoNCE (Stable LogSumExp) + Exact Gradients w.r.t. Embeddings\n","# Explanation: Implements bidirectional InfoNCE with numerically stable softmax,\n","# and derives exact gradients dL/dY_img and dL/dY_txt (then backprop into MLPs).\n","\n","def logsumexp(a: np.ndarray, axis: int) -> np.ndarray:\n","    m = np.max(a, axis=axis, keepdims=True)\n","    return m + np.log(np.sum(np.exp(a - m), axis=axis, keepdims=True) + 1e-12)\n","\n","def softmax(a: np.ndarray, axis: int) -> np.ndarray:\n","    a = a - np.max(a, axis=axis, keepdims=True)\n","    e = np.exp(a)\n","    return e / (np.sum(e, axis=axis, keepdims=True) + 1e-12)\n","\n","def contrastive_symmetric(Yi: np.ndarray, Yt: np.ndarray, temp: float) -> Tuple[float, np.ndarray, np.ndarray, Dict[str, Any]]:\n","    \"\"\"\n","    Yi, Yt are L2-normalized embeddings (B,D).\n","    sim = Yi @ Yt^T.\n","    Loss = 0.5*(CE_rows(sim/temp) + CE_rows(sim.T/temp))\n","    Return loss, dYi, dYt, and metrics.\n","    \"\"\"\n","    B = Yi.shape[0]\n","    sim = Yi @ Yt.T                           # (B,B)\n","    logits = sim / temp\n","\n","    P_it = softmax(logits, axis=1)            # rows: image->text\n","    P_ti = softmax(logits.T, axis=1)          # rows: text->image (equiv cols of P_it)\n","\n","    # cross entropy with correct match on diagonal\n","    loss_it = -np.mean(np.log(np.diag(P_it) + 1e-12))\n","    loss_ti = -np.mean(np.log(np.diag(P_ti) + 1e-12))\n","    loss = 0.5 * (loss_it + loss_ti)\n","\n","    # Gradients:\n","    # For CE over rows: dL/dlogits = (P - I)/B\n","    I = np.eye(B, dtype=np.float32)\n","    dlogits_it = (P_it - I) / B               # (B,B)\n","    dlogits_ti = (P_ti - I) / B               # (B,B) over logits.T\n","\n","    # Combine on logits (not logits.T) properly:\n","    # d/dlogits from second term is transpose of dlogits_ti\n","    dlogits = 0.5 * (dlogits_it + dlogits_ti.T)  # (B,B)\n","\n","    dsim = dlogits / temp                     # (B,B)\n","\n","    # sim = Yi @ Yt^T\n","    dYi = dsim @ Yt                           # (B,D)\n","    dYt = dsim.T @ Yi                         # (B,D)\n","\n","    metrics = {\n","        \"loss_it\": float(loss_it),\n","        \"loss_ti\": float(loss_ti),\n","        \"mean_pos_sim\": float(np.mean(np.diag(sim))),\n","        \"mean_sim\": float(np.mean(sim)),\n","    }\n","    return float(loss), dYi.astype(np.float32), dYt.astype(np.float32), metrics\n","\n","# quick shape sanity\n","b = 8\n","ci = IMG.forward(X_img[:b])\n","ct = TXT.forward(X_txt[:b])\n","L, dYi, dYt, met = contrastive_symmetric(ci[\"y\"], ct[\"y\"], CFG.temp)\n","assert dYi.shape == ci[\"y\"].shape and dYt.shape == ct[\"y\"].shape\n","print(\"Contrastive core OK. loss =\", L, \"metrics =\", met)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6dFDWckRnhd2","executionInfo":{"status":"ok","timestamp":1771332523675,"user_tz":360,"elapsed":29,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"2a489d68-c299-4b7b-be9c-6d0e3a4e9ec7"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["Contrastive core OK. loss = 2.6602158546447754 metrics = {'loss_it': 2.0775787830352783, 'loss_ti': 3.2428526878356934, 'mean_pos_sim': -0.07171455025672913, 'mean_sim': -0.07997961342334747}\n"]}]},{"cell_type":"markdown","source":["##6.GRADIENT CHECK"],"metadata":{"id":"3qMrcRA8iVGP"}},{"cell_type":"markdown","source":["###6.1.OVERVIEW"],"metadata":{"id":"3Ak9KwaQiXOz"}},{"cell_type":"markdown","source":["**Cell 6 — Gradient Checking (Why We Refuse to Trust Ourselves Without Evidence)**\n","\n","Cell 6 is the governance heart of the notebook. It answers a simple but profound question: how do we know our training loop is correct? In most deep learning workflows, you rely on autodiff libraries and assume the gradients are right. Here we are implementing backprop manually, so we must validate it. The pedagogical lesson is that “working code” is not the same as “correct optimization.” A model can produce decreasing loss even with incorrect gradients, especially if the problem is forgiving.\n","\n","Finite-difference gradient checking provides a local correctness test. We perturb a parameter slightly and measure how the loss changes. That numeric slope should match the analytic gradient computed by our backprop pipeline. If it does not, we treat the run as invalid. This is not optional. It is what makes the notebook a laboratory rather than a performance show.\n","\n","Students should also learn why we do the check in float64. In float32, very small perturbations can be swallowed by numerical precision, making the numeric gradient appear as zero. That failure is not a sign that gradients are zero; it is a sign that your measurement instrument is too coarse. Switching to float64 for the check is an engineering choice that increases measurement resolution. This reinforces the broader theme: embeddings are measurements, and measurements require appropriate precision.\n","\n","Gradient checking is not meant to be exhaustive. We do not check every parameter; we check random probes. This teaches a statistical mindset: we sample checks to catch gross errors, especially sign errors, missing terms, or dtype issues. In professional systems, you combine this with unit-test-like shape assertions and NaN checks to build confidence in the computational pipeline.\n","\n","Finally, Cell 6 teaches a cultural habit: hard failure on correctness gates. If the gradient check fails, we stop. We do not rationalize. We do not accept the run “because it mostly works.” This is precisely the posture students need for frontier topics. When systems become complex, the temptation to accept results based on plausibility increases. This cell trains the opposite muscle: correctness before interpretation.\n"],"metadata":{"id":"Fnhd7Fwaicyv"}},{"cell_type":"markdown","source":["###6.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"0jFxOakbido7"}},{"cell_type":"code","source":["# === Cell 6 (REPLACE ENTIRE CELL) ===\n","# Title: Finite-Difference Gradient Check (Float64 Clone, Central Difference)\n","# Explanation: Runs end-to-end gradient checks in float64 to avoid float32 quantization.\n","# Clones models into float64, computes analytic grads, and compares with central differences.\n","\n","def clone_model_to_float64(src: MLP2) -> MLP2:\n","    dst = MLP2(\n","        in_dim=src.W1.shape[0],\n","        hidden=src.W1.shape[1],\n","        out_dim=src.W2.shape[1],\n","        seed=123,          # overwritten immediately\n","        leak=src.leak\n","    )\n","    # overwrite parameters (float64)\n","    dst.W1 = src.W1.astype(np.float64).copy()\n","    dst.b1 = src.b1.astype(np.float64).copy()\n","    dst.W2 = src.W2.astype(np.float64).copy()\n","    dst.b2 = src.b2.astype(np.float64).copy()\n","\n","    # reset optimizer state in float64 (not used in check, but keeps structure consistent)\n","    dst.m = {k: np.zeros_like(v) for k, v in dst.params().items()}\n","    dst.v = {k: np.zeros_like(v) for k, v in dst.params().items()}\n","    dst.t = 0\n","    return dst\n","\n","def loss_only(model_a: MLP2, model_b: MLP2, Xa: np.ndarray, Xb: np.ndarray) -> float:\n","    ca = model_a.forward(Xa)\n","    cb = model_b.forward(Xb)\n","    loss, _, _, _ = contrastive_symmetric(ca[\"y\"], cb[\"y\"], CFG.temp)\n","    return float(loss)\n","\n","def analytic_grads(model_a: MLP2, model_b: MLP2, Xa: np.ndarray, Xb: np.ndarray) -> Dict[str, np.ndarray]:\n","    ca = model_a.forward(Xa)\n","    cb = model_b.forward(Xb)\n","    loss, dYa, dYb, _ = contrastive_symmetric(ca[\"y\"], cb[\"y\"], CFG.temp)\n","    ga = model_a.backward(ca, dYa)\n","    # (We only check grads for model_a here; symmetric check could also validate model_b)\n","    return ga\n","\n","def finite_diff_param(model_a: MLP2, model_b: MLP2, Xa: np.ndarray, Xb: np.ndarray,\n","                      param_name: str, num_checks: int, eps: float, tol: float) -> Dict[str, Any]:\n","    ga = analytic_grads(model_a, model_b, Xa, Xb)\n","    P = model_a.params()[param_name]\n","    G = ga[param_name]\n","\n","    rng = np.random.RandomState(CFG.seed + 2026)\n","    worst = {\"rel_err\": -1.0, \"idx\": None, \"num\": None, \"ana\": None}\n","\n","    if P.ndim == 2:\n","        coords = [(rng.randint(0, P.shape[0]), rng.randint(0, P.shape[1])) for _ in range(num_checks)]\n","    else:\n","        coords = [(0, rng.randint(0, P.shape[1])) for _ in range(num_checks)]\n","\n","    base_loss = loss_only(model_a, model_b, Xa, Xb)\n","\n","    for (i, j) in coords:\n","        orig = float(P[i, j])\n","\n","        P[i, j] = orig + eps\n","        lp = loss_only(model_a, model_b, Xa, Xb)\n","\n","        P[i, j] = orig - eps\n","        lm = loss_only(model_a, model_b, Xa, Xb)\n","\n","        P[i, j] = orig  # restore\n","\n","        num = float((lp - lm) / (2.0 * eps))\n","        ana = float(G[i, j])\n","\n","        denom = max(1e-12, abs(num) + abs(ana))\n","        rel = float(abs(num - ana) / denom)\n","\n","        if rel > worst[\"rel_err\"]:\n","            worst = {\"rel_err\": rel, \"idx\": (int(i), int(j)), \"num\": num, \"ana\": ana}\n","\n","    passed = worst[\"rel_err\"] <= tol\n","    return {\n","        \"param\": param_name,\n","        \"base_loss\": float(base_loss),\n","        \"eps\": float(eps),\n","        \"tol\": float(tol),\n","        \"worst\": worst,\n","        \"passed\": passed\n","    }\n","\n","# ----- run float64 gradient check on clones -----\n","IMG64 = clone_model_to_float64(IMG)\n","TXT64 = clone_model_to_float64(TXT)\n","\n","B = 16\n","Xa = X_img[train_idx[:B]].astype(np.float64)\n","Xb = X_txt[train_idx[:B]].astype(np.float64)\n","\n","# eps: float64-friendly; tol: realistic for a manual system with normalization and softmax\n","eps = 1e-6\n","tol = 2e-4\n","num_checks = 18\n","\n","report = []\n","for pname in [\"W1\", \"W2\", \"b1\", \"b2\"]:\n","    rep = finite_diff_param(IMG64, TXT64, Xa, Xb, pname, num_checks=num_checks, eps=eps, tol=tol)\n","    report.append(rep)\n","\n","AM.write_json_strict(\n","    os.path.join(CFG.gates_dir, \"gate_gradient_check.json\"),\n","    facts_provided={\"gradient_check_report\": report},\n","    assumptions={\n","        \"dtype\": \"float64 for finite-difference stability\",\n","        \"central_difference\": True,\n","        \"eps\": eps,\n","        \"tol_rel\": tol,\n","        \"activation\": f\"LeakyReLU(leak={CFG.relu_leak})\",\n","    },\n","    open_items=[],\n","    analysis=\"Gradient check executed on float64 clones to eliminate float32 quantization (loss_p == loss_m). Central differences validate manual backprop through activation + L2 normalization + symmetric InfoNCE.\",\n","    draft_output={\"passed\": all(r[\"passed\"] for r in report)},\n","    verification_status=\"Not verified\",\n","    questions_to_verify=[\"Does the check pass across multiple random seeds and larger batch sizes?\"]\n",")\n","\n","assert all(r[\"passed\"] for r in report), f\"Gradient check failed: {report}\"\n","print(\"Gradient checks PASSED (float64).\")\n","for r in report:\n","    print(r[\"param\"], \"worst_rel_err=\", r[\"worst\"][\"rel_err\"], \"idx=\", r[\"worst\"][\"idx\"])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p0gINRhfpsKT","executionInfo":{"status":"ok","timestamp":1771332621302,"user_tz":360,"elapsed":76,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"481f91f6-5ed8-4a36-c73a-386d2d8a52db"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["Gradient checks PASSED (float64).\n","W1 worst_rel_err= 6.810010923270595e-08 idx= (205, 180)\n","W2 worst_rel_err= 1.66649471053262e-07 idx= (153, 22)\n","b1 worst_rel_err= 1.1187579371748174e-06 idx= (0, 223)\n","b2 worst_rel_err= 1.955514531908551e-07 idx= (0, 25)\n"]}]},{"cell_type":"markdown","source":["##7.TRAINING LOOP"],"metadata":{"id":"hnqxNRdOigzp"}},{"cell_type":"markdown","source":["###7.1.OVERVIEW"],"metadata":{"id":"9N3hP5ksikQZ"}},{"cell_type":"markdown","source":["**Cell 7 — Training Loop as a Controlled Experiment (Metrics, Checkpoints, and Convergence Discipline)**\n","\n","Cell 7 is where the model actually learns, but the pedagogical emphasis is not “watch the loss go down.” The emphasis is “treat training as a controlled experiment with measured outcomes.” We implement a training loop with mini-batching, an optimizer (AdamW), gradient clipping, and checkpointing based on validation metrics. Each of these elements teaches a professional lesson about how real multimodal systems are trained and managed.\n","\n","AdamW is used because it is a practical optimizer that separates weight decay from gradient updates. Students should learn that weight decay is not just regularization in an abstract sense; it shapes representation geometry by discouraging parameter blow-up and improving generalization. Gradient clipping is included because contrastive objectives can generate unstable gradients, especially early in training when similarity matrices are noisy. Clipping is a risk control: it prevents the system from taking catastrophic steps that destroy learning.\n","\n","Checkpointing based on validation performance teaches students to separate training success from generalization. In contrastive learning, it is possible to improve training loss while overfitting to batch-specific structures or exploiting spurious correlations. Validation retrieval metrics provide a more meaningful criterion: does the shared space work on held-out pairs? Selecting the best checkpoint by validation recall@1 instills the habit of defining acceptance on what matters operationally.\n","\n","This cell also logs multiple metrics per epoch, not just loss. Students should learn that loss is an internal optimization quantity, while retrieval metrics are task-relevant behaviors. In a multimodal model used for search or matching, retrieval accuracy is closer to the professional objective than loss. The cell reinforces the idea that the model is a component in a system: you choose the metric that corresponds to the system’s function.\n","\n","Finally, students should learn that training is not an endpoint. It is a phase in a pipeline that includes evaluation and stress testing. The output of training is not merely weights; it is a set of artifacts that record the training history, the chosen checkpoint, and the conditions under which those results were obtained. That makes the later interpretation of embedding geometry credible.\n"],"metadata":{"id":"MzaMhrkuimFO"}},{"cell_type":"markdown","source":["###7.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"epotbIpqimYU"}},{"cell_type":"code","source":["# === Cell 7 ===\n","# Title: Trainer (AdamW, Clipping, Checkpointing, Epoch Metrics)\n","# Explanation: Implements a production-style training loop with mini-batching, AdamW updates,\n","# gradient clipping, per-epoch metrics, and best-checkpoint saving.\n","\n","def iter_batches(indices: np.ndarray, batch: int, seed: int) -> List[np.ndarray]:\n","    rng = np.random.RandomState(seed)\n","    perm = rng.permutation(indices)\n","    return [perm[i:i+batch] for i in range(0, len(perm), batch)]\n","\n","def retrieval_metrics(sim: np.ndarray, ks: Tuple[int, int]) -> Dict[str, float]:\n","    # sim: (N,N) similarity, correct match on diagonal\n","    N = sim.shape[0]\n","    order = np.argsort(-sim, axis=1)  # descending\n","    ranks = np.empty(N, dtype=np.int64)\n","    for i in range(N):\n","        ranks[i] = int(np.where(order[i] == i)[0][0]) + 1  # 1-based\n","    out = {}\n","    for k in ks:\n","        out[f\"recall@{k}\"] = float(np.mean(ranks <= k))\n","    out[\"mrr\"] = float(np.mean(1.0 / ranks))\n","    out[\"mean_rank\"] = float(np.mean(ranks))\n","    return out\n","\n","def embed_all(model: MLP2, X: np.ndarray, batch: int = 512) -> np.ndarray:\n","    Ys = []\n","    for i in range(0, X.shape[0], batch):\n","        c = model.forward(X[i:i+batch])\n","        Ys.append(c[\"y\"])\n","    return np.vstack(Ys)\n","\n","def eval_split(split_name: str, idx: np.ndarray) -> Dict[str, float]:\n","    Yi = embed_all(IMG, X_img[idx])\n","    Yt = embed_all(TXT, X_txt[idx])\n","    sim = Yi @ Yt.T\n","    m_it = retrieval_metrics(sim, CFG.topk)\n","    m_ti = retrieval_metrics(sim.T, CFG.topk)\n","    out = {f\"{split_name}_i2t_{k}\": v for k, v in m_it.items()}\n","    out.update({f\"{split_name}_t2i_{k}\": v for k, v in m_ti.items()})\n","    out[f\"{split_name}_sym_gap_recall@1\"] = float(abs(m_it[\"recall@1\"] - m_ti[\"recall@1\"]))\n","    out[f\"{split_name}_mean_pos_sim\"] = float(np.mean(np.diag(sim)))\n","    return out\n","\n","def save_checkpoint(path: str) -> None:\n","    ckpt = {\n","        \"IMG\": {k: v.tolist() for k, v in IMG.params().items()},\n","        \"TXT\": {k: v.tolist() for k, v in TXT.params().items()},\n","        \"meta\": {\"run_id\": AM.run_id, \"utc\": utc_now_iso()},\n","    }\n","    with open(path, \"w\") as f:\n","        json.dump(ckpt, f)\n","\n","best_val = -1.0\n","history: List[Dict[str, Any]] = []\n","\n","for epoch in range(1, CFG.epochs + 1):\n","    batches = iter_batches(train_idx, CFG.batch, seed=CFG.seed + epoch)\n","    epoch_losses = []\n","    grad_stats_accum = []\n","\n","    for bidx in batches:\n","        Xi = X_img[bidx].astype(np.float32)\n","        Xt = X_txt[bidx].astype(np.float32)\n","\n","        ci = IMG.forward(Xi)\n","        ct = TXT.forward(Xt)\n","        loss, dYi, dYt, lmet = contrastive_symmetric(ci[\"y\"], ct[\"y\"], CFG.temp)\n","\n","        gi = IMG.backward(ci, dYi)\n","        gt = TXT.backward(ct, dYt)\n","\n","        # update\n","        si = IMG.adam_step(gi, CFG.lr, CFG.adam_b1, CFG.adam_b2, CFG.adam_eps, CFG.weight_decay, CFG.grad_clip)\n","        st = TXT.adam_step(gt, CFG.lr, CFG.adam_b1, CFG.adam_b2, CFG.adam_eps, CFG.weight_decay, CFG.grad_clip)\n","\n","        epoch_losses.append(loss)\n","        grad_stats_accum.append({**si, **{f\"txt_{k}\": v for k, v in st.items()}, **lmet})\n","\n","    # eval\n","    tr = eval_split(\"train\", train_idx[:min(512, len(train_idx))])  # bounded eval for speed\n","    va = eval_split(\"val\", val_idx)\n","\n","    row = {\n","        \"epoch\": epoch,\n","        \"loss\": float(np.mean(epoch_losses)),\n","        \"loss_std\": float(np.std(epoch_losses)),\n","        **tr,\n","        **va,\n","        \"grad_norm_W1_mean\": float(np.mean([g[\"grad_norm_W1\"] for g in grad_stats_accum])),\n","        \"grad_norm_W2_mean\": float(np.mean([g[\"grad_norm_W2\"] for g in grad_stats_accum])),\n","        \"utc\": utc_now_iso(),\n","    }\n","    history.append(row)\n","\n","    # checkpoint on val recall@1 (i2t)\n","    key = \"val_i2t_recall@1\"\n","    score = row[key]\n","    if score > best_val:\n","        best_val = score\n","        ckpt_path = os.path.join(CFG.ckpt_dir, \"best_checkpoint.json\")\n","        save_checkpoint(ckpt_path)\n","\n","    if epoch % 5 == 0 or epoch == 1:\n","        print(f\"Epoch {epoch:03d} | loss={row['loss']:.4f} | val_r@1(i2t)={row['val_i2t_recall@1']:.3f} | val_sym_gap={row['val_sym_gap_recall@1']:.3f}\")\n","\n","# Save training curve\n","with open(os.path.join(CFG.out_dir, \"train_history.json\"), \"w\") as f:\n","    json.dump(history, f, indent=2)\n","\n","print(\"Training done. best val_i2t_recall@1 =\", best_val)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uttVAC2YnoSj","executionInfo":{"status":"ok","timestamp":1771332637099,"user_tz":360,"elapsed":6970,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"be488665-436b-4467-a8b3-b11762511bd7"},"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 001 | loss=4.8407 | val_r@1(i2t)=0.033 | val_sym_gap=0.013\n","Epoch 005 | loss=1.3285 | val_r@1(i2t)=0.202 | val_sym_gap=0.020\n","Epoch 010 | loss=1.1369 | val_r@1(i2t)=0.248 | val_sym_gap=0.033\n","Epoch 015 | loss=1.0378 | val_r@1(i2t)=0.231 | val_sym_gap=0.107\n","Epoch 020 | loss=0.8004 | val_r@1(i2t)=0.329 | val_sym_gap=0.075\n","Epoch 025 | loss=0.8408 | val_r@1(i2t)=0.339 | val_sym_gap=0.029\n","Epoch 030 | loss=0.8021 | val_r@1(i2t)=0.332 | val_sym_gap=0.065\n","Epoch 035 | loss=0.7947 | val_r@1(i2t)=0.336 | val_sym_gap=0.107\n","Epoch 040 | loss=0.6899 | val_r@1(i2t)=0.358 | val_sym_gap=0.052\n","Epoch 045 | loss=0.7277 | val_r@1(i2t)=0.368 | val_sym_gap=0.075\n","Epoch 050 | loss=0.7007 | val_r@1(i2t)=0.349 | val_sym_gap=0.075\n","Epoch 055 | loss=0.6413 | val_r@1(i2t)=0.384 | val_sym_gap=0.068\n","Epoch 060 | loss=0.6711 | val_r@1(i2t)=0.358 | val_sym_gap=0.029\n","Training done. best val_i2t_recall@1 = 0.41368078175895767\n"]}]},{"cell_type":"markdown","source":["##8.RETRIEVAL AND SPECTRAL DIAGNOSTICS"],"metadata":{"id":"BLus531lirIL"}},{"cell_type":"markdown","source":["###8.1.OVERVIEW"],"metadata":{"id":"x0j2JYTnixuf"}},{"cell_type":"markdown","source":["**Cell 8 — Evaluation: Geometry as Evidence (Retrieval, Separability, Collapse, Spectra, Visuals)**\n","\n","Cell 8 is designed to teach students how to “read” an embedding space responsibly. Many people stop at retrieval accuracy and declare victory. This cell insists that retrieval is necessary but not sufficient. We examine geometry through multiple lenses: retrieval metrics, factor separability, collapse diagnostics, covariance spectra, modality symmetry, and visual projections. The pedagogical goal is to replace narrative interpretation with structured evidence.\n","\n","Retrieval metrics (recall@k and MRR) are the operational core: can an image find its paired text, and can a text find its paired image? These metrics measure whether the shared space is actually shared. We evaluate both directions because asymmetry is a common failure mode and because many real applications need both query directions.\n","\n","Separability probes teach a different lesson: does the embedding preserve latent factors in a way that could support downstream tasks? We compute an ANOVA-like ratio between-class scatter over within-class scatter for each factor. Students should learn that this is not a “statistical proof,” but it is a controlled measure of whether factor structure is visible in geometry.\n","\n","Collapse diagnostics matter because contrastive systems can sometimes find degenerate solutions. The mean off-diagonal cosine similarity and the per-dimension variance provide simple, interpretable signals. The covariance spectrum adds a more global view: effective rank indicates how many dimensions are meaningfully used. A model with low effective rank is geometrically impoverished, even if it sometimes produces passable retrieval on easy data.\n","\n","Visuals (PCA via SVD and similarity heatmaps) are used as intuition builders, not as evidence. Students learn the correct scientific posture: visuals generate hypotheses; metrics test them. This matters because embedding plots are seductive. They can make you believe you see structure even when the structure is an artifact of projection.\n","\n","Finally, we export all evaluation results as strict JSON, emphasizing reviewability. In professional settings, evaluation is not complete until it can be inspected and compared across runs. Cell 8 teaches that interpretation must be anchored to exported, structured evidence.\n"],"metadata":{"id":"CGJ3TUQwi2JO"}},{"cell_type":"markdown","source":["###8.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"SCv1wHOni2cy"}},{"cell_type":"code","source":["# === Cell 8 ===\n","# Title: Evaluator (Retrieval@k, MRR, Separability, Collapse, Spectral Diagnostics, PCA via SVD)\n","# Explanation: Produces a rigorous diagnostic suite: retrieval, factor separability (ANOVA-like),\n","# collapse indicators, modality symmetry, and embedding covariance spectra. Also produces plots.\n","\n","def covariance_spectrum(Y: np.ndarray) -> Dict[str, float]:\n","    # Y: (N,D) normalized\n","    C = (Y - Y.mean(axis=0, keepdims=True)).T @ (Y - Y.mean(axis=0, keepdims=True)) / max(1, Y.shape[0]-1)\n","    # eigenvalues of symmetric PSD matrix\n","    evals = np.linalg.eigvalsh(C).astype(np.float64)\n","    evals = np.maximum(evals, 0.0)\n","    tr = float(np.sum(evals))\n","    if tr <= 1e-12:\n","        eff_rank = 0.0\n","        cond = float(\"inf\")\n","    else:\n","        eff_rank = float((tr**2) / (np.sum(evals**2) + 1e-12))\n","        cond = float((np.max(evals) + 1e-12) / (np.min(evals) + 1e-12))\n","    return {\n","        \"trace\": tr,\n","        \"max_eig\": float(np.max(evals)),\n","        \"min_eig\": float(np.min(evals)),\n","        \"effective_rank\": eff_rank,\n","        \"condition_number\": cond,\n","        \"eigvals\": evals.tolist(),  # keep for audit; can be large but D small\n","    }\n","\n","def collapse_metrics(Y: np.ndarray) -> Dict[str, float]:\n","    # mean off-diagonal cosine (Y normalized)\n","    sim = Y @ Y.T\n","    N = sim.shape[0]\n","    off = (np.sum(sim) - np.sum(np.diag(sim))) / max(1, N*(N-1))\n","    var = float(np.mean(np.var(Y, axis=0)))\n","    return {\"mean_offdiag_cos\": float(off), \"mean_dim_var\": var}\n","\n","def anova_separability(Y: np.ndarray, labels: np.ndarray) -> float:\n","    # Between / Within variance ratio (scalar)\n","    Yc = Y - Y.mean(axis=0, keepdims=True)\n","    classes = np.unique(labels)\n","    between = 0.0\n","    within = 0.0\n","    for c in classes:\n","        idx = np.where(labels == c)[0]\n","        if len(idx) == 0:\n","            continue\n","        mu_c = Yc[idx].mean(axis=0, keepdims=True)\n","        between += float(len(idx) * np.sum(mu_c**2))\n","        within += float(np.sum((Yc[idx] - mu_c)**2))\n","    return float(between / (within + 1e-12))\n","\n","def pca_2d(Y: np.ndarray) -> np.ndarray:\n","    # PCA via SVD of centered data\n","    Yc = Y - Y.mean(axis=0, keepdims=True)\n","    U, S, Vt = np.linalg.svd(Yc, full_matrices=False)\n","    return (U[:, :2] * S[:2]).astype(np.float32)\n","\n","# Evaluate on test split (full)\n","Yi_test = embed_all(IMG, X_img[test_idx])\n","Yt_test = embed_all(TXT, X_txt[test_idx])\n","sim_test = Yi_test @ Yt_test.T\n","\n","m_i2t = retrieval_metrics(sim_test, CFG.topk)\n","m_t2i = retrieval_metrics(sim_test.T, CFG.topk)\n","\n","# separability probes (use image embeddings; can also do text)\n","sep = {\n","    \"shape\": anova_separability(Yi_test, META[\"shape\"][test_idx]),\n","    \"orient\": anova_separability(Yi_test, META[\"orient\"][test_idx]),\n","    \"freq_bin\": anova_separability(Yi_test, META[\"freq_bin\"][test_idx]),\n","    \"phase_bin\": anova_separability(Yi_test, META[\"phase_bin\"][test_idx]),\n","    \"thick_bin\": anova_separability(Yi_test, META[\"thick_bin\"][test_idx]),\n","}\n","\n","# collapse + spectra\n","col_i = collapse_metrics(Yi_test)\n","col_t = collapse_metrics(Yt_test)\n","spec_i = covariance_spectrum(Yi_test)\n","spec_t = covariance_spectrum(Yt_test)\n","\n","# modality symmetry norms (pre-normalization norms are useful; approximate via cached z norms batchwise)\n","def approx_pre_norms(model: MLP2, X: np.ndarray, batch: int = 512) -> np.ndarray:\n","    norms = []\n","    for i in range(0, X.shape[0], batch):\n","        c = model.forward(X[i:i+batch])\n","        norms.append(c[\"nrm\"].reshape(-1))\n","    return np.concatenate(norms, axis=0)\n","\n","norm_i = approx_pre_norms(IMG, X_img[test_idx])\n","norm_t = approx_pre_norms(TXT, X_txt[test_idx])\n","\n","sym = {\n","    \"mean_pre_norm_img\": float(np.mean(norm_i)),\n","    \"mean_pre_norm_txt\": float(np.mean(norm_t)),\n","    \"ratio_img_txt\": float(np.mean(norm_i) / (np.mean(norm_t) + 1e-12)),\n","    \"sym_gap_recall@1\": float(abs(m_i2t[\"recall@1\"] - m_t2i[\"recall@1\"])),\n","    \"mean_pos_sim\": float(np.mean(np.diag(sim_test))),\n","}\n","\n","# plots: PCA colored by shape + similarity heatmap\n","Z2 = pca_2d(Yi_test)\n","plt.figure(figsize=(6,5))\n","plt.scatter(Z2[:,0], Z2[:,1], c=META[\"shape\"][test_idx], s=8)\n","plt.title(\"PCA (SVD) of IMAGE embeddings (test), colored by shape\")\n","p1 = os.path.join(CFG.plots_dir, \"pca_image_shape_test.png\")\n","plt.savefig(p1, dpi=140)\n","plt.close()\n","\n","plt.figure(figsize=(6,5))\n","plt.imshow(sim_test[:128, :128], aspect=\"auto\")\n","plt.title(\"Similarity heatmap (test subset 128x128)\")\n","p2 = os.path.join(CFG.plots_dir, \"sim_heatmap_128.png\")\n","plt.savefig(p2, dpi=140)\n","plt.close()\n","\n","metrics = {\n","    \"retrieval_i2t\": m_i2t,\n","    \"retrieval_t2i\": m_t2i,\n","    \"separability_anova_ratio_image\": sep,\n","    \"collapse_image\": col_i,\n","    \"collapse_text\": col_t,\n","    \"spectrum_image\": {k: v for k, v in spec_i.items() if k != \"eigvals\"},\n","    \"spectrum_text\": {k: v for k, v in spec_t.items() if k != \"eigvals\"},\n","    \"symmetry\": sym,\n","    \"plots\": {\"pca_image_shape_test\": p1, \"sim_heatmap_128\": p2},\n","}\n","\n","AM.write_json_strict(\n","    os.path.join(CFG.out_dir, \"metrics_summary.json\"),\n","    facts_provided=metrics,\n","    assumptions={\n","        \"ground_truth_pairs\": \"Diagonal corresponds to true pairing by construction.\",\n","        \"anova_ratio\": \"Between/within scatter proxy; not a full statistical test.\",\n","    },\n","    open_items=[],\n","    analysis=\"Comprehensive post-training diagnostics: retrieval, factor separability, collapse indicators, modality symmetry, and covariance spectra.\",\n","    draft_output={\"headline\": {\"test_i2t_recall@1\": m_i2t[\"recall@1\"], \"test_t2i_recall@1\": m_t2i[\"recall@1\"], \"effective_rank_img\": spec_i[\"effective_rank\"]}},\n","    verification_status=\"Not verified\",\n","    questions_to_verify=[\"Do these diagnostics predict downstream task success in real multimodal settings?\"]\n",")\n","\n","print(\"Evaluator complete.\")\n","print(\"  test recall@1 i2t:\", m_i2t[\"recall@1\"], \"| t2i:\", m_t2i[\"recall@1\"])\n","print(\"  sep(shape):\", sep[\"shape\"], \"| collapse(offdiag cos, img):\", col_i[\"mean_offdiag_cos\"])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ggMQPyMmnrou","executionInfo":{"status":"ok","timestamp":1771332641756,"user_tz":360,"elapsed":417,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"8e84e75d-d44f-4d7a-c05c-3656740d3fdc"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["Evaluator complete.\n","  test recall@1 i2t: 0.31493506493506496 | t2i: 0.38311688311688313\n","  sep(shape): 0.026190861125560717 | collapse(offdiag cos, img): 0.007339404430240393\n"]}]},{"cell_type":"markdown","source":["##9.STRESS SWEEP"],"metadata":{"id":"7JxS9vVQi4yB"}},{"cell_type":"markdown","source":["###9.1.0VERVIEW"],"metadata":{"id":"Wurgn_8fi5-m"}},{"cell_type":"markdown","source":["**Cell 9 — Stress Testing: Robustness, Fragility, and “Where the Geometry Breaks”**\n","\n","Cell 9 teaches the most important practical lesson for using multimodal models: performance is conditional. A model that works on clean data can fail sharply when one modality degrades or when pairing information becomes imperfect. In deployment, those shifts are not rare; they are normal. Therefore, the responsible way to use multimodal embeddings is to measure how they degrade under plausible stresses.\n","\n","We perform two stresses that map cleanly to real-world failure modes. The first is noise asymmetry: we increase image noise while keeping text constant. This corresponds to blurry images, low-quality scans, sensor noise, compression artifacts, or domain mismatch. The second is pair corruption: we permute a fraction of text pairs. This corresponds to metadata errors, mislabeled assets, incorrect file associations, or weak supervision where pairing is imperfect.\n","\n","Students should focus on the degradation curves. A degradation curve is not just a plot; it is a contract. It tells you how much shift the system can tolerate before it becomes unreliable. If recall@1 collapses quickly under mild noise, then the embedding space is brittle. If it degrades smoothly, the system is more robust. This teaches a professional decision-making habit: you do not deploy based on peak performance; you deploy based on tolerated stress.\n","\n","Stress tests also reveal whether the learned representation uses “meaningful invariants” or fragile shortcuts. A space that relies on spurious artifacts will often break catastrophically when those artifacts are perturbed. In synthetic labs, we can design stresses that target specific artifacts. In real systems, you design stresses that target your known risks: OCR errors, audio dropouts, camera shifts, or domain-specific confounders.\n","\n","Finally, this cell reinforces governance: stress outputs are exported as structured JSON and plots. Students learn that robustness is not a claim; it is measured evidence with recorded conditions. This is essential for frontier topics where stakeholders may be tempted to accept impressive demos without understanding fragility.\n"],"metadata":{"id":"SYflANI7irC5"}},{"cell_type":"markdown","source":["###9.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"WvgKf0NEi8Tj"}},{"cell_type":"code","source":["# === Cell 9 ===\n","# Title: StressSuite (Noise Asymmetry + Pair Corruption) with Degradation Curves\n","# Explanation: Runs controlled stress sweeps (image noise and pair mismatch) and records\n","# degradation curves and plots to teach robustness and fragility of alignment geometry.\n","\n","def eval_recall1_under(Xi: np.ndarray, Xt: np.ndarray) -> float:\n","    Yi = embed_all(IMG, Xi)\n","    Yt = embed_all(TXT, Xt)\n","    sim = Yi @ Yt.T\n","    return float(np.mean(np.argmax(sim, axis=1) == np.arange(sim.shape[0])))\n","\n","# Noise asymmetry sweep (only re-render images, keep text fixed)\n","noise_grid = np.linspace(0.0, 0.50, 9)\n","acc_noise = []\n","for nl in noise_grid:\n","    # temporarily override noise (without mutating CFG dataclass)\n","    old = WORLD.cfg.noise_image\n","    object.__setattr__(WORLD.cfg, \"noise_image\", float(nl))  # controlled override in runtime\n","    Xi_n, Xt_n, _ = WORLD.build_dataset(len(test_idx))\n","    object.__setattr__(WORLD.cfg, \"noise_image\", float(old))\n","    acc_noise.append(eval_recall1_under(Xi_n, X_txt[test_idx]))\n","\n","# Pair corruption sweep (permute text pairs by fraction)\n","def corrupt_pairs(Xt: np.ndarray, frac: float, seed: int) -> np.ndarray:\n","    rng = np.random.RandomState(seed)\n","    Xt2 = Xt.copy()\n","    n = Xt.shape[0]\n","    m = int(frac * n)\n","    if m <= 0:\n","        return Xt2\n","    idx = rng.choice(n, size=m, replace=False)\n","    perm = idx.copy()\n","    rng.shuffle(perm)\n","    Xt2[idx] = Xt2[perm]\n","    return Xt2\n","\n","corrupt_grid = np.linspace(0.0, 0.50, 9)\n","acc_corrupt = []\n","Xi_base = X_img[test_idx]\n","Xt_base = X_txt[test_idx]\n","for frac in corrupt_grid:\n","    Xt_c = corrupt_pairs(Xt_base, float(frac), seed=CFG.seed + 1234)\n","    acc_corrupt.append(eval_recall1_under(Xi_base, Xt_c))\n","\n","# plots\n","plt.figure(figsize=(6,4))\n","plt.plot(noise_grid, acc_noise, marker=\"o\")\n","plt.xlabel(\"Image noise (std)\")\n","plt.ylabel(\"Recall@1 (i2t)\")\n","plt.title(\"Stress: Noise Asymmetry (image-only)\")\n","p_noise = os.path.join(CFG.plots_dir, \"stress_noise_asymmetry.png\")\n","plt.savefig(p_noise, dpi=140)\n","plt.close()\n","\n","plt.figure(figsize=(6,4))\n","plt.plot(corrupt_grid, acc_corrupt, marker=\"o\")\n","plt.xlabel(\"Pair corruption fraction\")\n","plt.ylabel(\"Recall@1 (i2t)\")\n","plt.title(\"Stress: Pair Corruption\")\n","p_corr = os.path.join(CFG.plots_dir, \"stress_pair_corruption.png\")\n","plt.savefig(p_corr, dpi=140)\n","plt.close()\n","\n","stress = {\n","    \"noise_asymmetry\": {\"grid\": noise_grid.tolist(), \"recall1\": acc_noise, \"plot\": p_noise},\n","    \"pair_corruption\": {\"grid\": corrupt_grid.tolist(), \"recall1\": acc_corrupt, \"plot\": p_corr},\n","}\n","\n","AM.write_json_strict(\n","    os.path.join(CFG.stress_dir, \"stress_report.json\"),\n","    facts_provided=stress,\n","    assumptions={\"stress_design\": \"Noise affects only the image modality; corruption permutes a subset of text pairs.\"},\n","    open_items=[],\n","    analysis=\"Stress sweeps quantify robustness and illustrate degradation geometry under asymmetric noise and pairing corruption.\",\n","    draft_output={\"headline\": {\"recall1_clean\": acc_noise[0], \"recall1_noise_0.5\": acc_noise[-1], \"recall1_corrupt_0.5\": acc_corrupt[-1]}},\n","    verification_status=\"Not verified\",\n","    questions_to_verify=[\"Do these stress curves match qualitative failure regimes in real multimodal models?\"]\n",")\n","\n","print(\"StressSuite complete.\")\n","print(\"  clean recall@1:\", acc_noise[0], \"| noise(0.5):\", acc_noise[-1], \"| corrupt(0.5):\", acc_corrupt[-1])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IrGmEdLGnvG2","executionInfo":{"status":"ok","timestamp":1771332647454,"user_tz":360,"elapsed":434,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"51e7cc1f-dab2-4911-b0e6-0ab7783859ac"},"execution_count":67,"outputs":[{"output_type":"stream","name":"stdout","text":["StressSuite complete.\n","  clean recall@1: 0.003246753246753247 | noise(0.5): 0.003246753246753247 | corrupt(0.5): 0.16883116883116883\n"]}]},{"cell_type":"markdown","source":["##10.AUDIT BUNDLE"],"metadata":{"id":"ss5L2x1ojA8d"}},{"cell_type":"markdown","source":["###10.1.OVERVIEW"],"metadata":{"id":"sduxTxx7jC0M"}},{"cell_type":"markdown","source":["**Cell 10 — Finalization and the Audit Bundle (Turning a Notebook into a Reviewable Professional Artifact)**\n","\n","Cell 10 completes the governance loop. The notebook does not end when training ends; it ends when results are packaged into a form that can be reviewed by someone who was not present at runtime. This is a subtle but crucial pedagogical point. In professional contexts, your audience is rarely “you, right now.” Your audience is a reviewer, a colleague, an auditor, or a future version of yourself trying to understand what happened. The audit bundle is what makes that possible.\n","\n","This cell writes the prompt log, which records the intent of the notebook run along with hashes for integrity. It writes the risk log, which documents known failure modes and the controls implemented. It also writes a deliverables index: a file list with sizes that makes review navigation easy. This is a small engineering convenience that becomes a big practical advantage when you run many experiments and need to compare artifacts across runs.\n","\n","The final step is bundling. We zip the manifest, logs, metrics, plots, and stress reports into a single archive. The pedagogical lesson is that a model is not a weight file. A model is part of a narrative about evidence. The archive is the boundary object that allows that evidence to be transported, inspected, and critiqued.\n","\n","Students should also learn what “verification_status = Not verified” means. It is not pessimism; it is epistemic hygiene. The notebook can produce internal evidence, but it cannot verify external claims (such as real-world generalization). Marking outputs as “Not verified” teaches students to separate what the notebook demonstrated from what it did not. This prevents the common frontier failure: taking a controlled synthetic demonstration and overstating its implications.\n","\n","Ultimately, Cell 10 teaches the meta-lesson of the entire chapter: multimodality is not merely a capability; it is a practice. The practice includes reproducibility, diagnostics, stress testing, and reviewable artifacts. When students internalize that practice, they are ready to use multimodal models responsibly in real applications.\n"],"metadata":{"id":"bqPR0OmsWKLt"}},{"cell_type":"markdown","source":["###10.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"v_giRgoJjGY5"}},{"cell_type":"code","source":["# === Cell 10 ===\n","# Title: Finalization (Prompt Log, Bundle Zip, File Index, Run Summary)\n","# Explanation: Flushes prompt logs, bundles all artifacts into an audit zip,\n","# and prints a concise index of deliverables for review.\n","\n","AM.flush_prompts()\n","\n","# Create a concise file index for reviewer convenience\n","file_index = []\n","for root, _, files in os.walk(\".\"):\n","    for fn in files:\n","        if fn.endswith((\".json\", \".jsonl\", \".png\")):\n","            path = os.path.join(root, fn)\n","            try:\n","                sz = os.path.getsize(path)\n","            except OSError:\n","                sz = -1\n","            file_index.append({\"path\": path, \"bytes\": sz})\n","\n","file_index = sorted(file_index, key=lambda x: x[\"path\"])\n","\n","AM.write_json_strict(\n","    os.path.join(CFG.out_dir, \"deliverables_index.json\"),\n","    facts_provided={\"files\": file_index},\n","    assumptions={},\n","    open_items=[],\n","    analysis=\"Index of artifacts produced by this run; intended for audit/review navigation.\",\n","    draft_output={\"count\": len(file_index)},\n","    verification_status=\"Not verified\",\n","    questions_to_verify=[]\n",")\n","\n","zip_name = f\"audit_bundle_{AM.run_id}.zip\"\n","with zipfile.ZipFile(zip_name, \"w\", compression=zipfile.ZIP_DEFLATED) as z:\n","    for item in file_index:\n","        z.write(item[\"path\"])\n","\n","print(\"FINALIZATION\")\n","print(\"  run_id:\", AM.run_id)\n","print(\"  bundle:\", zip_name)\n","print(\"  key outputs:\")\n","print(\"   - run_manifest.json\")\n","print(\"   - risk_log.json\")\n","print(\"   - prompts_log.jsonl\")\n","print(\"   - deliverables/metrics_summary.json\")\n","print(\"   - deliverables/train_history.json\")\n","print(\"   - deliverables/stress/stress_report.json\")\n","print(\"   - deliverables/plots/*.png\")\n"],"metadata":{"id":"Lrqr5DdYjK83","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1771332651578,"user_tz":360,"elapsed":189,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"3496d1e8-ac62-4fe3-99bc-8fc033ac3ab4"},"execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["FINALIZATION\n","  run_id: 3cb8138df0b7\n","  bundle: audit_bundle_3cb8138df0b7.zip\n","  key outputs:\n","   - run_manifest.json\n","   - risk_log.json\n","   - prompts_log.jsonl\n","   - deliverables/metrics_summary.json\n","   - deliverables/train_history.json\n","   - deliverables/stress/stress_report.json\n","   - deliverables/plots/*.png\n"]}]},{"cell_type":"markdown","source":["##11.CONCLUSION"],"metadata":{"id":"ZmL0B12KjLXl"}},{"cell_type":"markdown","source":["**Conclusion: Main Lessons and How to Use a Multimodally Trained Model**\n","\n","The central lesson of this chapter is that a multimodally trained model is not “a model that understands images and text.” It is a disciplined system for constructing comparability. After you strip away marketing language, multimodality is the engineering of a shared coordinate system in which different measurement instruments can be meaningfully related. An image encoder and a text encoder are two different sensors. The model’s job is not to turn one into the other; it is to learn embeddings that preserve the invariants you care about so that cross-modal queries become stable geometric operations. Once you internalize this, you stop treating multimodality as magic and start treating it as a mechanism with failure modes, diagnostics, and governance obligations.\n","\n","A second lesson is that multimodal “understanding” is mostly geometry plus constraints. When you train with a contrastive objective, you are not teaching the model a semantic dictionary. You are teaching it a metric: what should be near, what should be far, and how strongly those preferences should be enforced. This is why temperature, normalization, batch composition, and negative sampling matter so much. They are not peripheral hyperparameters; they are geometric dials. In practice, to “use” a multimodally trained model well is to understand the geometry it learned and to respect the regime in which that geometry is stable. If you use the embeddings outside that regime—under distribution shift, under different pairing assumptions, or under different noise patterns—you can get confident but meaningless similarity.\n","\n","This leads to a practical posture: treat embeddings as measurements, not truths. An embedding is a coordinate produced by a learned instrument. It reflects the objective and data you trained on. It is not a direct encoding of reality, and it is not automatically interpretable. The correct question is not “what does this embedding mean?” but “what relations does this embedding preserve reliably?” The chapter operationalizes this by forcing you to measure retrieval, separability, and collapse. Those metrics are the minimal evidence that the geometry does what you think it does. If retrieval fails, the shared space is not functioning as a shared space. If separability fails, the space is not preserving important factors. If collapse indicators are high, the model is compressing everything into a near-single direction and you are confusing numerical stability with representation quality.\n","\n","Once you adopt the “embedding as measurement” view, you can articulate a correct workflow for using multimodally trained models. The workflow begins with specifying a task in geometric terms. Many practical multimodal tasks reduce to a small set of geometric operations: retrieval (find matching items across modalities), clustering (group items by shared factors), ranking (order candidates by similarity), and monitoring (detect drift by changes in similarity distributions). For each operation, your responsibility is to confirm that the geometry supports it. For retrieval, you test recall@k and MRR under the conditions you will use. For clustering, you test whether clusters correspond to meaningful factors rather than superficial artifacts. For ranking, you test calibration: does high similarity actually correspond to correctness, and does that relationship remain stable under mild perturbations?\n","\n","A key insight here is that “using a multimodal model” is often “using its embedding space as a database index.” In modern systems, the most common operational use of multimodal encoders is not generation. It is representation: you embed a corpus of images, documents, diagrams, or mixed media; you embed a query in one modality; you retrieve nearest neighbors in the shared space. This can feel like semantics, but it is essentially metric search. The difference between a robust system and a brittle one is whether you treat the embedding model as a static, unquestioned oracle, or as a measured component with verified operating conditions. In a professional setting, you do not deploy metric search without monitoring its error modes. Multimodal search is no different. You need baselines, drift detection, and periodic re-validation.\n","\n","Another lesson is that multimodal alignment is inseparable from data pairing assumptions. Contrastive learning assumes that your positives are truly positives and your negatives are “other.” In real datasets, this assumption is noisy. Captions can be incomplete or misleading. Images can contain multiple objects while text mentions only one. Two different items can be validly related (near-duplicates, paraphrases, similar scenes) but be labeled as negatives. In our synthetic world, pairing is clean by construction, which is why the mechanism is teachable. But the point of the synthetic lab is precisely to help you recognize what breaks when pairing becomes ambiguous. When you use a multimodally trained model, you must ask: what is a “pair” in this setting? Is it identity (exact match) or relevance (partially overlapping factors) or style (aesthetic similarity) or intent (functional similarity)? Different pairing definitions imply different geometries, and a model trained under one pairing regime will be systematically wrong under another.\n","\n","This is where the chapter’s stress tests become a professional habit rather than a classroom trick. Noise asymmetry and pair corruption are not artificial; they are simplified versions of real-world shifts. Noise asymmetry occurs when one modality becomes degraded: blurry images, low-light frames, OCR errors, speech-to-text mistakes, low-quality scans. Pair corruption occurs when metadata linking modalities breaks: mislabeled attachments, wrong captions, duplicated IDs, or inconsistent naming conventions. A model that performs beautifully on clean pairs can fail catastrophically under these shifts. Therefore, to “use” a multimodal model responsibly is to treat stress testing as part of acceptance, not as an optional curiosity. If you cannot characterize degradation curves for the likely shifts in your domain, you do not understand the system you are deploying.\n","\n","A further lesson is the importance of modality symmetry. In a shared embedding space, you can have a deceptive success pattern: one direction works well (image→text retrieval) and the reverse direction works poorly (text→image retrieval), or vice versa. This is not a minor asymmetry; it is evidence that the shared space is not truly shared. It often indicates that one encoder dominates the learning dynamics or that one modality carries more easily exploitable features. In practice, this matters because real systems often need both directions: a user might search images with text queries, but they might also search textual descriptions with image queries or use images to retrieve documents. A symmetry gap is a warning sign. The correct use pattern is to measure both directions and to decide explicitly whether you are building a symmetric system or a one-way index. If it is one-way, you should say so and constrain use accordingly.\n","\n","Related to symmetry is the deeper issue of “what the model chooses to align.” A multimodal system will align whatever is easiest to align under the objective and data. If your dataset contains spurious correlations—such as certain words always appearing with certain colors, or certain layouts always corresponding to certain labels—the model may exploit those correlations rather than the intended causal factors. This is not a moral failure; it is optimization. The governance implication is that you must be explicit about spurious correlation risk and must test for it. In our synthetic lab, spurious correlation can be introduced intentionally: add a token that correlates with a nuisance feature, or add an image artifact correlated with a class. The model will likely latch onto it. The professional lesson is that multimodal models are not immune to shortcut learning; they are often more vulnerable, because the cross-modal objective can amplify correlated nuisance signals that make retrieval easy but meaning shallow.\n","\n","A major practical takeaway is how to interpret distances and similarities. People often treat cosine similarity as if it were a probability of correctness. It is not. It is a geometric measure that can be monotonic with correctness under certain conditions, but it is not calibrated. If you use similarity thresholds to decide whether to accept a match, you must empirically calibrate those thresholds under your domain conditions. This includes evaluating false positives, false negatives, and ambiguous matches. It also includes monitoring how similarity distributions shift over time. In a deployed system, a drift in the similarity histogram can signal a data pipeline change, a domain shift, or a subtle degradation in one modality. Treat similarity as a signal that requires governance, not as a truth score.\n","\n","Another lesson is that embedding visualizations are not evidence by themselves. PCA plots and heatmaps are invaluable for intuition. They help students see “cluster” and “axis” in a visceral way. But it is dangerously easy to over-interpret them. Dimensionality reduction can create apparent structure where none exists, or hide structure that exists. The correct posture is: visuals are hypotheses, metrics are tests. Use PCA to generate hypotheses about factor structure, then confirm those hypotheses with separability metrics and retrieval performance. This is a good scientific practice that transfers directly to real multimodal work.\n","\n","Now, what does it mean to use a multimodally trained model well, in a concrete operational sense? It means you separate your work into three layers: representation, decision, and governance. The representation layer produces embeddings. The decision layer uses embeddings for tasks like retrieval, ranking, clustering, or matching. The governance layer monitors and constrains those decisions. Most failures happen because practitioners conflate these layers. They embed and immediately treat nearest neighbors as ground truth. The correct workflow is to: embed, measure geometry quality, choose task-specific decision rules, stress test the decision rules, and then deploy with monitoring and periodic re-validation.\n","\n","In that workflow, the concept of “acceptance criteria” becomes central. A model is not accepted because it trains without errors. It is accepted because it meets pre-defined criteria under defined stresses. For this chapter, those criteria can be simple but meaningful: retrieval@1 above a threshold on validation, symmetry gap below a threshold, effective rank above a floor (to avoid collapse), and degradation curves that do not fall off a cliff under mild noise. In real systems, you will add domain-specific criteria: bias checks, adversarial robustness, privacy constraints, and audit requirements. But the principle is the same: acceptance is evidence-based. This is what makes multimodality teachable in a governance-first framework. Students learn that representation learning is not just optimization; it is system acceptance under constraint.\n","\n","Finally, the deepest lesson is about interpretation. Multimodality teaches you to think of intelligence as coordination among partial views. No single modality is complete. Each is an instrument with blind spots. A multimodal model is valuable when it can reconcile those partial views into a representation that supports coherent action—retrieval, decision support, navigation, summarization, or monitoring. But it is dangerous when it gives you the illusion that partial views have become total knowledge. Governance is the counterweight to that illusion. You are required to label what is supported, what is assumed, and what is unknown. You are required to preserve reproducibility and provenance. You are required to stress the system and document failure modes. These are not bureaucratic extras; they are the conditions under which multimodal capability becomes professionally usable.\n","\n","So the practical conclusion is simple to state and difficult to practice: use multimodal models as engineered measurement systems. Define what “pairing” means in your task. Validate geometry with retrieval and separability. Detect collapse and dominance. Stress test likely shifts. Calibrate similarity thresholds rather than guessing them. Deploy with monitoring and reviewable artifacts. When you do this, multimodality stops being frontier mystique and becomes a professional instrument: a shared coordinate system that you can trust, because you have measured the conditions under which it is trustworthy. That is the main lesson this chapter is designed to leave with you and your students.\n"],"metadata":{"id":"tv8ReGkpWL8u"}}]}